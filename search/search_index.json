{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Course website Material This website Zoom meeting (through mail) Google doc (through mail) Slack channel Learning outcomes After this course, you will be able to: Understand important aspects of NGS and read alignment for variant analysis Perform a read alignment ready for variant analysis Perform variant calling according to GATK best practices Perform a variant annotation Learning experiences This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only. Exercises Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different. Asking questions During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online): A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #peer-q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. Answer questions only if you have finished the practical block, and use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re stuck and need tutor support, use the no button in Zoom, if you\u2019re finished use the yes button. To summarize: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #peer_q_and_a on slack if really stuck: no button in zoom if finished: yes button in zoom","title":"Home"},{"location":"#course-website","text":"","title":"Course website"},{"location":"#material","text":"This website Zoom meeting (through mail) Google doc (through mail) Slack channel","title":"Material"},{"location":"#learning-outcomes","text":"After this course, you will be able to: Understand important aspects of NGS and read alignment for variant analysis Perform a read alignment ready for variant analysis Perform variant calling according to GATK best practices Perform a variant annotation","title":"Learning outcomes"},{"location":"#learning-experiences","text":"This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only.","title":"Learning experiences"},{"location":"#exercises","text":"Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Exercises"},{"location":"#asking-questions","text":"During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online): A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #peer-q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. Answer questions only if you have finished the practical block, and use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re stuck and need tutor support, use the no button in Zoom, if you\u2019re finished use the yes button. To summarize: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #peer_q_and_a on slack if really stuck: no button in zoom if finished: yes button in zoom","title":"Asking questions"},{"location":"course_schedule/","text":"Day 1 block start end subject block 1 9:00 AM 10:30 AM Introduction 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Read alignment - basics 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment - advanced Day 2 block start end subject block 1 9:00 AM 10:30 AM Variant calling 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Visualisation 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Filtering & evaluation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Annotation","title":"Course schedule"},{"location":"course_schedule/#day-1","text":"block start end subject block 1 9:00 AM 10:30 AM Introduction 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Read alignment - basics 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment - advanced","title":"Day 1"},{"location":"course_schedule/#day-2","text":"block start end subject block 1 9:00 AM 10:30 AM Variant calling 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Visualisation 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Filtering & evaluation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Annotation","title":"Day 2"},{"location":"precourse/","text":"UNIX As is stated in the course prerequisites at the announcement web page . We expect participants to have a basic understanding of working with the command line on UNIX-based systems. If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial . Software We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through ssh with a username, key and IP address. All participants will be granted access to a personal home directory. Before the course, make sure you can comfortably work on a remote server. This means that you can approach it through the shell, modify scripts and transfer files. We can recommend atom for Linux and Mac, and MobaXterm for Windows. We will be visualising our results with IGV. Therefore, install in your computer: mac OS/Linux SSH and scripting: Atom with packages like: terminus and ftp-remote-edit Transferring files: FileZilla Integrative Genomics Viewer (IGV) Windows SSH and scripting: MobaXterm and/or Notepad++ with the plugin NppFTP Transferring files: FileZilla Integrative Genomics Viewer (IGV)","title":"Precourse preparations"},{"location":"precourse/#unix","text":"As is stated in the course prerequisites at the announcement web page . We expect participants to have a basic understanding of working with the command line on UNIX-based systems. If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial .","title":"UNIX"},{"location":"precourse/#software","text":"We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through ssh with a username, key and IP address. All participants will be granted access to a personal home directory. Before the course, make sure you can comfortably work on a remote server. This means that you can approach it through the shell, modify scripts and transfer files. We can recommend atom for Linux and Mac, and MobaXterm for Windows. We will be visualising our results with IGV. Therefore, install in your computer: mac OS/Linux SSH and scripting: Atom with packages like: terminus and ftp-remote-edit Transferring files: FileZilla Integrative Genomics Viewer (IGV) Windows SSH and scripting: MobaXterm and/or Notepad++ with the plugin NppFTP Transferring files: FileZilla Integrative Genomics Viewer (IGV)","title":"Software"},{"location":"day1/alignment/","text":"Material Download the presentation Exercises 1. Prepare the reference genome Download and unpack the data files in your working directory ( ~/workdir ). cd ~/workdir wget https://ngs-variants-training.s3.eu-central-1.amazonaws.com/ngs-variants-training.tar.gz tar -xvf ngs-variants-training.tar.gz This will create the directory data . Check out what\u2019s in there. We\u2019ll use bwa mem for the alignment. Like all alignment software, it requires an index of the reference genome. You can make an index like this: Activate the conda environment All software below is in the conda environment variants . To activate it: conda activate variants Before you\u2019ve run this your shell starts with (base) , indicating you\u2019re in the base environment. After running the conda activate variants command, it should have changed to variants . bwa index <reference.fa> Make an index of the reference sequence of chromosome 20 of the human genome. You can find the fasta file in ~/workdir/data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer cd ~/workdir/data/reference/ bwa index Homo_sapiens.GRCh38.dna.chromosome.20.fa Check out the synopsis and manual of bwa mem . We\u2019ll be using paired-end reads of three samples that can be found at ~/workdir/data/fastq . If we run bwa mem with default options, which three arguments do we need? Answer The manual says: bwa mem [-aCHMpP] [-t nThreads] [-k minSeedLen] ... db.prefix reads.fq [mates.fq] So, we\u2019ll need: a database prefix ( db.prefix ) forward reads ( reads.fq ) reverse reads ( mates.fq ) For our reference sequence a command would look like: cd ~/workdir/ bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ <forward_reads.fq> \\ <reverse_reads.fq> \\ > <alignment.sam> Perform an alignment with bwa mem of the reads from the mother ( mother_R1.fastq and mother_R2.fastq ) against chromosome 20. Write the alignment file to a directory in ~/workdir called alignment . Index prefix is the same a reference filename With default values, the name of the index of a reference for bwa mem is the same as the name of the reference itself. In this case, this would be Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer We\u2019ll first make the alignment directory: cd ~/workdir/ mkdir alignment Then, we run the alignment: bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/mother_R1.fastq.gz \\ data/fastq/mother_R2.fastq.gz \\ > alignment/mother.sam 2. Alignment statistics Exercise: Check out the statistics of the alignment by using samtools flagstat . Find the documentation here . Any duplicates in there? Answer cd ~/workdir/alignment samtools flagstat mother.sam Should give: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 0 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) No duplicates were found ( 0 + 0 duplicates ). The aligner doesn\u2019t automatically flag duplicates. This needs to be done after the alignment. 3. Compression The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Tip: samtools view writes to stdout Like bwa mem , samtools view writes its output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . Answer samtools view -bh mother.sam > mother.bam By using ls -lh , you can find out that mother.sam has a size of 54 Mb, while mother.bam is only 20 Mb.","title":"Read alignment - basics"},{"location":"day1/alignment/#material","text":"Download the presentation","title":"Material"},{"location":"day1/alignment/#exercises","text":"","title":"Exercises"},{"location":"day1/alignment/#1-prepare-the-reference-genome","text":"Download and unpack the data files in your working directory ( ~/workdir ). cd ~/workdir wget https://ngs-variants-training.s3.eu-central-1.amazonaws.com/ngs-variants-training.tar.gz tar -xvf ngs-variants-training.tar.gz This will create the directory data . Check out what\u2019s in there. We\u2019ll use bwa mem for the alignment. Like all alignment software, it requires an index of the reference genome. You can make an index like this: Activate the conda environment All software below is in the conda environment variants . To activate it: conda activate variants Before you\u2019ve run this your shell starts with (base) , indicating you\u2019re in the base environment. After running the conda activate variants command, it should have changed to variants . bwa index <reference.fa> Make an index of the reference sequence of chromosome 20 of the human genome. You can find the fasta file in ~/workdir/data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer cd ~/workdir/data/reference/ bwa index Homo_sapiens.GRCh38.dna.chromosome.20.fa Check out the synopsis and manual of bwa mem . We\u2019ll be using paired-end reads of three samples that can be found at ~/workdir/data/fastq . If we run bwa mem with default options, which three arguments do we need? Answer The manual says: bwa mem [-aCHMpP] [-t nThreads] [-k minSeedLen] ... db.prefix reads.fq [mates.fq] So, we\u2019ll need: a database prefix ( db.prefix ) forward reads ( reads.fq ) reverse reads ( mates.fq ) For our reference sequence a command would look like: cd ~/workdir/ bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ <forward_reads.fq> \\ <reverse_reads.fq> \\ > <alignment.sam> Perform an alignment with bwa mem of the reads from the mother ( mother_R1.fastq and mother_R2.fastq ) against chromosome 20. Write the alignment file to a directory in ~/workdir called alignment . Index prefix is the same a reference filename With default values, the name of the index of a reference for bwa mem is the same as the name of the reference itself. In this case, this would be Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer We\u2019ll first make the alignment directory: cd ~/workdir/ mkdir alignment Then, we run the alignment: bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/mother_R1.fastq.gz \\ data/fastq/mother_R2.fastq.gz \\ > alignment/mother.sam","title":"1. Prepare the reference genome"},{"location":"day1/alignment/#2-alignment-statistics","text":"Exercise: Check out the statistics of the alignment by using samtools flagstat . Find the documentation here . Any duplicates in there? Answer cd ~/workdir/alignment samtools flagstat mother.sam Should give: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 0 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) No duplicates were found ( 0 + 0 duplicates ). The aligner doesn\u2019t automatically flag duplicates. This needs to be done after the alignment.","title":"2. Alignment statistics"},{"location":"day1/alignment/#3-compression","text":"The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Tip: samtools view writes to stdout Like bwa mem , samtools view writes its output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . Answer samtools view -bh mother.sam > mother.bam By using ls -lh , you can find out that mother.sam has a size of 54 Mb, while mother.bam is only 20 Mb.","title":"3. Compression"},{"location":"day1/alignment_advanced/","text":"Material samtools documentation Exercises 1. Marking duplicates For variant analysis, it\u2019s important to mark reads that possibly originated from PCR duplication. We can do that with samtools markdup . However, we can not directly run that on our .sam file nor on our compressed .bam file. Exercise: Which samtools commands would we need to run to mark duplicates? Hint More info on this at the samtools markdup documentation . Also: the reads are already collated (i.e. forward and reverse are grouped) after the alignment, so no need to run samtools collate . Answer The commands would be: samtools fixmate (with the -m option) samtools sort samtools markdup Exercise: Run the three commands that are required to mark duplicates. Answer cd ~/workdir/alignment samtools fixmate -m mother.bam mother.fixmate.bam samtools sort -o mother.positionsort.bam mother.fixmate.bam samtools markdup mother.positionsort.bam mother.markdup.bam Exercise: Run samtools flagstat on the alignment file with marked duplicates. How many reads were marked as duplicate? Answer samtools flagstat mother.markdup.bam Gives: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 17329 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Which tells us that 17329 reads were marked as duplicate. 2. Adding read groups For variant analysis, it\u2019s important to know which read came from which sample. Right now, that\u2019s easy. All reads come from one individual. But this can become less trivial if you are combining samples. Therefore we add a tag to each read specifying its origin. You can add a readgroup to your marked alignment file like this: samtools addreplacerg \\ -r ID:mother \\ -r SM:mother \\ -r PL:ILLUMINA \\ mother.markdup.bam \\ > mother.markdup.rg.bam This command modifies the sam header and read tags. Exercise: Run the samtools addreplacerg command and compare the header and first alignments of mother.markdup.bam and mother.markdup.rg.bam . Notice any differences? Hint You can view the header with samtools view -H <alignment.bam> And the first few alignments with samtools view <alignment.bam> | head Answer Compared to the header of mother.markdup.bam , the header of mother.markdup.rg.bam contains two extra lines starting with @PG and @RG respectively: @PG ID:samtools.4 PN:samtools PP:samtools.3 VN:1.11 CL:samtools addreplacerg -r ID:mother -r SM:mother -r PL:ILLUMINA mother.markdup.bam @RG ID:mother SM:mother PL:ILLUMINA Here, the @PG lines tell you which commands have been run on this alignment file. The @RG line defines the readgroups present in the alignment file. In the alignment records, a tag was added at the very end of each line: RG:Z:mother . 3. Indexing To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools index mother.markdup.rg.bam 4. Piping and looping Samtools can quite easily be used in a UNIX pipeline. This has the advantage that you don\u2019t need to write many intermediate files. However, the developers have not been very consistent with managing input and output (I\u2019m sure they had their reasons). To use samtools in a pipe, the input argument needs to replaced with a - . Also, some commands do not write by default to stdout, but to a specified file (this is the case for e.g. samtools fixmate and samtools markdup ). In that case, also the output argument should be replaced with - . Example For the command samtools addreplacerg the samtools documentation provides the following synopsis: samtools addreplacerg [-r rg-line | -R rg-ID] [-m mode] [-l level] [-o out.bam] in.bam Meaning that it requires in.bam , and can write to out.bam if option -o is provided. By default, it writes to stdout. So, if you pipe to samtools addreplacerg you would only need to replace the input file with a - : some_command | samtools addreplacerg [ options ] - > output.sam For the command samtools fixmate , the samtools documentation provides this synopsis: samtools fixmate [-rpcm] [-O format] in.nameSrt.bam out.bam Meaning that it requires both the input file in.nameSrt.bam and the output file out.bam . So, if you pipe to samtools fixmate and you want to write to stdout (so piping from), you\u2019ll need to replace both the input and output with a - : some_command | samtools fixmate [ options ] - - > output.sam The most frequently used samtools commands don\u2019t require an input nor an output file, and therefore behave like many UNIX commands. An example of this is samtools sort . The synopsis is: samtools sort [-l level] [-m maxMem] [-o out.bam] [-O format] [-n] [-t tag] [-T tmpprefix] [-@ threads] [in.sam|in.bam|in.cram] Telling us that both the input file and output (with option -o ) file are optional. If the input file is absent, it reads from stdin. So, you could use it without a - replacing input or output files: some_command | samtools sort > output.sam Let\u2019s put everything we\u2019ve done so far in a pipe and loop over our three samples. The command below loops over the strings father , mother and son , and: performs the alignment marks duplicates adds readgroups compresses the output creates an index #!/usr/bin/env bash cd ~/workdir for sample in mother father son do bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz \\ | samtools fixmate -m - - \\ | samtools sort \\ | samtools markdup -s - - \\ | samtools addreplacerg -r ID: $sample -r SM: $sample -r PL:ILLUMINA - \\ | samtools view -bh > alignment/ $sample .bam samtools index alignment/ $sample .bam done Exercise: Try to understand what each line of this script does. After that, run it to get the alignments of all three samples.","title":"Read alignment - advanced"},{"location":"day1/alignment_advanced/#material","text":"samtools documentation","title":"Material"},{"location":"day1/alignment_advanced/#exercises","text":"","title":"Exercises"},{"location":"day1/alignment_advanced/#1-marking-duplicates","text":"For variant analysis, it\u2019s important to mark reads that possibly originated from PCR duplication. We can do that with samtools markdup . However, we can not directly run that on our .sam file nor on our compressed .bam file. Exercise: Which samtools commands would we need to run to mark duplicates? Hint More info on this at the samtools markdup documentation . Also: the reads are already collated (i.e. forward and reverse are grouped) after the alignment, so no need to run samtools collate . Answer The commands would be: samtools fixmate (with the -m option) samtools sort samtools markdup Exercise: Run the three commands that are required to mark duplicates. Answer cd ~/workdir/alignment samtools fixmate -m mother.bam mother.fixmate.bam samtools sort -o mother.positionsort.bam mother.fixmate.bam samtools markdup mother.positionsort.bam mother.markdup.bam Exercise: Run samtools flagstat on the alignment file with marked duplicates. How many reads were marked as duplicate? Answer samtools flagstat mother.markdup.bam Gives: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 17329 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Which tells us that 17329 reads were marked as duplicate.","title":"1. Marking duplicates"},{"location":"day1/alignment_advanced/#2-adding-read-groups","text":"For variant analysis, it\u2019s important to know which read came from which sample. Right now, that\u2019s easy. All reads come from one individual. But this can become less trivial if you are combining samples. Therefore we add a tag to each read specifying its origin. You can add a readgroup to your marked alignment file like this: samtools addreplacerg \\ -r ID:mother \\ -r SM:mother \\ -r PL:ILLUMINA \\ mother.markdup.bam \\ > mother.markdup.rg.bam This command modifies the sam header and read tags. Exercise: Run the samtools addreplacerg command and compare the header and first alignments of mother.markdup.bam and mother.markdup.rg.bam . Notice any differences? Hint You can view the header with samtools view -H <alignment.bam> And the first few alignments with samtools view <alignment.bam> | head Answer Compared to the header of mother.markdup.bam , the header of mother.markdup.rg.bam contains two extra lines starting with @PG and @RG respectively: @PG ID:samtools.4 PN:samtools PP:samtools.3 VN:1.11 CL:samtools addreplacerg -r ID:mother -r SM:mother -r PL:ILLUMINA mother.markdup.bam @RG ID:mother SM:mother PL:ILLUMINA Here, the @PG lines tell you which commands have been run on this alignment file. The @RG line defines the readgroups present in the alignment file. In the alignment records, a tag was added at the very end of each line: RG:Z:mother .","title":"2. Adding read groups"},{"location":"day1/alignment_advanced/#3-indexing","text":"To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools index mother.markdup.rg.bam","title":"3. Indexing"},{"location":"day1/alignment_advanced/#4-piping-and-looping","text":"Samtools can quite easily be used in a UNIX pipeline. This has the advantage that you don\u2019t need to write many intermediate files. However, the developers have not been very consistent with managing input and output (I\u2019m sure they had their reasons). To use samtools in a pipe, the input argument needs to replaced with a - . Also, some commands do not write by default to stdout, but to a specified file (this is the case for e.g. samtools fixmate and samtools markdup ). In that case, also the output argument should be replaced with - . Example For the command samtools addreplacerg the samtools documentation provides the following synopsis: samtools addreplacerg [-r rg-line | -R rg-ID] [-m mode] [-l level] [-o out.bam] in.bam Meaning that it requires in.bam , and can write to out.bam if option -o is provided. By default, it writes to stdout. So, if you pipe to samtools addreplacerg you would only need to replace the input file with a - : some_command | samtools addreplacerg [ options ] - > output.sam For the command samtools fixmate , the samtools documentation provides this synopsis: samtools fixmate [-rpcm] [-O format] in.nameSrt.bam out.bam Meaning that it requires both the input file in.nameSrt.bam and the output file out.bam . So, if you pipe to samtools fixmate and you want to write to stdout (so piping from), you\u2019ll need to replace both the input and output with a - : some_command | samtools fixmate [ options ] - - > output.sam The most frequently used samtools commands don\u2019t require an input nor an output file, and therefore behave like many UNIX commands. An example of this is samtools sort . The synopsis is: samtools sort [-l level] [-m maxMem] [-o out.bam] [-O format] [-n] [-t tag] [-T tmpprefix] [-@ threads] [in.sam|in.bam|in.cram] Telling us that both the input file and output (with option -o ) file are optional. If the input file is absent, it reads from stdin. So, you could use it without a - replacing input or output files: some_command | samtools sort > output.sam Let\u2019s put everything we\u2019ve done so far in a pipe and loop over our three samples. The command below loops over the strings father , mother and son , and: performs the alignment marks duplicates adds readgroups compresses the output creates an index #!/usr/bin/env bash cd ~/workdir for sample in mother father son do bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz \\ | samtools fixmate -m - - \\ | samtools sort \\ | samtools markdup -s - - \\ | samtools addreplacerg -r ID: $sample -r SM: $sample -r PL:ILLUMINA - \\ | samtools view -bh > alignment/ $sample .bam samtools index alignment/ $sample .bam done Exercise: Try to understand what each line of this script does. After that, run it to get the alignments of all three samples.","title":"4. Piping and looping"},{"location":"day1/introduction/","text":"Material Course introduction: Download the presentation Introduction to variant analysis: Download the presentation","title":"Introduction"},{"location":"day1/introduction/#material","text":"Course introduction: Download the presentation Introduction to variant analysis: Download the presentation","title":"Material"},{"location":"day1/server_login/","text":"In this part we will set up your computer to work on the remote AWS server or with Docker (choose Docker if you are doing this course independently). mac OS/Linux Material You have received an e-mail shortly before the workshop with a key, username and IP address to login on a cloud server. Below you can find the material that helps you to login, edit scripts and transfer files. Great power comes with great responsibility The cloud server is a temporary instance for this workshop only. Although the computational resources should be more than enough, it\u2019s a basic Ubuntu server, and there are no hard limits on memory or CPU usage. Take therefore into account that great power comes with great responsibility. Overloading it can result in a reboot, cancelling all running calculations. Video tutorials Set up ftp-remote-edit for Atom Set up FileZilla Exercises Login to AWS EC2 remote server In this part, we\u2019ll use the video tutorials and the information below to log in and set up a remote script editor. Open a terminal and login like this: ssh -i path/to/key/key_<username>.pem <username>@<IP> Warning change path/to/key to the actual path where you have put the key file. replace and with your actual username and IP Setup your Atom and FileZilla Atom Atom is a versatile text editor for all major operating systems. For this course, it\u2019s the recommended script editor for Linux and Mac OS users. With the third-party package ftp-remote-edit , you can remotely edit scripts. Set it up on your own computer using your own credentials and the video below. In general, setup the connection to the server with the following details: protocol: sftp username: your username hostname: server IP port: 22 authentication/logon type: path to private key file FileZilla Many results come in an image (e.g. .png , .jpg ) or html format. These can not be viewed directly from the server. Also, for this course, files loaded in IGV need to be on your local computer. You can easily transfer files between your local PC and the remote host with FileZilla . Set it up on your own computer using your own credentials and the video below. Initiate conda To make use of the pre-installed software with conda, we need to initiate it first. Login to the server and run: /opt/miniconda3/bin/conda init exec bash Now, your shell should start with (base) , meaning that the conda base environment is loaded. To load the environment variants with the required software packages, run: conda activate variants Which should change the start of your shell from (base) to (variants) Activating the environment You will need to activate the variants environment each time you login. Windows Material You have received an e-mail shortly before the workshop with a key, username and IP address to login on a cloud server. Below you can find the material that helps you to login, edit scripts and transfer files. Great power comes with great responsibility The cloud server is a temporary instance for this workshop only. Although the computational resources should be more than enough, it\u2019s a basic Ubuntu server, and there are no hard limits on memory or CPU usage. Take therefore into account that great power comes with great responsibility. Overloading it can result in a reboot, cancelling all running calculations. Video tutorials Set up MobaXterm Set up FileZilla Exercises Set up MobaXterm In this part, you will use the video tutorials and the information below to log in and set up a remote script editor. MobaXterm is an SSH client for Windows. Use this to connect to the remote host and edit remote scripts. With MobaXterm, you will automatically login to the remote server once you\u2019ve started the SSH session. Set it up on your own computer using your own credentials and the video below. These are the general settings you should take into account: protocol: sftp username: your username hostname: server IP port: 22 authentication/logon type: path to private key file Set up FileZilla Many results come in an image (e.g. .png , .jpg ) or html format. These can not be viewed directly from the server. Also, for this course, files loaded in IGV need to be on your local computer. You can easily transfer files between your local PC and the remote host with FileZilla . Set it up on your own computer using your own credentials and the video below. Initiate conda To make use of the pre-installed software with conda, we need to initiate it first. Login to the server and run: /opt/miniconda3/bin/conda init exec bash Now, your shell should start with (base) , meaning that the conda base environment is loaded. To load the environment variants with the required software packages, run: conda activate variants Which should change the start of your shell from (base) to (variants) Activating the environment You will need to activate the variants environment each time you login. Docker Material Instructions to install docker Instructions to set up to container Exercises First login Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. The command to run the environment required for this course looks like this (in a terminal or powershell): Modify the script Modify the path after -v to the working directory on your computer before running it. Mac OS/Linux terminal docker run \\ -v /full/path/to/local/workdir:/root/workdir \\ -i -t \\ geertvangeest/ngs-variants \\ /bin/bash Windows powershell docker run ` -v C : \\ Users \\ myusername : / root / workdir ` -i -t ` geertvangeest / ngs-variants ` / bin / bash The option -v mounts a local directory in your computer to the directory /root/workdir in the docker container. In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. edit scripts and visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The options -i and -t let you approach the container interactively. Meaning that you can use the shell. The part geertvangeest/ngs-intro is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. The last bit /bin/bash tells us which entrypoint we take. Which is the bash command line interpreter. You can exit the shell with exit . Working with a running container Restarting After exiting, you can restart the container. Find the container name: docker container ls -a The name is e.g. adoring_bell . To restart run: docker start adoring_bell docker attach adoring_bell Second shell If you want to have a second shell in your container, e.g. because your current shell is busy, you can use: docker exec -it adoring_bell /bin/bash Difference docker attach and docker exec Difference between the commands is explainer here . Conclusion: do not run docker attach for a second shell in which you usually want to start a new process. Lost the container If you lost the container for whatever reason, no problem. If you did all your work in the mounted workdir, you can just remount it to a new container based on the same image. To do that, just rerun the docker run command (with the option -v , -i , -t and the entrypoint). Save your own version If you have additional installations, and you want to keep them, you can save the image with: docker commit adoring_bell my-image Use conda If you are in the container with shell, you can load the environment with the required software packages: conda activate variants Activating the environment You will need to activate the ngs environment each time you login. A UNIX command line interface (CLI) refresher Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory. Make a new directory Login to the server and use the command line to make a directory called workdir . If working with Docker If your are working with docker you are a root user. This means that your \u201chome\u201d directory is the root directory, i.e. /root , and not /home/username . If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts File permissions Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer You can use your remote script editor to edit your script. Otherwise you can use nano to edit it: nano new_script.sh The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here . Redirection: > and | In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory (use ls and > ). Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l Variables Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE shell scripts Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l 3. Loops 20 minutes If you want to run the same command on a range of arguments, it\u2019s not very convenient to type the command for each individual argument. For example, you could write dog , fox , bird to stdout in a script like this: #!/usr/bin/env bash echo dog echo fox echo bird However, if you want to change the command (add an option for example), you would have to change it for all the three command calls. Amongst others for that reason, you want to write the command only once. You can do this with a for-loop, like this: #!/usr/bin/env bash ANIMALS = \"dog fox bird\" for animal in $ANIMALS do echo $animal done Which results in: cat dog bird Write a shell script that removes all the letters \u201ce\u201d from a list of words. Hint Removing the letter \u201ce\u201d from a string can be done with tr like this: word = \"test\" echo $word | tr -d \"e\" Which would result in: tst Answer Your script should e.g. look like this (I\u2019ve added some awesome functionality): #!/usr/bin/env bash WORDLIST = \"here is a list of words resulting in a sentence\" for word in $WORDLIST do echo \"' $word ' with e's removed looks like:\" echo $word | tr -d \"e\" done resulting in: 'here' with e's removed looks like: hr 'is' with e's removed looks like: is 'a' with e's removed looks like: a 'list' with e's removed looks like: list 'of' with e's removed looks like: of 'words' with e's removed looks like: words 'resulting' with e's removed looks like: rsulting 'in' with e's removed looks like: in 'a' with e's removed looks like: a 'sentence' with e's removed looks like: sntnc","title":"Server login"},{"location":"day1/server_login/#material","text":"You have received an e-mail shortly before the workshop with a key, username and IP address to login on a cloud server. Below you can find the material that helps you to login, edit scripts and transfer files. Great power comes with great responsibility The cloud server is a temporary instance for this workshop only. Although the computational resources should be more than enough, it\u2019s a basic Ubuntu server, and there are no hard limits on memory or CPU usage. Take therefore into account that great power comes with great responsibility. Overloading it can result in a reboot, cancelling all running calculations.","title":"Material"},{"location":"day1/server_login/#video-tutorials","text":"Set up ftp-remote-edit for Atom Set up FileZilla","title":"Video tutorials"},{"location":"day1/server_login/#exercises","text":"","title":"Exercises"},{"location":"day1/server_login/#login-to-aws-ec2-remote-server","text":"In this part, we\u2019ll use the video tutorials and the information below to log in and set up a remote script editor. Open a terminal and login like this: ssh -i path/to/key/key_<username>.pem <username>@<IP> Warning change path/to/key to the actual path where you have put the key file. replace and with your actual username and IP","title":"Login to AWS EC2 remote server"},{"location":"day1/server_login/#setup-your-atom-and-filezilla","text":"","title":"Setup your Atom and FileZilla"},{"location":"day1/server_login/#atom","text":"Atom is a versatile text editor for all major operating systems. For this course, it\u2019s the recommended script editor for Linux and Mac OS users. With the third-party package ftp-remote-edit , you can remotely edit scripts. Set it up on your own computer using your own credentials and the video below. In general, setup the connection to the server with the following details: protocol: sftp username: your username hostname: server IP port: 22 authentication/logon type: path to private key file","title":"Atom"},{"location":"day1/server_login/#filezilla","text":"Many results come in an image (e.g. .png , .jpg ) or html format. These can not be viewed directly from the server. Also, for this course, files loaded in IGV need to be on your local computer. You can easily transfer files between your local PC and the remote host with FileZilla . Set it up on your own computer using your own credentials and the video below.","title":"FileZilla"},{"location":"day1/server_login/#initiate-conda","text":"To make use of the pre-installed software with conda, we need to initiate it first. Login to the server and run: /opt/miniconda3/bin/conda init exec bash Now, your shell should start with (base) , meaning that the conda base environment is loaded. To load the environment variants with the required software packages, run: conda activate variants Which should change the start of your shell from (base) to (variants) Activating the environment You will need to activate the variants environment each time you login. Windows","title":"Initiate conda"},{"location":"day1/server_login/#material_1","text":"You have received an e-mail shortly before the workshop with a key, username and IP address to login on a cloud server. Below you can find the material that helps you to login, edit scripts and transfer files. Great power comes with great responsibility The cloud server is a temporary instance for this workshop only. Although the computational resources should be more than enough, it\u2019s a basic Ubuntu server, and there are no hard limits on memory or CPU usage. Take therefore into account that great power comes with great responsibility. Overloading it can result in a reboot, cancelling all running calculations.","title":"Material"},{"location":"day1/server_login/#video-tutorials_1","text":"Set up MobaXterm Set up FileZilla","title":"Video tutorials"},{"location":"day1/server_login/#exercises_1","text":"","title":"Exercises"},{"location":"day1/server_login/#set-up-mobaxterm","text":"In this part, you will use the video tutorials and the information below to log in and set up a remote script editor. MobaXterm is an SSH client for Windows. Use this to connect to the remote host and edit remote scripts. With MobaXterm, you will automatically login to the remote server once you\u2019ve started the SSH session. Set it up on your own computer using your own credentials and the video below. These are the general settings you should take into account: protocol: sftp username: your username hostname: server IP port: 22 authentication/logon type: path to private key file","title":"Set up MobaXterm"},{"location":"day1/server_login/#set-up-filezilla","text":"Many results come in an image (e.g. .png , .jpg ) or html format. These can not be viewed directly from the server. Also, for this course, files loaded in IGV need to be on your local computer. You can easily transfer files between your local PC and the remote host with FileZilla . Set it up on your own computer using your own credentials and the video below.","title":"Set up FileZilla"},{"location":"day1/server_login/#initiate-conda_1","text":"To make use of the pre-installed software with conda, we need to initiate it first. Login to the server and run: /opt/miniconda3/bin/conda init exec bash Now, your shell should start with (base) , meaning that the conda base environment is loaded. To load the environment variants with the required software packages, run: conda activate variants Which should change the start of your shell from (base) to (variants) Activating the environment You will need to activate the variants environment each time you login. Docker","title":"Initiate conda"},{"location":"day1/server_login/#material_2","text":"Instructions to install docker Instructions to set up to container","title":"Material"},{"location":"day1/server_login/#exercises_2","text":"","title":"Exercises"},{"location":"day1/server_login/#first-login","text":"Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. The command to run the environment required for this course looks like this (in a terminal or powershell): Modify the script Modify the path after -v to the working directory on your computer before running it. Mac OS/Linux terminal docker run \\ -v /full/path/to/local/workdir:/root/workdir \\ -i -t \\ geertvangeest/ngs-variants \\ /bin/bash Windows powershell docker run ` -v C : \\ Users \\ myusername : / root / workdir ` -i -t ` geertvangeest / ngs-variants ` / bin / bash The option -v mounts a local directory in your computer to the directory /root/workdir in the docker container. In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. edit scripts and visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The options -i and -t let you approach the container interactively. Meaning that you can use the shell. The part geertvangeest/ngs-intro is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. The last bit /bin/bash tells us which entrypoint we take. Which is the bash command line interpreter. You can exit the shell with exit .","title":"First login"},{"location":"day1/server_login/#working-with-a-running-container","text":"","title":"Working with a running container"},{"location":"day1/server_login/#restarting","text":"After exiting, you can restart the container. Find the container name: docker container ls -a The name is e.g. adoring_bell . To restart run: docker start adoring_bell docker attach adoring_bell","title":"Restarting"},{"location":"day1/server_login/#second-shell","text":"If you want to have a second shell in your container, e.g. because your current shell is busy, you can use: docker exec -it adoring_bell /bin/bash Difference docker attach and docker exec Difference between the commands is explainer here . Conclusion: do not run docker attach for a second shell in which you usually want to start a new process.","title":"Second shell"},{"location":"day1/server_login/#lost-the-container","text":"If you lost the container for whatever reason, no problem. If you did all your work in the mounted workdir, you can just remount it to a new container based on the same image. To do that, just rerun the docker run command (with the option -v , -i , -t and the entrypoint).","title":"Lost the container"},{"location":"day1/server_login/#save-your-own-version","text":"If you have additional installations, and you want to keep them, you can save the image with: docker commit adoring_bell my-image","title":"Save your own version"},{"location":"day1/server_login/#use-conda","text":"If you are in the container with shell, you can load the environment with the required software packages: conda activate variants Activating the environment You will need to activate the ngs environment each time you login.","title":"Use conda"},{"location":"day1/server_login/#a-unix-command-line-interface-cli-refresher","text":"Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory.","title":"A UNIX command line interface (CLI) refresher"},{"location":"day1/server_login/#make-a-new-directory","text":"Login to the server and use the command line to make a directory called workdir . If working with Docker If your are working with docker you are a root user. This means that your \u201chome\u201d directory is the root directory, i.e. /root , and not /home/username . If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts","title":"Make a new directory"},{"location":"day1/server_login/#file-permissions","text":"Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer You can use your remote script editor to edit your script. Otherwise you can use nano to edit it: nano new_script.sh The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here .","title":"File permissions"},{"location":"day1/server_login/#redirection-and","text":"In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory (use ls and > ). Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l","title":"Redirection: &gt; and |"},{"location":"day1/server_login/#variables","text":"Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE","title":"Variables"},{"location":"day1/server_login/#shell-scripts","text":"Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l","title":"shell scripts"},{"location":"day1/server_login/#3-loops","text":"20 minutes If you want to run the same command on a range of arguments, it\u2019s not very convenient to type the command for each individual argument. For example, you could write dog , fox , bird to stdout in a script like this: #!/usr/bin/env bash echo dog echo fox echo bird However, if you want to change the command (add an option for example), you would have to change it for all the three command calls. Amongst others for that reason, you want to write the command only once. You can do this with a for-loop, like this: #!/usr/bin/env bash ANIMALS = \"dog fox bird\" for animal in $ANIMALS do echo $animal done Which results in: cat dog bird Write a shell script that removes all the letters \u201ce\u201d from a list of words. Hint Removing the letter \u201ce\u201d from a string can be done with tr like this: word = \"test\" echo $word | tr -d \"e\" Which would result in: tst Answer Your script should e.g. look like this (I\u2019ve added some awesome functionality): #!/usr/bin/env bash WORDLIST = \"here is a list of words resulting in a sentence\" for word in $WORDLIST do echo \"' $word ' with e's removed looks like:\" echo $word | tr -d \"e\" done resulting in: 'here' with e's removed looks like: hr 'is' with e's removed looks like: is 'a' with e's removed looks like: a 'list' with e's removed looks like: list 'of' with e's removed looks like: of 'words' with e's removed looks like: words 'resulting' with e's removed looks like: rsulting 'in' with e's removed looks like: in 'a' with e's removed looks like: a 'sentence' with e's removed looks like: sntnc","title":"3. Loops"},{"location":"day2/annotation/","text":"Material Download the presentation Exercises To use the human genome is a reference, we have downloaded the database with: No need to download, it\u2019s already downloaded for you # don't run this. It's already downloaded for you snpEff download -v GRCh38.99 You can run snpEff like so: snpEff -Xmx4g \\ -v \\ -o gatk \\ GRCh38.99 \\ variants/trio.filtered.vcf > annotation/trio.filtered.snpeff.vcf Output -o gatk is deprecated for gatk4 Here, we use output -o gatk for readability reasons (only one effect per variant is reported). With gatk3 you could use gatk VariantAnnotator with input from snpEff . In gatk4 that is not supported anymore. Exercise: Run the command, and check out the html file ( snpEff_summary.html ). Try to answer these questions: A. How many effects were calculated? B. How many variants are in the vcf? C. Why is this different? D. How many effects result in a missense mutation? Answer A. There were 10,357 effects calculated. B. There are only 556 variants in the vcf. C. This means that there are multiple effects per variant. snpEff calculates effects for each splice variant, and therefore the number of effects are a multitude of the number of variants. D. Two effects result in a missense mutation. You can (quick and dirty) query the annotation vcf ( trio.filtered.snpeff.vcf ) for the missense mutation with grep . Exercise: Find the variant causing the missense mutation (the line contains the string MISSENSE ). And answer the following questions: Hint grep MISSENSE annotation/trio.filtered.snpeff.vcf Only one effect per SNP in the vcf In the vcf we have created you can only find one effect per SNP. If you would run snpEff without -o gatk , you would get all effects per variant. A. How are the SNP annotations stored in the vcf? B. What are the genotypes of the individuals? C. Which amino acid change does it cause? Answer Find the line with the missense mutation like this: grep MISSENSE annotation/trio.filtered.snpeff.vcf This results in (long line, scroll to the right to see more): chr20 10049540 . T A 220.29 PASS AC=1;AF=0.167;AN=6;BaseQRankSum=-6.040e-01;DP=85;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=0.00;QD=8.16;ReadPosRankSum=0.226;SOR=0.951;EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|cTg/cAg|L324Q|ANKEF1|protein_coding|CODING|ENST00000378392|7) GT:AD:DP:GQ:PL 0/0:34,0:34:99:0,102,1163 0/1:17,10:27:99:229,0,492 0/0:24,0:24:72:0,72,811 A. SNP annotations are stored in the INFO field, starting with EFF= B. The genotypes are homozygous reference for the father and son, and heterozygous for the mother. (find the order of the samples with grep ^#CHROM ) C. The triplet changes from cTg to cAg, resulting in a change from L (Leucine) to Q (Glutamine).","title":"Annotation"},{"location":"day2/annotation/#material","text":"Download the presentation","title":"Material"},{"location":"day2/annotation/#exercises","text":"To use the human genome is a reference, we have downloaded the database with: No need to download, it\u2019s already downloaded for you # don't run this. It's already downloaded for you snpEff download -v GRCh38.99 You can run snpEff like so: snpEff -Xmx4g \\ -v \\ -o gatk \\ GRCh38.99 \\ variants/trio.filtered.vcf > annotation/trio.filtered.snpeff.vcf Output -o gatk is deprecated for gatk4 Here, we use output -o gatk for readability reasons (only one effect per variant is reported). With gatk3 you could use gatk VariantAnnotator with input from snpEff . In gatk4 that is not supported anymore. Exercise: Run the command, and check out the html file ( snpEff_summary.html ). Try to answer these questions: A. How many effects were calculated? B. How many variants are in the vcf? C. Why is this different? D. How many effects result in a missense mutation? Answer A. There were 10,357 effects calculated. B. There are only 556 variants in the vcf. C. This means that there are multiple effects per variant. snpEff calculates effects for each splice variant, and therefore the number of effects are a multitude of the number of variants. D. Two effects result in a missense mutation. You can (quick and dirty) query the annotation vcf ( trio.filtered.snpeff.vcf ) for the missense mutation with grep . Exercise: Find the variant causing the missense mutation (the line contains the string MISSENSE ). And answer the following questions: Hint grep MISSENSE annotation/trio.filtered.snpeff.vcf Only one effect per SNP in the vcf In the vcf we have created you can only find one effect per SNP. If you would run snpEff without -o gatk , you would get all effects per variant. A. How are the SNP annotations stored in the vcf? B. What are the genotypes of the individuals? C. Which amino acid change does it cause? Answer Find the line with the missense mutation like this: grep MISSENSE annotation/trio.filtered.snpeff.vcf This results in (long line, scroll to the right to see more): chr20 10049540 . T A 220.29 PASS AC=1;AF=0.167;AN=6;BaseQRankSum=-6.040e-01;DP=85;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=0.00;QD=8.16;ReadPosRankSum=0.226;SOR=0.951;EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|cTg/cAg|L324Q|ANKEF1|protein_coding|CODING|ENST00000378392|7) GT:AD:DP:GQ:PL 0/0:34,0:34:99:0,102,1163 0/1:17,10:27:99:229,0,492 0/0:24,0:24:72:0,72,811 A. SNP annotations are stored in the INFO field, starting with EFF= B. The genotypes are homozygous reference for the father and son, and heterozygous for the mother. (find the order of the samples with grep ^#CHROM ) C. The triplet changes from cTg to cAg, resulting in a change from L (Leucine) to Q (Glutamine).","title":"Exercises"},{"location":"day2/filtering_evaluation/","text":"Exercises 1. Hard filtering The developers of gatk strongly advise to do Variant Quality Score Recalibration (VQSR) for filtering SNPs and INDELs. However, this is not always possible. For example, in the case of limited data availability and/or in the case you are working with non-model organisms and/or in the case you are a bit lazy and okay with a number of false positives. Our dataset is too small to apply VQSR. We will therefore do hard filtering instead. Splitting SNPs and INDELs First, filtering thresholds are usually different for SNPs and INDELs. You can extract all the SNP records in our trio vcf like this: cd ~/workdir gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type SNP \\ --output variants/trio.SNP.vcf Exercise: Check out the documentation of gatk SelectVariants , and: Figure out what you\u2019ll need to fill in at --select-type if you want to select only INDELS. Generate a vcf with only the SNPs and a second vcf with only the INDELs from trio.vcf . Answer You will need to fill in INDEL at --select-type to filter for INDELs. To get the SNPs you can run the command above. To get the INDELs you\u2019ll need to change --select-type to INDEL : gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type INDEL \\ --output variants/trio.INDEL.vcf Filtering SNPs The command gatk VariantFiltration enables you to filter for both the INFO field (per variant) and FORMAT field (per genotype). For now we\u2019re only interested in filtering variants. Below you can find the command to hard-filter the SNP variants on some sensible thresholds (that are explained here ). gatk VariantFiltration \\ --variant variants/trio.SNP.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"SOR > 3.0\" --filter-name \"SOR3\" \\ --filter-expression \"FS > 60.0\" --filter-name \"FS60\" \\ --filter-expression \"MQ < 40.0\" --filter-name \"MQ40\" \\ --filter-expression \"MQRankSum < -12.5\" --filter-name \"MQRankSum-12.5\" \\ --filter-expression \"ReadPosRankSum < -8.0\" --filter-name \"ReadPosRankSum-8\" \\ --output variants/trio.SNP.filtered.vcf Exercise: Run the filtering command above. Did it affect the number of records in the vcf? Hint You can check out the number of records in a vcf with: grep -v \"^#\" <variants.vcf> | wc -l Answer There are no differences in the number of records: grep -v \"^#\" variants/trio.SNP.vcf | wc -l and grep -v \"^#\" variants/trio.SNP.filtered.vcf | wc -l both give 446. However, there are SNPs filtered out, by changing the FILTER column. You can check the number of records with PASS by: grep -v \"^#\" variants/trio.SNP.filtered.vcf | cut -f 7 | sort | uniq -c Giving: 441 PASS 2 QD2;SOR3 3 SOR3 Filtering INDELs A command with sensible parameters to do a first iteration of hard filtering the INDELs would be: gatk VariantFiltration \\ --variant variants/trio.INDEL.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"FS > 200.0\" --filter-name \"FS200\" \\ --filter-expression \"ReadPosRankSum < -20.0\" --filter-name \"ReadPosRankSum-20\" \\ --output variants/trio.INDEL.filtered.vcf Exercise: Run the command and figure out how many variants are filtered out. Hint You can use this command from the answer to the previous exercise: grep -v \"^#\" <variants.vcf> | cut -f 7 | sort | uniq -c to see how many INDELs were filtered out. Answer grep -v \"^#\" variants/trio.INDEL.filtered.vcf | cut -f 7 | sort | uniq -c gives: 110 PASS So no variants are filtered out. Merging filtered SNPs and INDELs Now that we have filtered the INDELs and SNPs separately, we can merge them again with this command: gatk MergeVcfs \\ --INPUT variants/trio.SNP.filtered.vcf \\ --INPUT variants/trio.INDEL.filtered.vcf \\ --OUTPUT variants/trio.filtered.vcf Exercise: Run the command to merge the vcfs. 2. Evaluation by concordance For this region we have a highly curated truth set for the mother available. It originates from the Illumina Platinum truth set . You can find it at variants/NA12878.vcf.gz To check how well we did, we\u2019d first need to extract a vcf with only the information of the mother. Exercise: To extract variants that have at least one alternative allele in the mother from variants/trio.filtered.vcf , use gatk SelectVariants with the arguments: --sample-name mother --exclude-non-variants --remove-unused-alternates In addition to the required arguments. Answer gatk SelectVariants \\ --variant variants/trio.filtered.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --output variants/mother.trio.filtered.vcf Exercise: A. How many variants are in mother.trio.filtered.vcf ? How many of those are filtered out? B. Compare our vcf with the curated truth set with the command below. How many SNPs didn\u2019t we detect? gatk Concordance \\ --evaluation variants/mother.trio.filtered.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio.filtered Answer To get the number of records per FILTER, we run: grep -v \"^#\" variants/mother.trio.filtered.vcf | cut -f 7 | sort | uniq -c gives: 407 PASS 2 SOR3 So two records were filtered out, based on the Symmetric Odds Ratio (issues with strand bias). Check out the output of gatk Concordance with cat : cat variants/concordance.mother.trio.filtered gives: type TP FP FN RECALL PRECISION SNP 319 5 9 0.973 0.985 INDEL 63 20 6 0.913 0.759 Showing that there were 9 false negatives, i.e. SNPs we didn\u2019t detect. Recall & precision More info on the definition of recall and precision on this wikipedia page Exercise: Check out the concordance of the mother with the truth set before filtering. Did filtering improve the recall or precision? Note We did the filtering on trio.vcf , therefore, you first have to extract the records that only apply to the mother by using gatk SelectVariants . Also note that trio.vcf contains records other than SNPs and INDELs. Use --select-type to select only SNPs and INDELs. Answer First select only SNPs and INDELs from the mother from the unfiltered vcf: gatk SelectVariants \\ --variant variants/trio.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --select-type INDEL \\ --select-type SNP \\ --output variants/mother.trio.vcf Get the concordance with the truth set: gatk Concordance \\ --evaluation variants/mother.trio.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio Which gives: type TP FP FN RECALL PRECISION SNP 319 7 9 0.973 0.979 INDEL 63 20 6 0.913 0.759 The precision for SNPs is slightly lower. Due to filtering, we removed two false positives.","title":"Filtering & evaluation"},{"location":"day2/filtering_evaluation/#exercises","text":"","title":"Exercises"},{"location":"day2/filtering_evaluation/#1-hard-filtering","text":"The developers of gatk strongly advise to do Variant Quality Score Recalibration (VQSR) for filtering SNPs and INDELs. However, this is not always possible. For example, in the case of limited data availability and/or in the case you are working with non-model organisms and/or in the case you are a bit lazy and okay with a number of false positives. Our dataset is too small to apply VQSR. We will therefore do hard filtering instead.","title":"1. Hard filtering"},{"location":"day2/filtering_evaluation/#splitting-snps-and-indels","text":"First, filtering thresholds are usually different for SNPs and INDELs. You can extract all the SNP records in our trio vcf like this: cd ~/workdir gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type SNP \\ --output variants/trio.SNP.vcf Exercise: Check out the documentation of gatk SelectVariants , and: Figure out what you\u2019ll need to fill in at --select-type if you want to select only INDELS. Generate a vcf with only the SNPs and a second vcf with only the INDELs from trio.vcf . Answer You will need to fill in INDEL at --select-type to filter for INDELs. To get the SNPs you can run the command above. To get the INDELs you\u2019ll need to change --select-type to INDEL : gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type INDEL \\ --output variants/trio.INDEL.vcf","title":"Splitting SNPs and INDELs"},{"location":"day2/filtering_evaluation/#filtering-snps","text":"The command gatk VariantFiltration enables you to filter for both the INFO field (per variant) and FORMAT field (per genotype). For now we\u2019re only interested in filtering variants. Below you can find the command to hard-filter the SNP variants on some sensible thresholds (that are explained here ). gatk VariantFiltration \\ --variant variants/trio.SNP.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"SOR > 3.0\" --filter-name \"SOR3\" \\ --filter-expression \"FS > 60.0\" --filter-name \"FS60\" \\ --filter-expression \"MQ < 40.0\" --filter-name \"MQ40\" \\ --filter-expression \"MQRankSum < -12.5\" --filter-name \"MQRankSum-12.5\" \\ --filter-expression \"ReadPosRankSum < -8.0\" --filter-name \"ReadPosRankSum-8\" \\ --output variants/trio.SNP.filtered.vcf Exercise: Run the filtering command above. Did it affect the number of records in the vcf? Hint You can check out the number of records in a vcf with: grep -v \"^#\" <variants.vcf> | wc -l Answer There are no differences in the number of records: grep -v \"^#\" variants/trio.SNP.vcf | wc -l and grep -v \"^#\" variants/trio.SNP.filtered.vcf | wc -l both give 446. However, there are SNPs filtered out, by changing the FILTER column. You can check the number of records with PASS by: grep -v \"^#\" variants/trio.SNP.filtered.vcf | cut -f 7 | sort | uniq -c Giving: 441 PASS 2 QD2;SOR3 3 SOR3","title":"Filtering SNPs"},{"location":"day2/filtering_evaluation/#filtering-indels","text":"A command with sensible parameters to do a first iteration of hard filtering the INDELs would be: gatk VariantFiltration \\ --variant variants/trio.INDEL.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"FS > 200.0\" --filter-name \"FS200\" \\ --filter-expression \"ReadPosRankSum < -20.0\" --filter-name \"ReadPosRankSum-20\" \\ --output variants/trio.INDEL.filtered.vcf Exercise: Run the command and figure out how many variants are filtered out. Hint You can use this command from the answer to the previous exercise: grep -v \"^#\" <variants.vcf> | cut -f 7 | sort | uniq -c to see how many INDELs were filtered out. Answer grep -v \"^#\" variants/trio.INDEL.filtered.vcf | cut -f 7 | sort | uniq -c gives: 110 PASS So no variants are filtered out.","title":"Filtering INDELs"},{"location":"day2/filtering_evaluation/#merging-filtered-snps-and-indels","text":"Now that we have filtered the INDELs and SNPs separately, we can merge them again with this command: gatk MergeVcfs \\ --INPUT variants/trio.SNP.filtered.vcf \\ --INPUT variants/trio.INDEL.filtered.vcf \\ --OUTPUT variants/trio.filtered.vcf Exercise: Run the command to merge the vcfs.","title":"Merging filtered SNPs and INDELs"},{"location":"day2/filtering_evaluation/#2-evaluation-by-concordance","text":"For this region we have a highly curated truth set for the mother available. It originates from the Illumina Platinum truth set . You can find it at variants/NA12878.vcf.gz To check how well we did, we\u2019d first need to extract a vcf with only the information of the mother. Exercise: To extract variants that have at least one alternative allele in the mother from variants/trio.filtered.vcf , use gatk SelectVariants with the arguments: --sample-name mother --exclude-non-variants --remove-unused-alternates In addition to the required arguments. Answer gatk SelectVariants \\ --variant variants/trio.filtered.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --output variants/mother.trio.filtered.vcf Exercise: A. How many variants are in mother.trio.filtered.vcf ? How many of those are filtered out? B. Compare our vcf with the curated truth set with the command below. How many SNPs didn\u2019t we detect? gatk Concordance \\ --evaluation variants/mother.trio.filtered.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio.filtered Answer To get the number of records per FILTER, we run: grep -v \"^#\" variants/mother.trio.filtered.vcf | cut -f 7 | sort | uniq -c gives: 407 PASS 2 SOR3 So two records were filtered out, based on the Symmetric Odds Ratio (issues with strand bias). Check out the output of gatk Concordance with cat : cat variants/concordance.mother.trio.filtered gives: type TP FP FN RECALL PRECISION SNP 319 5 9 0.973 0.985 INDEL 63 20 6 0.913 0.759 Showing that there were 9 false negatives, i.e. SNPs we didn\u2019t detect. Recall & precision More info on the definition of recall and precision on this wikipedia page Exercise: Check out the concordance of the mother with the truth set before filtering. Did filtering improve the recall or precision? Note We did the filtering on trio.vcf , therefore, you first have to extract the records that only apply to the mother by using gatk SelectVariants . Also note that trio.vcf contains records other than SNPs and INDELs. Use --select-type to select only SNPs and INDELs. Answer First select only SNPs and INDELs from the mother from the unfiltered vcf: gatk SelectVariants \\ --variant variants/trio.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --select-type INDEL \\ --select-type SNP \\ --output variants/mother.trio.vcf Get the concordance with the truth set: gatk Concordance \\ --evaluation variants/mother.trio.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio Which gives: type TP FP FN RECALL PRECISION SNP 319 7 9 0.973 0.979 INDEL 63 20 6 0.913 0.759 The precision for SNPs is slightly lower. Due to filtering, we removed two false positives.","title":"2. Evaluation by concordance"},{"location":"day2/variant_calling/","text":"Material Download the presentation GATK best practices germline short variant workflow : Exercises 1. Indexing, indexing, indexing Many algorithms work faster, or only work with an index of their (large) input files. In that sense, gatk is no different from other tools. The index for a reference needs to be created in two steps: cd ~/workdir/data/reference samtools faidx <reference.fa> gatk CreateSequenceDictionary --REFERENCE <reference.fa> Also input vcf files need to be indexed. This will create a .idx file associated with the .vcf . You can do this like this: gatk IndexFeatureFile --input <variants.vcf> Exercise: Create the required gatk indexes for: The reference genome reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa A part of the dbsnp database: variants/GCF.38.filtered.renamed.vcf A part of the 1000 genomes indel golden standard: variants/1000g_gold_standard.indels.filtered.vcf Answer Creating the index for the reference genome: cd ~/workdir/data samtools faidx reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa gatk CreateSequenceDictionary --REFERENCE reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa Creating the indices for the vcfs: gatk IndexFeatureFile --input variants/1000g_gold_standard.indels.filtered.vcf gatk IndexFeatureFile --input variants/GCF.38.filtered.renamed.vcf Chromosome names Unlike IGV, gatk requires equal chromosome names for all its input files and indexes, e.g. in .fasta , .bam and .vcf files. In general, for the human genome there are three types of chromosome names: Just a number, e.g. 20 Prefixed by chr . e.g. chr20 Refseq name, e.g. NC_000020.11 Before you start the alignment, it\u2019s wise to check out what chromosome naming your input files are using, because changing chromosome names in a .fasta file is easier than in a .bam file. If your fasta titles are e.g. starting with a number you can add chr to it with sed : sed s/^>/>chr/g <reference.fasta> You can change chromsome names in a vcf with bcftools annotate : bcftools annotate --rename-chrs <tab-delimited-renaming> <input.vcf> 2. Base Quality Score Recalibration (BQSR) BQSR evaluates the base qualities on systematic error. It can ignore sites with known variants. BQSR helps to identify faulty base calls, and therefore reduces the chance on discovering false positive variant positions. BQSR is done in two steps: Recalibration with gatk BaseRecalibrator By using the output of gatk BaseRecalibrator , the application to the bam file with gatk ApplyBQSR Exercise: Check out the documentation of the tools. Which options are required? Answer For gatk BaseRecalibrator : --reference --input --known-sites --output For gatk ApplyBQSR : --bqsr-recal-file --input --output Exercise: Run the two commands with the required options on mother.bam , with --known-sites variants/1000g_gold_standard.indels.filtered.vcf and variants/GCF.38.filtered.renamed.vcf . Multiple inputs for same argument In some cases you need to add multiple inputs (e.g. multiple vcf files) into the same argument (e.g. --known-sites ). To provide multiple inputs for the same argument in gatk , you can use the same argument multiple times, e.g.: gatk BaseRecalibrator \\ --reference <reference.fa> \\ --input <alignment.bam> \\ --known-sites <variants1.vcf> \\ --known-sites <variants2.vcf> \\ --output <output.table> Answer cd ~/workdir mkdir bqsr gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/mother.bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/mother.recal.table gatk ApplyBQSR \\ --input alignment/mother.bam \\ --bqsr-recal-file bqsr/mother.recal.table \\ --output bqsr/mother.recal.bam Exercise: Place these commands in a loop, that performs the BQSR for mother, father and son. Answer cd ~/workdir for sample in mother father son do gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/ $sample .bam \\ --known-sites variants/GCF.38.filtered.renamed.vcf \\ --known-sites variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/ $sample .recal.table gatk ApplyBQSR \\ --input alignment/ $sample .bam \\ --bqsr-recal-file bqsr/ $sample .recal.table \\ --output bqsr/ $sample .recal.bam done 3. Variant calling The command gatk HaplotypeCaller is the core command of gatk . It performs the actual variant calling. Exercise: Check out the gatk HaplotypeCaller documentation , and find out which arguments are required. Answer Required arguments are: --input --ouput --reference Exercise: Make a directory ~/workdir/variants to write the output vcf. After that, run gatk HaplotypeCaller with required options on the recalibrated alignment file of the mother ( bqsr/mother.recal.bam ). We\u2019ll focus on a small region, so add --intervals chr20:10018000-10220000 . Answer cd ~/workdir mkdir /variants gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/mother.recal.bam \\ --output variants/mother.HC.vcf \\ --intervals chr20:10018000-10220000 \\ We will do the variant calling on all three samples. Later we want to combine the variant calls. For efficient merging of vcfs, we will need to output the variants as a GVCF. To do that, we will use the option --emit-ref-confidence GVCF . Also, we\u2019ll visualise the haplotype phasing with IGV in the next section. For that we\u2019ll need a phased bam. You can get this output with the argument --bam-output . Exercise: Run gatk HaplotypeCaller for mother, father and son by using a loop, and by using the arguments in the previous exercise. On top of that add the arguments --emit-ref-confidence GVCF and --bamoutput <phased.bam> . Answer cd ~/workdir for sample in mother father son do gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/ $sample .recal.bam \\ --output variants/ $sample .HC.g.vcf \\ --bam-output variants/ $sample .phased.bam \\ --intervals chr20:10018000-10220000 \\ --emit-ref-confidence GVCF done 4. Combining GVCFs Now that we have all three GVCFs of the mother, father and son, we can combine them into a database. We do this because it enables us to later add GVCFs (with the option --genomicsdb-update-workspace-path ), and to efficiently combine them into a single vcf. You can generate a GenomicsDB on our three samples like this: gatk GenomicsDBImport \\ --variant variants/mother.HC.g.vcf \\ --variant variants/father.HC.g.vcf \\ --variant variants/son.HC.g.vcf \\ --intervals chr20:10018000-10220000 \\ --genomicsdb-workspace-path genomicsdb Exercise: Run this command to generate the database. You can retrieve the combined vcf from the database with gatk GenotypeGVCFs . gatk GenotypeGVCFs \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --variant gendb://genomicsdb \\ --intervals chr20:10018000-10220000 \\ --output variants/trio.vcf Exercise: Run this command to generate the combined vcf.","title":"Variant calling"},{"location":"day2/variant_calling/#material","text":"Download the presentation GATK best practices germline short variant workflow :","title":"Material"},{"location":"day2/variant_calling/#exercises","text":"","title":"Exercises"},{"location":"day2/variant_calling/#1-indexing-indexing-indexing","text":"Many algorithms work faster, or only work with an index of their (large) input files. In that sense, gatk is no different from other tools. The index for a reference needs to be created in two steps: cd ~/workdir/data/reference samtools faidx <reference.fa> gatk CreateSequenceDictionary --REFERENCE <reference.fa> Also input vcf files need to be indexed. This will create a .idx file associated with the .vcf . You can do this like this: gatk IndexFeatureFile --input <variants.vcf> Exercise: Create the required gatk indexes for: The reference genome reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa A part of the dbsnp database: variants/GCF.38.filtered.renamed.vcf A part of the 1000 genomes indel golden standard: variants/1000g_gold_standard.indels.filtered.vcf Answer Creating the index for the reference genome: cd ~/workdir/data samtools faidx reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa gatk CreateSequenceDictionary --REFERENCE reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa Creating the indices for the vcfs: gatk IndexFeatureFile --input variants/1000g_gold_standard.indels.filtered.vcf gatk IndexFeatureFile --input variants/GCF.38.filtered.renamed.vcf Chromosome names Unlike IGV, gatk requires equal chromosome names for all its input files and indexes, e.g. in .fasta , .bam and .vcf files. In general, for the human genome there are three types of chromosome names: Just a number, e.g. 20 Prefixed by chr . e.g. chr20 Refseq name, e.g. NC_000020.11 Before you start the alignment, it\u2019s wise to check out what chromosome naming your input files are using, because changing chromosome names in a .fasta file is easier than in a .bam file. If your fasta titles are e.g. starting with a number you can add chr to it with sed : sed s/^>/>chr/g <reference.fasta> You can change chromsome names in a vcf with bcftools annotate : bcftools annotate --rename-chrs <tab-delimited-renaming> <input.vcf>","title":"1. Indexing, indexing, indexing"},{"location":"day2/variant_calling/#2-base-quality-score-recalibration-bqsr","text":"BQSR evaluates the base qualities on systematic error. It can ignore sites with known variants. BQSR helps to identify faulty base calls, and therefore reduces the chance on discovering false positive variant positions. BQSR is done in two steps: Recalibration with gatk BaseRecalibrator By using the output of gatk BaseRecalibrator , the application to the bam file with gatk ApplyBQSR Exercise: Check out the documentation of the tools. Which options are required? Answer For gatk BaseRecalibrator : --reference --input --known-sites --output For gatk ApplyBQSR : --bqsr-recal-file --input --output Exercise: Run the two commands with the required options on mother.bam , with --known-sites variants/1000g_gold_standard.indels.filtered.vcf and variants/GCF.38.filtered.renamed.vcf . Multiple inputs for same argument In some cases you need to add multiple inputs (e.g. multiple vcf files) into the same argument (e.g. --known-sites ). To provide multiple inputs for the same argument in gatk , you can use the same argument multiple times, e.g.: gatk BaseRecalibrator \\ --reference <reference.fa> \\ --input <alignment.bam> \\ --known-sites <variants1.vcf> \\ --known-sites <variants2.vcf> \\ --output <output.table> Answer cd ~/workdir mkdir bqsr gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/mother.bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/mother.recal.table gatk ApplyBQSR \\ --input alignment/mother.bam \\ --bqsr-recal-file bqsr/mother.recal.table \\ --output bqsr/mother.recal.bam Exercise: Place these commands in a loop, that performs the BQSR for mother, father and son. Answer cd ~/workdir for sample in mother father son do gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/ $sample .bam \\ --known-sites variants/GCF.38.filtered.renamed.vcf \\ --known-sites variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/ $sample .recal.table gatk ApplyBQSR \\ --input alignment/ $sample .bam \\ --bqsr-recal-file bqsr/ $sample .recal.table \\ --output bqsr/ $sample .recal.bam done","title":"2. Base Quality Score Recalibration (BQSR)"},{"location":"day2/variant_calling/#3-variant-calling","text":"The command gatk HaplotypeCaller is the core command of gatk . It performs the actual variant calling. Exercise: Check out the gatk HaplotypeCaller documentation , and find out which arguments are required. Answer Required arguments are: --input --ouput --reference Exercise: Make a directory ~/workdir/variants to write the output vcf. After that, run gatk HaplotypeCaller with required options on the recalibrated alignment file of the mother ( bqsr/mother.recal.bam ). We\u2019ll focus on a small region, so add --intervals chr20:10018000-10220000 . Answer cd ~/workdir mkdir /variants gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/mother.recal.bam \\ --output variants/mother.HC.vcf \\ --intervals chr20:10018000-10220000 \\ We will do the variant calling on all three samples. Later we want to combine the variant calls. For efficient merging of vcfs, we will need to output the variants as a GVCF. To do that, we will use the option --emit-ref-confidence GVCF . Also, we\u2019ll visualise the haplotype phasing with IGV in the next section. For that we\u2019ll need a phased bam. You can get this output with the argument --bam-output . Exercise: Run gatk HaplotypeCaller for mother, father and son by using a loop, and by using the arguments in the previous exercise. On top of that add the arguments --emit-ref-confidence GVCF and --bamoutput <phased.bam> . Answer cd ~/workdir for sample in mother father son do gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/ $sample .recal.bam \\ --output variants/ $sample .HC.g.vcf \\ --bam-output variants/ $sample .phased.bam \\ --intervals chr20:10018000-10220000 \\ --emit-ref-confidence GVCF done","title":"3. Variant calling"},{"location":"day2/variant_calling/#4-combining-gvcfs","text":"Now that we have all three GVCFs of the mother, father and son, we can combine them into a database. We do this because it enables us to later add GVCFs (with the option --genomicsdb-update-workspace-path ), and to efficiently combine them into a single vcf. You can generate a GenomicsDB on our three samples like this: gatk GenomicsDBImport \\ --variant variants/mother.HC.g.vcf \\ --variant variants/father.HC.g.vcf \\ --variant variants/son.HC.g.vcf \\ --intervals chr20:10018000-10220000 \\ --genomicsdb-workspace-path genomicsdb Exercise: Run this command to generate the database. You can retrieve the combined vcf from the database with gatk GenotypeGVCFs . gatk GenotypeGVCFs \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --variant gendb://genomicsdb \\ --intervals chr20:10018000-10220000 \\ --output variants/trio.vcf Exercise: Run this command to generate the combined vcf.","title":"4. Combining GVCFs"},{"location":"day2/visualisation/","text":"Material Exercises Download the following files to your local computer: variants/mother.phased.bam variants/mother.phased.bam.bai bqsr/mother.recal.bam bqsr/mother.recal.bam.bai variants/mother.HC.g.vcf Launch IGV and select the human genome version hg38 as a reference. Load the downloaded files as tracks in igv with File > Load From File\u2026 , and navigate to region chr20:10,026,397-10,026,638 . Exercise: Zoom out for a bit. Not all reads are in the track of mother.phased.bam . What kind of reads are in there? Answer The reads supporting called variants. Now, we\u2019ll investigate the haplotype phasing. Go back to chr20:10,026,397-10,026,638 . Tip If your screen isn\u2019t huge, you can remove the track mother.recal.bam . Do that by right-click on the track, and click on Remove Track . In the track with mother.phased.bam , right click on the reads and select Group alignments by > read group . This splits your track in two parts, one with artificial reads describing haplotypes that were taken in consideration (ArtificalHaplotypeRG), and one with original reads that support the variants. Exercise : How many haplotypes were taken into consideration? How many haplotypes can you expect at maximum within a single individual? Hint This might come as a shock, but humans are diploid. Answer Three haplotypes, as there are three artificial reads: Diploids can carry two haplotypes. So at least one of the three is wrong. Now colour the reads by phase. Do that with by right clicking on the track and choose Colour alignments by > tag , and type in \u201cHC\u201d (that\u2019s the tag where the phasing is stored). Exercise: Which artificial read doesn\u2019t get support from the original sequence reads? Are the alternative alleles of the two SNPs on the same haplotype (i.e. in phase)? Answer The track should look like this (colours can be different): The reads only support the brown and blue haplotype, and not the pink one. The alternative alleles are coloured in IGV. For the first SNP this is the C (in blue) and for the second the T (in red). They are always in different reads, so they are in repulsion (not in phase).","title":"Visualisation"},{"location":"day2/visualisation/#material","text":"","title":"Material"},{"location":"day2/visualisation/#exercises","text":"Download the following files to your local computer: variants/mother.phased.bam variants/mother.phased.bam.bai bqsr/mother.recal.bam bqsr/mother.recal.bam.bai variants/mother.HC.g.vcf Launch IGV and select the human genome version hg38 as a reference. Load the downloaded files as tracks in igv with File > Load From File\u2026 , and navigate to region chr20:10,026,397-10,026,638 . Exercise: Zoom out for a bit. Not all reads are in the track of mother.phased.bam . What kind of reads are in there? Answer The reads supporting called variants. Now, we\u2019ll investigate the haplotype phasing. Go back to chr20:10,026,397-10,026,638 . Tip If your screen isn\u2019t huge, you can remove the track mother.recal.bam . Do that by right-click on the track, and click on Remove Track . In the track with mother.phased.bam , right click on the reads and select Group alignments by > read group . This splits your track in two parts, one with artificial reads describing haplotypes that were taken in consideration (ArtificalHaplotypeRG), and one with original reads that support the variants. Exercise : How many haplotypes were taken into consideration? How many haplotypes can you expect at maximum within a single individual? Hint This might come as a shock, but humans are diploid. Answer Three haplotypes, as there are three artificial reads: Diploids can carry two haplotypes. So at least one of the three is wrong. Now colour the reads by phase. Do that with by right clicking on the track and choose Colour alignments by > tag , and type in \u201cHC\u201d (that\u2019s the tag where the phasing is stored). Exercise: Which artificial read doesn\u2019t get support from the original sequence reads? Are the alternative alleles of the two SNPs on the same haplotype (i.e. in phase)? Answer The track should look like this (colours can be different): The reads only support the brown and blue haplotype, and not the pink one. The alternative alleles are coloured in IGV. For the first SNP this is the C (in blue) and for the second the T (in red). They are always in different reads, so they are in repulsion (not in phase).","title":"Exercises"}]}