{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This course is inspired on the variant analysis course previously given by Walid Gharib Material This website Zoom meeting (through mail) Google doc (through mail) Slack channel Learning outcomes After this course, you will be able to: Understand important aspects of NGS and read alignment for variant analysis Perform a read alignment ready for variant analysis Perform variant calling according to GATK best practices Perform a variant annotation Learning experiences This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only. Exercises Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different. Asking questions During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online). Find the buttons in the participants list (\u2018Participants\u2019 button): Alternatively, (depending on your zoom version or OS) use the \u2018Reactions\u2019 button: A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. If you are replying to a question, use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re really stuck and need specific tutor support, write the teachers or helpers personally. To summarise: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #q-and-a on slack","title":"Home"},{"location":"#material","text":"This website Zoom meeting (through mail) Google doc (through mail) Slack channel","title":"Material"},{"location":"#learning-outcomes","text":"After this course, you will be able to: Understand important aspects of NGS and read alignment for variant analysis Perform a read alignment ready for variant analysis Perform variant calling according to GATK best practices Perform a variant annotation","title":"Learning outcomes"},{"location":"#learning-experiences","text":"This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only.","title":"Learning experiences"},{"location":"#exercises","text":"Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Exercises"},{"location":"#asking-questions","text":"During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online). Find the buttons in the participants list (\u2018Participants\u2019 button): Alternatively, (depending on your zoom version or OS) use the \u2018Reactions\u2019 button: A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. If you are replying to a question, use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re really stuck and need specific tutor support, write the teachers or helpers personally. To summarise: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #q-and-a on slack","title":"Asking questions"},{"location":"course_schedule/","text":"Day 1 block start end subject block 1 9:00 AM 10:30 AM Introduction 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Read alignment - basics 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment - advanced Day 2 block start end subject block 1 9:00 AM 10:30 AM Variant calling 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Visualisation 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Filtering & evaluation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Annotation","title":"Course schedule"},{"location":"course_schedule/#day-1","text":"block start end subject block 1 9:00 AM 10:30 AM Introduction 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Read alignment - basics 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment - advanced","title":"Day 1"},{"location":"course_schedule/#day-2","text":"block start end subject block 1 9:00 AM 10:30 AM Variant calling 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Visualisation 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Filtering & evaluation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Annotation","title":"Day 2"},{"location":"precourse/","text":"UNIX As is stated in the course prerequisites at the announcement web page , we expect participants to have a basic understanding of working with the command line on UNIX-based systems. You can test your UNIX skills with a quiz here . If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial . Software We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through a jupyter notebook . All participants will be granted access to a personal workspace to be used during the course. The only software you need to install before the course is Integrative Genomics Viewer (IGV) .","title":"Precourse preparations"},{"location":"precourse/#unix","text":"As is stated in the course prerequisites at the announcement web page , we expect participants to have a basic understanding of working with the command line on UNIX-based systems. You can test your UNIX skills with a quiz here . If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial .","title":"UNIX"},{"location":"precourse/#software","text":"We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through a jupyter notebook . All participants will be granted access to a personal workspace to be used during the course. The only software you need to install before the course is Integrative Genomics Viewer (IGV) .","title":"Software"},{"location":"day1/alignment/","text":"Learning outcomes After having completed this chapter you will be able to: Describe the general workflow of library preparation and sequencing with an Illumina sequencer Explain how the fastq format stores sequence and base quality information Calculate probability from phred quality and the other way around Explain why base quality and mapping quality are important for detecting variants Illustrate the difference between short-read and long-read sequencing Explain which type of invention led to development of long-read sequencing Explain what impact long read sequencing can have on variant analysis Describe how alignment information is stored in a sequence alignment ( .sam ) file Define a duplicate alignment and explain how alignment duplicates can affect variant analysis Perform an alignment of genomic reads with bwa mem Generate and interpret the alignment statistics from samtools flagstat Material Download the presentation Exercises 1. Prepare the reference genome Download and unpack the data files in your working directory ( ~/workdir ). cd ~/workdir wget https://ngs-variants-training.s3.eu-central-1.amazonaws.com/ngs-variants-training.tar.gz tar -xvf ngs-variants-training.tar.gz rm ngs-variants-training.tar.gz This will create the directory data . Check out what\u2019s in there. We\u2019ll use bwa mem for the alignment. Like all alignment software, it requires an index of the reference genome. You can make an index like this: bwa index <reference.fa> Make an index of the reference sequence of chromosome 20 of the human genome. You can find the fasta file in ~/workdir/data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer cd ~/workdir/data/reference/ bwa index Homo_sapiens.GRCh38.dna.chromosome.20.fa 2. Read alignment Check out the synopsis and manual of bwa mem . We\u2019ll be using paired-end reads of three samples that can be found at ~/workdir/data/fastq . If we run bwa mem with default options, which three arguments do we need? Answer The manual says: bwa mem [-aCHMpP] [-t nThreads] [-k minSeedLen] ... db.prefix reads.fq [mates.fq] So, we\u2019ll need: a database prefix ( db.prefix ) forward reads ( reads.fq ) reverse reads ( mates.fq ) For our reference sequence a command would look like: cd ~/workdir/ bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ <forward_reads.fq> \\ <reverse_reads.fq> \\ > <alignment.sam> Perform an alignment with bwa mem of the reads from the mother ( mother_R1.fastq and mother_R2.fastq ) against chromosome 20. Write the alignment file to a directory in ~/workdir called alignment . Index prefix is the same a reference filename With default values, the name of the index of a reference for bwa mem is the same as the name of the reference itself. In this case, this would be Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer We\u2019ll first make the alignment directory: cd ~/workdir/ mkdir alignment Then, we run the alignment: bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/mother_R1.fastq.gz \\ data/fastq/mother_R2.fastq.gz \\ > alignment/mother.sam 3. Alignment statistics Exercise: Check out the statistics of the alignment by using samtools flagstat . Find the documentation here . Any duplicates in there? Answer cd ~/workdir/alignment samtools flagstat mother.sam Should give: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 0 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) No duplicates were found ( 0 + 0 duplicates ). The aligner doesn\u2019t automatically flag duplicates. This needs to be done after the alignment. 4. Compression The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Tip: samtools view writes to stdout Like bwa mem , samtools view writes its output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . Answer samtools view -bh mother.sam > mother.bam By using ls -lh , you can find out that mother.sam has a size of 54 Mb, while mother.bam is only 20 Mb.","title":"Read alignment - basics"},{"location":"day1/alignment/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe the general workflow of library preparation and sequencing with an Illumina sequencer Explain how the fastq format stores sequence and base quality information Calculate probability from phred quality and the other way around Explain why base quality and mapping quality are important for detecting variants Illustrate the difference between short-read and long-read sequencing Explain which type of invention led to development of long-read sequencing Explain what impact long read sequencing can have on variant analysis Describe how alignment information is stored in a sequence alignment ( .sam ) file Define a duplicate alignment and explain how alignment duplicates can affect variant analysis Perform an alignment of genomic reads with bwa mem Generate and interpret the alignment statistics from samtools flagstat","title":"Learning outcomes"},{"location":"day1/alignment/#material","text":"Download the presentation","title":"Material"},{"location":"day1/alignment/#exercises","text":"","title":"Exercises"},{"location":"day1/alignment/#1-prepare-the-reference-genome","text":"Download and unpack the data files in your working directory ( ~/workdir ). cd ~/workdir wget https://ngs-variants-training.s3.eu-central-1.amazonaws.com/ngs-variants-training.tar.gz tar -xvf ngs-variants-training.tar.gz rm ngs-variants-training.tar.gz This will create the directory data . Check out what\u2019s in there. We\u2019ll use bwa mem for the alignment. Like all alignment software, it requires an index of the reference genome. You can make an index like this: bwa index <reference.fa> Make an index of the reference sequence of chromosome 20 of the human genome. You can find the fasta file in ~/workdir/data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer cd ~/workdir/data/reference/ bwa index Homo_sapiens.GRCh38.dna.chromosome.20.fa","title":"1. Prepare the reference genome"},{"location":"day1/alignment/#2-read-alignment","text":"Check out the synopsis and manual of bwa mem . We\u2019ll be using paired-end reads of three samples that can be found at ~/workdir/data/fastq . If we run bwa mem with default options, which three arguments do we need? Answer The manual says: bwa mem [-aCHMpP] [-t nThreads] [-k minSeedLen] ... db.prefix reads.fq [mates.fq] So, we\u2019ll need: a database prefix ( db.prefix ) forward reads ( reads.fq ) reverse reads ( mates.fq ) For our reference sequence a command would look like: cd ~/workdir/ bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ <forward_reads.fq> \\ <reverse_reads.fq> \\ > <alignment.sam> Perform an alignment with bwa mem of the reads from the mother ( mother_R1.fastq and mother_R2.fastq ) against chromosome 20. Write the alignment file to a directory in ~/workdir called alignment . Index prefix is the same a reference filename With default values, the name of the index of a reference for bwa mem is the same as the name of the reference itself. In this case, this would be Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer We\u2019ll first make the alignment directory: cd ~/workdir/ mkdir alignment Then, we run the alignment: bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/mother_R1.fastq.gz \\ data/fastq/mother_R2.fastq.gz \\ > alignment/mother.sam","title":"2. Read alignment"},{"location":"day1/alignment/#3-alignment-statistics","text":"Exercise: Check out the statistics of the alignment by using samtools flagstat . Find the documentation here . Any duplicates in there? Answer cd ~/workdir/alignment samtools flagstat mother.sam Should give: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 0 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) No duplicates were found ( 0 + 0 duplicates ). The aligner doesn\u2019t automatically flag duplicates. This needs to be done after the alignment.","title":"3. Alignment statistics"},{"location":"day1/alignment/#4-compression","text":"The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Tip: samtools view writes to stdout Like bwa mem , samtools view writes its output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . Answer samtools view -bh mother.sam > mother.bam By using ls -lh , you can find out that mother.sam has a size of 54 Mb, while mother.bam is only 20 Mb.","title":"4. Compression"},{"location":"day1/alignment_advanced/","text":"Learning outcomes After having completed this chapter you will be able to: Use samtools to mark duplicates from an alignment file Use samtools to add readgroups to an alignment file Use a for loop in bash to perform the same operation on a range of files Use samtools in a pipe to efficiently do multiple operations on an alignment file in a single command Material samtools documentation Exercises 1. Marking duplicates For variant analysis, it\u2019s important to mark reads that possibly originated from PCR duplication. We can do that with samtools markdup . However, we can not directly run that on our .sam file nor on our compressed .bam file. Exercise: Which samtools commands would we need to run to mark duplicates? Hint More info on this at the samtools markdup documentation . Also: the reads are already collated (i.e. forward and reverse are grouped) after the alignment, so no need to run samtools collate . Answer The commands would be: samtools fixmate (with the -m option) samtools sort samtools markdup Exercise: Run the three commands that are required to mark duplicates. Answer cd ~/workdir/alignment samtools fixmate -m mother.bam mother.fixmate.bam samtools sort -o mother.positionsort.bam mother.fixmate.bam samtools markdup mother.positionsort.bam mother.markdup.bam Exercise: Run samtools flagstat on the alignment file with marked duplicates. How many reads were marked as duplicate? Answer samtools flagstat mother.markdup.bam Gives: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 17329 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Which tells us that 17329 reads were marked as duplicate. 2. Adding read groups For variant analysis, it\u2019s important to know which read came from which sample. Right now, that\u2019s easy. All reads come from one individual. But this can become less trivial if you are combining samples. Therefore we add a tag to each read specifying its origin. You can add a readgroup to your marked alignment file like this: samtools addreplacerg \\ -r ID:mother \\ -r SM:mother \\ -r PL:ILLUMINA \\ -o mother.markdup.rg.bam \\ mother.markdup.bam This command modifies the sam header and read tags. Exercise: Run the samtools addreplacerg command and compare the header and first alignments of mother.markdup.bam and mother.markdup.rg.bam . Notice any differences? Hint You can view the header with samtools view -H <alignment.bam> And the first few alignments with samtools view <alignment.bam> | head Answer Compared to the header of mother.markdup.bam , the header of mother.markdup.rg.bam contains an extra line starting with @RG : @RG ID:mother SM:mother PL:ILLUMINA In the alignment records, a tag was added at the very end of each line: RG:Z:mother . 3. Indexing To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools index mother.markdup.rg.bam 4. Piping and looping Samtools can quite easily be used in a UNIX pipeline. This has the advantage that you don\u2019t need to write many intermediate files. However, the developers have not been very consistent with managing input and output (I\u2019m sure they had their reasons). To use samtools in a pipe, the input argument needs to replaced with a - . Also, some commands do not write by default to stdout, but to a specified file (this is the case for e.g. samtools fixmate and samtools markdup ). In that case, also the output argument should be replaced with - . Example For the command samtools addreplacerg the samtools documentation provides the following synopsis: samtools addreplacerg [-r rg-line | -R rg-ID] [-m mode] [-l level] [-o out.bam] in.bam Meaning that it requires in.bam , and can write to out.bam if option -o is provided. By default, it writes to stdout. So, if you pipe to samtools addreplacerg you would only need to replace the input file with a - : some_command | samtools addreplacerg [ options ] - > output.sam For the command samtools fixmate , the samtools documentation provides this synopsis: samtools fixmate [-rpcm] [-O format] in.nameSrt.bam out.bam Meaning that it requires both the input file in.nameSrt.bam and the output file out.bam . So, if you pipe to samtools fixmate and you want to write to stdout (so piping from), you\u2019ll need to replace both the input and output with a - : some_command | samtools fixmate [ options ] - - > output.sam The most frequently used samtools commands don\u2019t require an input nor an output file, and therefore behave like many UNIX commands. An example of this is samtools sort . The synopsis is: samtools sort [-l level] [-m maxMem] [-o out.bam] [-O format] [-n] [-t tag] [-T tmpprefix] [-@ threads] [in.sam|in.bam|in.cram] Telling us that both the input file and output (with option -o ) file are optional. If the input file is absent, it reads from stdin. So, you could use it without a - replacing input or output files: some_command | samtools sort > output.sam Let\u2019s put everything we\u2019ve done so far in a pipe and loop over our three samples. The command below loops over the strings father , mother and son , and performs these tasks: Create a variable to work on data of mother, father and son separately Perform the alignment Fill in the mate coordinates and sort on coordinate Mark duplicates Add readgroups Compress the output Create an index #!/usr/bin/env bash cd ~/workdir for sample in mother father son do bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz \\ | samtools fixmate -m - - \\ | samtools sort \\ | samtools markdup -s - - \\ | samtools addreplacerg -r ID: $sample -r SM: $sample -r PL:ILLUMINA - \\ | samtools view -bh > alignment/ $sample .bam samtools index alignment/ $sample .bam done Exercise: For each task (1-7), figure out which part of the script performs that task. After that, run it to get the alignments of all three samples. Answer Creating variables (1): for sample in mother father son do ... done Perform the alignment (2): bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz Fill in the mate coordinates and sort on coordinate (3): samtools fixmate -m <INPUT> <OUTPUT> \\ | samtools sort Mark duplicates (4): samtools markdup -s <INPUT> <OUTPUT> Add readgroups (5): samtools addreplacerg -r ID: $sample -r SM: $sample -r PL:ILLUMINA <INPUT> Compress the output (6): samtools view -bh > alignment/ $sample .bam Create an index (7): samtools index alignment/ $sample .bam","title":"Read alignment - advanced"},{"location":"day1/alignment_advanced/#learning-outcomes","text":"After having completed this chapter you will be able to: Use samtools to mark duplicates from an alignment file Use samtools to add readgroups to an alignment file Use a for loop in bash to perform the same operation on a range of files Use samtools in a pipe to efficiently do multiple operations on an alignment file in a single command","title":"Learning outcomes"},{"location":"day1/alignment_advanced/#material","text":"samtools documentation","title":"Material"},{"location":"day1/alignment_advanced/#exercises","text":"","title":"Exercises"},{"location":"day1/alignment_advanced/#1-marking-duplicates","text":"For variant analysis, it\u2019s important to mark reads that possibly originated from PCR duplication. We can do that with samtools markdup . However, we can not directly run that on our .sam file nor on our compressed .bam file. Exercise: Which samtools commands would we need to run to mark duplicates? Hint More info on this at the samtools markdup documentation . Also: the reads are already collated (i.e. forward and reverse are grouped) after the alignment, so no need to run samtools collate . Answer The commands would be: samtools fixmate (with the -m option) samtools sort samtools markdup Exercise: Run the three commands that are required to mark duplicates. Answer cd ~/workdir/alignment samtools fixmate -m mother.bam mother.fixmate.bam samtools sort -o mother.positionsort.bam mother.fixmate.bam samtools markdup mother.positionsort.bam mother.markdup.bam Exercise: Run samtools flagstat on the alignment file with marked duplicates. How many reads were marked as duplicate? Answer samtools flagstat mother.markdup.bam Gives: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 17329 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Which tells us that 17329 reads were marked as duplicate.","title":"1. Marking duplicates"},{"location":"day1/alignment_advanced/#2-adding-read-groups","text":"For variant analysis, it\u2019s important to know which read came from which sample. Right now, that\u2019s easy. All reads come from one individual. But this can become less trivial if you are combining samples. Therefore we add a tag to each read specifying its origin. You can add a readgroup to your marked alignment file like this: samtools addreplacerg \\ -r ID:mother \\ -r SM:mother \\ -r PL:ILLUMINA \\ -o mother.markdup.rg.bam \\ mother.markdup.bam This command modifies the sam header and read tags. Exercise: Run the samtools addreplacerg command and compare the header and first alignments of mother.markdup.bam and mother.markdup.rg.bam . Notice any differences? Hint You can view the header with samtools view -H <alignment.bam> And the first few alignments with samtools view <alignment.bam> | head Answer Compared to the header of mother.markdup.bam , the header of mother.markdup.rg.bam contains an extra line starting with @RG : @RG ID:mother SM:mother PL:ILLUMINA In the alignment records, a tag was added at the very end of each line: RG:Z:mother .","title":"2. Adding read groups"},{"location":"day1/alignment_advanced/#3-indexing","text":"To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools index mother.markdup.rg.bam","title":"3. Indexing"},{"location":"day1/alignment_advanced/#4-piping-and-looping","text":"Samtools can quite easily be used in a UNIX pipeline. This has the advantage that you don\u2019t need to write many intermediate files. However, the developers have not been very consistent with managing input and output (I\u2019m sure they had their reasons). To use samtools in a pipe, the input argument needs to replaced with a - . Also, some commands do not write by default to stdout, but to a specified file (this is the case for e.g. samtools fixmate and samtools markdup ). In that case, also the output argument should be replaced with - . Example For the command samtools addreplacerg the samtools documentation provides the following synopsis: samtools addreplacerg [-r rg-line | -R rg-ID] [-m mode] [-l level] [-o out.bam] in.bam Meaning that it requires in.bam , and can write to out.bam if option -o is provided. By default, it writes to stdout. So, if you pipe to samtools addreplacerg you would only need to replace the input file with a - : some_command | samtools addreplacerg [ options ] - > output.sam For the command samtools fixmate , the samtools documentation provides this synopsis: samtools fixmate [-rpcm] [-O format] in.nameSrt.bam out.bam Meaning that it requires both the input file in.nameSrt.bam and the output file out.bam . So, if you pipe to samtools fixmate and you want to write to stdout (so piping from), you\u2019ll need to replace both the input and output with a - : some_command | samtools fixmate [ options ] - - > output.sam The most frequently used samtools commands don\u2019t require an input nor an output file, and therefore behave like many UNIX commands. An example of this is samtools sort . The synopsis is: samtools sort [-l level] [-m maxMem] [-o out.bam] [-O format] [-n] [-t tag] [-T tmpprefix] [-@ threads] [in.sam|in.bam|in.cram] Telling us that both the input file and output (with option -o ) file are optional. If the input file is absent, it reads from stdin. So, you could use it without a - replacing input or output files: some_command | samtools sort > output.sam Let\u2019s put everything we\u2019ve done so far in a pipe and loop over our three samples. The command below loops over the strings father , mother and son , and performs these tasks: Create a variable to work on data of mother, father and son separately Perform the alignment Fill in the mate coordinates and sort on coordinate Mark duplicates Add readgroups Compress the output Create an index #!/usr/bin/env bash cd ~/workdir for sample in mother father son do bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz \\ | samtools fixmate -m - - \\ | samtools sort \\ | samtools markdup -s - - \\ | samtools addreplacerg -r ID: $sample -r SM: $sample -r PL:ILLUMINA - \\ | samtools view -bh > alignment/ $sample .bam samtools index alignment/ $sample .bam done Exercise: For each task (1-7), figure out which part of the script performs that task. After that, run it to get the alignments of all three samples. Answer Creating variables (1): for sample in mother father son do ... done Perform the alignment (2): bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz Fill in the mate coordinates and sort on coordinate (3): samtools fixmate -m <INPUT> <OUTPUT> \\ | samtools sort Mark duplicates (4): samtools markdup -s <INPUT> <OUTPUT> Add readgroups (5): samtools addreplacerg -r ID: $sample -r SM: $sample -r PL:ILLUMINA <INPUT> Compress the output (6): samtools view -bh > alignment/ $sample .bam Create an index (7): samtools index alignment/ $sample .bam","title":"4. Piping and looping"},{"location":"day1/introduction/","text":"Learning outcomes After having completed this chapter you will be able to: Describe the importance of studying variants Define a DNA mutation Illustrate the difference between a somatic mutation and a germline mutation Describe the two major types of small variants: SNPs and INDELs Explain why SNPs are the most used type of variant for genetic research Explain what haplotypes are and how they can capture more genetic information compared to single small variants Material Course introduction: Download the presentation Introduction to variant analysis: Download the presentation","title":"Introduction"},{"location":"day1/introduction/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe the importance of studying variants Define a DNA mutation Illustrate the difference between a somatic mutation and a germline mutation Describe the two major types of small variants: SNPs and INDELs Explain why SNPs are the most used type of variant for genetic research Explain what haplotypes are and how they can capture more genetic information compared to single small variants","title":"Learning outcomes"},{"location":"day1/introduction/#material","text":"Course introduction: Download the presentation Introduction to variant analysis: Download the presentation","title":"Material"},{"location":"day1/server_login/","text":"Learning outcomes Note You might already be able to do some or all of these learning outcomes. If so, you can go through the corresponding exercises quickly. The general aim of this chapter is to work comfortably on a remote server by using the command line. After having completed this chapter you will be able to: Use the command line to: Make a directory Change file permissions to \u2018executable\u2019 Run a bash script Pipe data from and to a file or other executable Program a loop in bash Choose your platform In this part we will show you how to access the cloud server, or setup your computer to do the exercises with conda or with Docker. If you are doing the course with a teacher , you will have to login to the remote server. Therefore choose: Cloud notebook If you are doing this course independently (i.e. without a teacher) choose either: conda Docker Cloud notebook If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002 ) in your browser. This should result in the following page: Type your password, and proceed to the notebook home page. This page contains all the files in your working directory (if there are any). Most of the exercises will be executed through the command line. Here\u2019s a video that explains how to use JupyterLab to use a terminal and work with scripts: If you rather read, here\u2019s written explanation how to work with JupyterLab. First, let\u2019s open the terminal. Find it at New > Terminal : For a.o. efficiency and reproducibility it makes sense to execute your commands from a script. You can generate and edit scripts with New > Text File : Once you have opened a script you can change the code highlighting. This is convenient for writing the code. The text editor will automatically change the highlighting based on the file extension (e.g. .py extension will result in python syntax highlighting). You can change or set the syntax highlighting by clicking the button on the bottom of the page. We will be using mainly shell scripting in this course, so here\u2019s an example for adjusting it to shell syntax highlighting: Docker Material Instructions to install docker Instructions to set up to container Exercises First login Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. The command to run the environment required for this course looks like this (in a terminal): Modify the script Modify the path after -v to the working directory on your computer before running it. docker run \\ --rm \\ -e JUPYTER_ENABLE_LAB = yes \\ -v /path/to/workingdir/:/home/jovyan \\ -p 8888 :8888 \\ geertvangeest/ngs-variants-jupyter:latest \\ start-notebook.sh If this command has run successfully, you will find a link and token in the console, e.g.: http://127.0.0.1:8888/?token = 4be8d916e89afad166923de5ce5th1s1san3xamp13 Copy this URL into your browser, and you will be able to use the jupyter notebook. The option -v mounts a local directory in your computer to the directory /home/jovyan in the docker container (\u2018jovyan\u2019 is the default user for jupyter containers). In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The part geertvangeest/ngs-variants-jupyter:latest is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. conda If you have a conda installation on your local computer, you can install the required software using conda. You can build the environment from ngs-variants.yml Generate the conda environment like this: conda env create --name ngs-variants -f ngs-variants.yml The yaml file probably only works for Linux systems If you want to use the conda environment on a different OS, use: conda create -n ngs-variants python = 3 .8 conda activate ngs-variants conda install -y -c bioconda \\ samtools \\ bwa \\ snpeff \\ gatk4 This will create the conda environment ngs-variants Activate it like so: conda activate ngs-variants After successful installation and activating the environment all the software required to do the exercises should be available. A UNIX command line interface (CLI) refresher Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory. Make a new directory Login to the server and use the command line to make a directory called workdir . If working with Docker If your are working with docker you are a root user. This means that your \u201chome\u201d directory is the root directory, i.e. /root , and not /home/username . If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts File permissions Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here . Redirection: > and | In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory (use ls and > ). Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l Variables Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE shell scripts Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l Loops 20 minutes If you want to run the same command on a range of arguments, it\u2019s not very convenient to type the command for each individual argument. For example, you could write dog , fox , bird to stdout in a script like this: #!/usr/bin/env bash echo dog echo fox echo bird However, if you want to change the command (add an option for example), you would have to change it for all the three command calls. Amongst others for that reason, you want to write the command only once. You can do this with a for-loop, like this: #!/usr/bin/env bash ANIMALS = \"dog fox bird\" for animal in $ANIMALS do echo $animal done Which results in: dog fox bird Write a shell script that removes all the letters \u201ce\u201d from a list of words. Hint Removing the letter \u201ce\u201d from a string can be done with tr like this: word = \"test\" echo $word | tr -d \"e\" Which would result in: tst Answer Your script should e.g. look like this (I\u2019ve added some awesome functionality): #!/usr/bin/env bash WORDLIST = \"here is a list of words resulting in a sentence\" for word in $WORDLIST do echo \"' $word ' with e's removed looks like:\" echo $word | tr -d \"e\" done resulting in: 'here' with e's removed looks like: hr 'is' with e's removed looks like: is 'a' with e's removed looks like: a 'list' with e's removed looks like: list 'of' with e's removed looks like: of 'words' with e's removed looks like: words 'resulting' with e's removed looks like: rsulting 'in' with e's removed looks like: in 'a' with e's removed looks like: a 'sentence' with e's removed looks like: sntnc","title":"Server login"},{"location":"day1/server_login/#learning-outcomes","text":"Note You might already be able to do some or all of these learning outcomes. If so, you can go through the corresponding exercises quickly. The general aim of this chapter is to work comfortably on a remote server by using the command line. After having completed this chapter you will be able to: Use the command line to: Make a directory Change file permissions to \u2018executable\u2019 Run a bash script Pipe data from and to a file or other executable Program a loop in bash Choose your platform In this part we will show you how to access the cloud server, or setup your computer to do the exercises with conda or with Docker. If you are doing the course with a teacher , you will have to login to the remote server. Therefore choose: Cloud notebook If you are doing this course independently (i.e. without a teacher) choose either: conda Docker Cloud notebook If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002 ) in your browser. This should result in the following page: Type your password, and proceed to the notebook home page. This page contains all the files in your working directory (if there are any). Most of the exercises will be executed through the command line. Here\u2019s a video that explains how to use JupyterLab to use a terminal and work with scripts: If you rather read, here\u2019s written explanation how to work with JupyterLab. First, let\u2019s open the terminal. Find it at New > Terminal : For a.o. efficiency and reproducibility it makes sense to execute your commands from a script. You can generate and edit scripts with New > Text File : Once you have opened a script you can change the code highlighting. This is convenient for writing the code. The text editor will automatically change the highlighting based on the file extension (e.g. .py extension will result in python syntax highlighting). You can change or set the syntax highlighting by clicking the button on the bottom of the page. We will be using mainly shell scripting in this course, so here\u2019s an example for adjusting it to shell syntax highlighting: Docker","title":"Learning outcomes"},{"location":"day1/server_login/#material","text":"Instructions to install docker Instructions to set up to container","title":"Material"},{"location":"day1/server_login/#exercises","text":"","title":"Exercises"},{"location":"day1/server_login/#first-login","text":"Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. The command to run the environment required for this course looks like this (in a terminal): Modify the script Modify the path after -v to the working directory on your computer before running it. docker run \\ --rm \\ -e JUPYTER_ENABLE_LAB = yes \\ -v /path/to/workingdir/:/home/jovyan \\ -p 8888 :8888 \\ geertvangeest/ngs-variants-jupyter:latest \\ start-notebook.sh If this command has run successfully, you will find a link and token in the console, e.g.: http://127.0.0.1:8888/?token = 4be8d916e89afad166923de5ce5th1s1san3xamp13 Copy this URL into your browser, and you will be able to use the jupyter notebook. The option -v mounts a local directory in your computer to the directory /home/jovyan in the docker container (\u2018jovyan\u2019 is the default user for jupyter containers). In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The part geertvangeest/ngs-variants-jupyter:latest is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. conda If you have a conda installation on your local computer, you can install the required software using conda. You can build the environment from ngs-variants.yml Generate the conda environment like this: conda env create --name ngs-variants -f ngs-variants.yml The yaml file probably only works for Linux systems If you want to use the conda environment on a different OS, use: conda create -n ngs-variants python = 3 .8 conda activate ngs-variants conda install -y -c bioconda \\ samtools \\ bwa \\ snpeff \\ gatk4 This will create the conda environment ngs-variants Activate it like so: conda activate ngs-variants After successful installation and activating the environment all the software required to do the exercises should be available.","title":"First login"},{"location":"day1/server_login/#a-unix-command-line-interface-cli-refresher","text":"Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory.","title":"A UNIX command line interface (CLI) refresher"},{"location":"day1/server_login/#make-a-new-directory","text":"Login to the server and use the command line to make a directory called workdir . If working with Docker If your are working with docker you are a root user. This means that your \u201chome\u201d directory is the root directory, i.e. /root , and not /home/username . If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts","title":"Make a new directory"},{"location":"day1/server_login/#file-permissions","text":"Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here .","title":"File permissions"},{"location":"day1/server_login/#redirection-and","text":"In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory (use ls and > ). Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l","title":"Redirection: &gt; and |"},{"location":"day1/server_login/#variables","text":"Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE","title":"Variables"},{"location":"day1/server_login/#shell-scripts","text":"Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l","title":"shell scripts"},{"location":"day1/server_login/#loops","text":"20 minutes If you want to run the same command on a range of arguments, it\u2019s not very convenient to type the command for each individual argument. For example, you could write dog , fox , bird to stdout in a script like this: #!/usr/bin/env bash echo dog echo fox echo bird However, if you want to change the command (add an option for example), you would have to change it for all the three command calls. Amongst others for that reason, you want to write the command only once. You can do this with a for-loop, like this: #!/usr/bin/env bash ANIMALS = \"dog fox bird\" for animal in $ANIMALS do echo $animal done Which results in: dog fox bird Write a shell script that removes all the letters \u201ce\u201d from a list of words. Hint Removing the letter \u201ce\u201d from a string can be done with tr like this: word = \"test\" echo $word | tr -d \"e\" Which would result in: tst Answer Your script should e.g. look like this (I\u2019ve added some awesome functionality): #!/usr/bin/env bash WORDLIST = \"here is a list of words resulting in a sentence\" for word in $WORDLIST do echo \"' $word ' with e's removed looks like:\" echo $word | tr -d \"e\" done resulting in: 'here' with e's removed looks like: hr 'is' with e's removed looks like: is 'a' with e's removed looks like: a 'list' with e's removed looks like: list 'of' with e's removed looks like: of 'words' with e's removed looks like: words 'resulting' with e's removed looks like: rsulting 'in' with e's removed looks like: in 'a' with e's removed looks like: a 'sentence' with e's removed looks like: sntnc","title":"Loops"},{"location":"day2/annotation/","text":"Learning outcomes After having completed this chapter you will be able to: Describe the aims of variant annotation Explain how variants are ranked in order of importance Explain how splice variation affects variant annotation Perform a variant annotation with snpEff Interpret the report generated by snpEff Explain how variant annotation can be added to a vcf file Material Presentation will be sent to you by e-mail. Exercises To use the human genome is a reference, we have downloaded the database with: No need to download, it\u2019s already downloaded for you # don't run this. It's already downloaded for you snpEff download -v GRCh38.99 You can run snpEff like so: mkdir annotation snpEff -Xmx4g \\ -v \\ -o gatk \\ GRCh38.99 \\ variants/trio.filtered.vcf > annotation/trio.filtered.snpeff.vcf Output -o gatk is deprecated for gatk4 Here, we use output -o gatk for readability reasons (only one effect per variant is reported). With gatk3 you could use gatk VariantAnnotator with input from snpEff . In gatk4 that is not supported anymore. Exercise: Run the command, and check out the html file ( snpEff_summary.html ). Try to answer these questions: A. How many effects were calculated? B. How many variants are in the vcf? C. Why is this different? D. How many effects result in a missense mutation? Answer A. There were 10,357 effects calculated. B. There are only 556 variants in the vcf. C. This means that there are multiple effects per variant. snpEff calculates effects for each splice variant, and therefore the number of effects are a multitude of the number of variants. D. Two effects result in a missense mutation. You can (quick and dirty) query the annotation vcf ( trio.filtered.snpeff.vcf ) for the missense mutation with grep . Exercise: Find the variant causing the missense mutation (the line contains the string MISSENSE ). And answer the following questions: Hint grep MISSENSE annotation/trio.filtered.snpeff.vcf Only one effect per SNP in the vcf In the vcf we have created you can only find one effect per SNP. If you would run snpEff without -o gatk , you would get all effects per variant. A. How are the SNP annotations stored in the vcf? B. What are the genotypes of the individuals? C. Which amino acid change does it cause? Answer Find the line with the missense mutation like this: grep MISSENSE annotation/trio.filtered.snpeff.vcf This results in (long line, scroll to the right to see more): chr20 10049540 . T A 220.29 PASS AC=1;AF=0.167;AN=6;BaseQRankSum=-6.040e-01;DP=85;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=0.00;QD=8.16;ReadPosRankSum=0.226;SOR=0.951;EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|cTg/cAg|L324Q|ANKEF1|protein_coding|CODING|ENST00000378392|7) GT:AD:DP:GQ:PL 0/0:34,0:34:99:0,102,1163 0/1:17,10:27:99:229,0,492 0/0:24,0:24:72:0,72,811 A. SNP annotations are stored in the INFO field, starting with EFF= B. The genotypes are homozygous reference for the father and son, and heterozygous for the mother. (find the order of the samples with grep ^#CHROM ) C. The triplet changes from cTg to cAg, resulting in a change from L (Leucine) to Q (Glutamine).","title":"Annotation"},{"location":"day2/annotation/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe the aims of variant annotation Explain how variants are ranked in order of importance Explain how splice variation affects variant annotation Perform a variant annotation with snpEff Interpret the report generated by snpEff Explain how variant annotation can be added to a vcf file","title":"Learning outcomes"},{"location":"day2/annotation/#material","text":"Presentation will be sent to you by e-mail.","title":"Material"},{"location":"day2/annotation/#exercises","text":"To use the human genome is a reference, we have downloaded the database with: No need to download, it\u2019s already downloaded for you # don't run this. It's already downloaded for you snpEff download -v GRCh38.99 You can run snpEff like so: mkdir annotation snpEff -Xmx4g \\ -v \\ -o gatk \\ GRCh38.99 \\ variants/trio.filtered.vcf > annotation/trio.filtered.snpeff.vcf Output -o gatk is deprecated for gatk4 Here, we use output -o gatk for readability reasons (only one effect per variant is reported). With gatk3 you could use gatk VariantAnnotator with input from snpEff . In gatk4 that is not supported anymore. Exercise: Run the command, and check out the html file ( snpEff_summary.html ). Try to answer these questions: A. How many effects were calculated? B. How many variants are in the vcf? C. Why is this different? D. How many effects result in a missense mutation? Answer A. There were 10,357 effects calculated. B. There are only 556 variants in the vcf. C. This means that there are multiple effects per variant. snpEff calculates effects for each splice variant, and therefore the number of effects are a multitude of the number of variants. D. Two effects result in a missense mutation. You can (quick and dirty) query the annotation vcf ( trio.filtered.snpeff.vcf ) for the missense mutation with grep . Exercise: Find the variant causing the missense mutation (the line contains the string MISSENSE ). And answer the following questions: Hint grep MISSENSE annotation/trio.filtered.snpeff.vcf Only one effect per SNP in the vcf In the vcf we have created you can only find one effect per SNP. If you would run snpEff without -o gatk , you would get all effects per variant. A. How are the SNP annotations stored in the vcf? B. What are the genotypes of the individuals? C. Which amino acid change does it cause? Answer Find the line with the missense mutation like this: grep MISSENSE annotation/trio.filtered.snpeff.vcf This results in (long line, scroll to the right to see more): chr20 10049540 . T A 220.29 PASS AC=1;AF=0.167;AN=6;BaseQRankSum=-6.040e-01;DP=85;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=0.00;QD=8.16;ReadPosRankSum=0.226;SOR=0.951;EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|cTg/cAg|L324Q|ANKEF1|protein_coding|CODING|ENST00000378392|7) GT:AD:DP:GQ:PL 0/0:34,0:34:99:0,102,1163 0/1:17,10:27:99:229,0,492 0/0:24,0:24:72:0,72,811 A. SNP annotations are stored in the INFO field, starting with EFF= B. The genotypes are homozygous reference for the father and son, and heterozygous for the mother. (find the order of the samples with grep ^#CHROM ) C. The triplet changes from cTg to cAg, resulting in a change from L (Leucine) to Q (Glutamine).","title":"Exercises"},{"location":"day2/filtering_evaluation/","text":"Learning outcomes After having completed this chapter you will be able to: Explain why using Variant Quality Score Recalibration (VQSR) for filtering variants can outperform hard filtering Perform hard filtering on both SNPs and INDELs separately by using gatk SelectVariants in combination with gatk VariantFiltration Perform concordance between called variants and a truth set and evaluate performance of a variant calling workflow Exercises 1. Hard filtering The developers of gatk strongly advise to do Variant Quality Score Recalibration (VQSR) for filtering SNPs and INDELs. However, this is not always possible. For example, in the case of limited data availability and/or in the case you are working with non-model organisms and/or in the case you are a bit lazy and okay with a number of false positives. Our dataset is too small to apply VQSR. We will therefore do hard filtering instead. Splitting SNPs and INDELs First, filtering thresholds are usually different for SNPs and INDELs. You can extract all the SNP records in our trio vcf like this: cd ~/workdir gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type SNP \\ --output variants/trio.SNP.vcf Exercise: Check out the documentation of gatk SelectVariants , and: Figure out what you\u2019ll need to fill in at --select-type if you want to select only INDELS. Generate a vcf with only the SNPs and a second vcf with only the INDELs from trio.vcf . Answer You will need to fill in INDEL at --select-type to filter for INDELs. To get the SNPs you can run the command above. To get the INDELs you\u2019ll need to change --select-type to INDEL : gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type INDEL \\ --output variants/trio.INDEL.vcf Filtering SNPs The command gatk VariantFiltration enables you to filter for both the INFO field (per variant) and FORMAT field (per genotype). For now we\u2019re only interested in filtering variants. Below you can find the command to hard-filter the SNP variants on some sensible thresholds (that are explained here ). gatk VariantFiltration \\ --variant variants/trio.SNP.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"SOR > 3.0\" --filter-name \"SOR3\" \\ --filter-expression \"FS > 60.0\" --filter-name \"FS60\" \\ --filter-expression \"MQ < 40.0\" --filter-name \"MQ40\" \\ --filter-expression \"MQRankSum < -12.5\" --filter-name \"MQRankSum-12.5\" \\ --filter-expression \"ReadPosRankSum < -8.0\" --filter-name \"ReadPosRankSum-8\" \\ --output variants/trio.SNP.filtered.vcf Exercise: Run the filtering command above. Did it affect the number of records in the vcf? Hint You can check out the number of records in a vcf with: grep -v \"^#\" <variants.vcf> | wc -l Answer There are no differences in the number of records: grep -v \"^#\" variants/trio.SNP.vcf | wc -l and grep -v \"^#\" variants/trio.SNP.filtered.vcf | wc -l both give 446. However, there are SNPs filtered out, by changing the FILTER column. You can check the number of records with PASS by: grep -v \"^#\" variants/trio.SNP.filtered.vcf | cut -f 7 | sort | uniq -c Giving: 441 PASS 2 QD2;SOR3 3 SOR3 Filtering INDELs A command with sensible parameters to do a first iteration of hard filtering the INDELs would be: gatk VariantFiltration \\ --variant variants/trio.INDEL.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"FS > 200.0\" --filter-name \"FS200\" \\ --filter-expression \"ReadPosRankSum < -20.0\" --filter-name \"ReadPosRankSum-20\" \\ --output variants/trio.INDEL.filtered.vcf Exercise: Run the command and figure out how many variants are filtered out. Hint You can use this command from the answer to the previous exercise: grep -v \"^#\" <variants.vcf> | cut -f 7 | sort | uniq -c to see how many INDELs were filtered out. Answer grep -v \"^#\" variants/trio.INDEL.filtered.vcf | cut -f 7 | sort | uniq -c gives: 110 PASS So no variants are filtered out. Merging filtered SNPs and INDELs Now that we have filtered the INDELs and SNPs separately, we can merge them again with this command: gatk MergeVcfs \\ --INPUT variants/trio.SNP.filtered.vcf \\ --INPUT variants/trio.INDEL.filtered.vcf \\ --OUTPUT variants/trio.filtered.vcf Exercise: Run the command to merge the vcfs. 2. Evaluation by concordance For this region we have a highly curated truth set for the mother available. It originates from the Illumina Platinum truth set . You can find it at data/variants/NA12878.vcf.gz To check how well we did, we\u2019d first need to extract a vcf with only the information of the mother. Exercise: To extract variants that have at least one alternative allele in the mother from variants/trio.filtered.vcf , use gatk SelectVariants with the arguments: --sample-name mother --exclude-non-variants --remove-unused-alternates In addition to the required arguments. Answer gatk SelectVariants \\ --variant variants/trio.filtered.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --output variants/mother.trio.filtered.vcf Exercise: A. How many variants are in mother.trio.filtered.vcf ? How many of those are filtered out? B. Compare our vcf with the curated truth set with the command below. How many SNPs didn\u2019t we detect? gatk Concordance \\ --evaluation variants/mother.trio.filtered.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio.filtered Answer To get the number of records per FILTER, we run: grep -v \"^#\" variants/mother.trio.filtered.vcf | cut -f 7 | sort | uniq -c gives: 407 PASS 2 SOR3 So two records were filtered out, based on the Symmetric Odds Ratio (issues with strand bias). Check out the output of gatk Concordance with cat : cat variants/concordance.mother.trio.filtered gives: type TP FP FN RECALL PRECISION SNP 319 5 9 0.973 0.985 INDEL 63 20 6 0.913 0.759 Showing that there were 9 false negatives, i.e. SNPs we didn\u2019t detect. Recall & precision More info on the definition of recall and precision on this wikipedia page Exercise: Check out the concordance of the mother with the truth set before filtering. Did filtering improve the recall or precision? Note We did the filtering on trio.vcf , therefore, you first have to extract the records that only apply to the mother by using gatk SelectVariants . Also note that trio.vcf contains records other than SNPs and INDELs. Use --select-type to select only SNPs and INDELs. Answer First select only SNPs and INDELs from the mother from the unfiltered vcf: gatk SelectVariants \\ --variant variants/trio.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --select-type INDEL \\ --select-type SNP \\ --output variants/mother.trio.vcf Get the concordance with the truth set: gatk Concordance \\ --evaluation variants/mother.trio.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio Which gives: type TP FP FN RECALL PRECISION SNP 319 7 9 0.973 0.979 INDEL 63 20 6 0.913 0.759 The precision for SNPs is slightly lower. Due to filtering, we removed two false positives.","title":"Filtering & evaluation"},{"location":"day2/filtering_evaluation/#learning-outcomes","text":"After having completed this chapter you will be able to: Explain why using Variant Quality Score Recalibration (VQSR) for filtering variants can outperform hard filtering Perform hard filtering on both SNPs and INDELs separately by using gatk SelectVariants in combination with gatk VariantFiltration Perform concordance between called variants and a truth set and evaluate performance of a variant calling workflow","title":"Learning outcomes"},{"location":"day2/filtering_evaluation/#exercises","text":"","title":"Exercises"},{"location":"day2/filtering_evaluation/#1-hard-filtering","text":"The developers of gatk strongly advise to do Variant Quality Score Recalibration (VQSR) for filtering SNPs and INDELs. However, this is not always possible. For example, in the case of limited data availability and/or in the case you are working with non-model organisms and/or in the case you are a bit lazy and okay with a number of false positives. Our dataset is too small to apply VQSR. We will therefore do hard filtering instead.","title":"1. Hard filtering"},{"location":"day2/filtering_evaluation/#splitting-snps-and-indels","text":"First, filtering thresholds are usually different for SNPs and INDELs. You can extract all the SNP records in our trio vcf like this: cd ~/workdir gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type SNP \\ --output variants/trio.SNP.vcf Exercise: Check out the documentation of gatk SelectVariants , and: Figure out what you\u2019ll need to fill in at --select-type if you want to select only INDELS. Generate a vcf with only the SNPs and a second vcf with only the INDELs from trio.vcf . Answer You will need to fill in INDEL at --select-type to filter for INDELs. To get the SNPs you can run the command above. To get the INDELs you\u2019ll need to change --select-type to INDEL : gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type INDEL \\ --output variants/trio.INDEL.vcf","title":"Splitting SNPs and INDELs"},{"location":"day2/filtering_evaluation/#filtering-snps","text":"The command gatk VariantFiltration enables you to filter for both the INFO field (per variant) and FORMAT field (per genotype). For now we\u2019re only interested in filtering variants. Below you can find the command to hard-filter the SNP variants on some sensible thresholds (that are explained here ). gatk VariantFiltration \\ --variant variants/trio.SNP.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"SOR > 3.0\" --filter-name \"SOR3\" \\ --filter-expression \"FS > 60.0\" --filter-name \"FS60\" \\ --filter-expression \"MQ < 40.0\" --filter-name \"MQ40\" \\ --filter-expression \"MQRankSum < -12.5\" --filter-name \"MQRankSum-12.5\" \\ --filter-expression \"ReadPosRankSum < -8.0\" --filter-name \"ReadPosRankSum-8\" \\ --output variants/trio.SNP.filtered.vcf Exercise: Run the filtering command above. Did it affect the number of records in the vcf? Hint You can check out the number of records in a vcf with: grep -v \"^#\" <variants.vcf> | wc -l Answer There are no differences in the number of records: grep -v \"^#\" variants/trio.SNP.vcf | wc -l and grep -v \"^#\" variants/trio.SNP.filtered.vcf | wc -l both give 446. However, there are SNPs filtered out, by changing the FILTER column. You can check the number of records with PASS by: grep -v \"^#\" variants/trio.SNP.filtered.vcf | cut -f 7 | sort | uniq -c Giving: 441 PASS 2 QD2;SOR3 3 SOR3","title":"Filtering SNPs"},{"location":"day2/filtering_evaluation/#filtering-indels","text":"A command with sensible parameters to do a first iteration of hard filtering the INDELs would be: gatk VariantFiltration \\ --variant variants/trio.INDEL.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"FS > 200.0\" --filter-name \"FS200\" \\ --filter-expression \"ReadPosRankSum < -20.0\" --filter-name \"ReadPosRankSum-20\" \\ --output variants/trio.INDEL.filtered.vcf Exercise: Run the command and figure out how many variants are filtered out. Hint You can use this command from the answer to the previous exercise: grep -v \"^#\" <variants.vcf> | cut -f 7 | sort | uniq -c to see how many INDELs were filtered out. Answer grep -v \"^#\" variants/trio.INDEL.filtered.vcf | cut -f 7 | sort | uniq -c gives: 110 PASS So no variants are filtered out.","title":"Filtering INDELs"},{"location":"day2/filtering_evaluation/#merging-filtered-snps-and-indels","text":"Now that we have filtered the INDELs and SNPs separately, we can merge them again with this command: gatk MergeVcfs \\ --INPUT variants/trio.SNP.filtered.vcf \\ --INPUT variants/trio.INDEL.filtered.vcf \\ --OUTPUT variants/trio.filtered.vcf Exercise: Run the command to merge the vcfs.","title":"Merging filtered SNPs and INDELs"},{"location":"day2/filtering_evaluation/#2-evaluation-by-concordance","text":"For this region we have a highly curated truth set for the mother available. It originates from the Illumina Platinum truth set . You can find it at data/variants/NA12878.vcf.gz To check how well we did, we\u2019d first need to extract a vcf with only the information of the mother. Exercise: To extract variants that have at least one alternative allele in the mother from variants/trio.filtered.vcf , use gatk SelectVariants with the arguments: --sample-name mother --exclude-non-variants --remove-unused-alternates In addition to the required arguments. Answer gatk SelectVariants \\ --variant variants/trio.filtered.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --output variants/mother.trio.filtered.vcf Exercise: A. How many variants are in mother.trio.filtered.vcf ? How many of those are filtered out? B. Compare our vcf with the curated truth set with the command below. How many SNPs didn\u2019t we detect? gatk Concordance \\ --evaluation variants/mother.trio.filtered.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio.filtered Answer To get the number of records per FILTER, we run: grep -v \"^#\" variants/mother.trio.filtered.vcf | cut -f 7 | sort | uniq -c gives: 407 PASS 2 SOR3 So two records were filtered out, based on the Symmetric Odds Ratio (issues with strand bias). Check out the output of gatk Concordance with cat : cat variants/concordance.mother.trio.filtered gives: type TP FP FN RECALL PRECISION SNP 319 5 9 0.973 0.985 INDEL 63 20 6 0.913 0.759 Showing that there were 9 false negatives, i.e. SNPs we didn\u2019t detect. Recall & precision More info on the definition of recall and precision on this wikipedia page Exercise: Check out the concordance of the mother with the truth set before filtering. Did filtering improve the recall or precision? Note We did the filtering on trio.vcf , therefore, you first have to extract the records that only apply to the mother by using gatk SelectVariants . Also note that trio.vcf contains records other than SNPs and INDELs. Use --select-type to select only SNPs and INDELs. Answer First select only SNPs and INDELs from the mother from the unfiltered vcf: gatk SelectVariants \\ --variant variants/trio.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --select-type INDEL \\ --select-type SNP \\ --output variants/mother.trio.vcf Get the concordance with the truth set: gatk Concordance \\ --evaluation variants/mother.trio.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio Which gives: type TP FP FN RECALL PRECISION SNP 319 7 9 0.973 0.979 INDEL 63 20 6 0.913 0.759 The precision for SNPs is slightly lower. Due to filtering, we removed two false positives.","title":"2. Evaluation by concordance"},{"location":"day2/variant_calling/","text":"Learning outcomes After having completed this chapter you will be able to: Describe how variant information is stored in a variant call format ( .vcf ) file Describe the \u2018missing genotype problem\u2019 when calling variants of multiple samples, and the different methods on how this can be solved Follow gatk best practices workflow to perform a variant analysis by: Applying Base Quality Score Recalibration on an alignment file Calling variants with gatk HaplotypeCaller Combining multiple vcf files into a single vcf file Perform basic operations to get statistics of a vcf file Material Download the presentation VCF format description GATK best practices germline short variant workflow : Exercises 1. Indexing, indexing, indexing Many algorithms work faster, or only work with an index of their (large) input files. In that sense, gatk is no different from other tools. The index for a reference needs to be created in two steps: cd ~/workdir/data/reference samtools faidx <reference.fa> gatk CreateSequenceDictionary --REFERENCE <reference.fa> Also input vcf files need to be indexed. This will create a .idx file associated with the .vcf . You can do this like this: gatk IndexFeatureFile --input <variants.vcf> Exercise: Create the required gatk indexes for: The reference genome reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa A part of the dbsnp database: variants/GCF.38.filtered.renamed.vcf A part of the 1000 genomes indel golden standard: variants/1000g_gold_standard.indels.filtered.vcf Answer Creating the index for the reference genome: cd ~/workdir/data samtools faidx reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa gatk CreateSequenceDictionary --REFERENCE reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa Creating the indices for the vcfs: gatk IndexFeatureFile --input variants/1000g_gold_standard.indels.filtered.vcf gatk IndexFeatureFile --input variants/GCF.38.filtered.renamed.vcf Chromosome names Unlike IGV, gatk requires equal chromosome names for all its input files and indexes, e.g. in .fasta , .bam and .vcf files. In general, for the human genome there are three types of chromosome names: Just a number, e.g. 20 Prefixed by chr . e.g. chr20 Refseq name, e.g. NC_000020.11 Before you start the alignment, it\u2019s wise to check out what chromosome naming your input files are using, because changing chromosome names in a .fasta file is easier than in a .bam file. If your fasta titles are e.g. starting with a number you can add chr to it with sed : sed s/^>/>chr/g <reference.fasta> You can change chromsome names in a vcf with bcftools annotate : bcftools annotate --rename-chrs <tab-delimited-renaming> <input.vcf> 2. Base Quality Score Recalibration (BQSR) BQSR evaluates the base qualities on systematic error. It can ignore sites with known variants. BQSR helps to identify faulty base calls, and therefore reduces the chance on discovering false positive variant positions. BQSR is done in two steps: Recalibration with gatk BaseRecalibrator By using the output of gatk BaseRecalibrator , the application to the bam file with gatk ApplyBQSR Exercise: Check out the documentation of the tools. Which options are required? Answer For gatk BaseRecalibrator : --reference --input --known-sites --output For gatk ApplyBQSR : --bqsr-recal-file --input --output Exercise: Run the two commands with the required options on mother.bam , with --known-sites variants/1000g_gold_standard.indels.filtered.vcf and variants/GCF.38.filtered.renamed.vcf . Multiple inputs for same argument In some cases you need to add multiple inputs (e.g. multiple vcf files) into the same argument (e.g. --known-sites ). To provide multiple inputs for the same argument in gatk , you can use the same argument multiple times, e.g.: gatk BaseRecalibrator \\ --reference <reference.fa> \\ --input <alignment.bam> \\ --known-sites <variants1.vcf> \\ --known-sites <variants2.vcf> \\ --output <output.table> Answer cd ~/workdir mkdir bqsr gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/mother.bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/mother.recal.table gatk ApplyBQSR \\ --input alignment/mother.bam \\ --bqsr-recal-file bqsr/mother.recal.table \\ --output bqsr/mother.recal.bam Exercise: Place these commands in a loop, that performs the BQSR for mother, father and son. Answer cd ~/workdir for sample in mother father son do gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/ $sample .bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/ $sample .recal.table gatk ApplyBQSR \\ --input alignment/ $sample .bam \\ --bqsr-recal-file bqsr/ $sample .recal.table \\ --output bqsr/ $sample .recal.bam done 3. Variant calling The command gatk HaplotypeCaller is the core command of gatk . It performs the actual variant calling. Exercise: Check out the gatk HaplotypeCaller documentation , and find out which arguments are required. Answer Required arguments are: --input --ouput --reference Exercise: Make a directory ~/workdir/variants to write the output vcf. After that, run gatk HaplotypeCaller with required options on the recalibrated alignment file of the mother ( bqsr/mother.recal.bam ). We\u2019ll focus on a small region, so add --intervals chr20:10018000-10220000 . Answer cd ~/workdir mkdir variants gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/mother.recal.bam \\ --output variants/mother.HC.vcf \\ --intervals chr20:10018000-10220000 Exercise: You can get the number of records in a vcf with piping the output of grep -v '^#' to wc -l . Get the number of variants in the vcf. Answer grep -v '^#' variants/mother.HC.vcf | wc -l Shows you that there are 411 variants in there. You can get some more statistics with gatk VariantsToTable . The output can be used to easily query things in R or MS Excel. Here\u2019s an example: gatk VariantsToTable \\ --variant variants/mother.HC.vcf \\ --fields CHROM -F POS -F TYPE -GF GT \\ --output variants/mother.HC.table Exercise: Run the command and have a look at the first few records (use e.g. head or less ). After that, report the number of SNPs and INDELs. Answer You can get the number of SNPs with: grep -c \"SNP\" variants/mother.HC.table which will give 326 And the number of INDELs with: grep -c \"INDEL\" variants/mother.HC.table that outputs 84 A more fancy way to this would be: cut -f 3 variants/mother.HC.table | tail -n +2 | sort | uniq -c Giving: 84 INDEL 1 MIXED 326 SNP We will do the variant calling on all three samples. Later we want to combine the variant calls. For efficient merging of vcfs, we will need to output the variants as a GVCF. To do that, we will use the option --emit-ref-confidence GVCF . Also, we\u2019ll visualise the haplotype phasing with IGV in the next section. For that we\u2019ll need a phased bam. You can get this output with the argument --bam-output . Exercise: Run gatk HaplotypeCaller for mother, father and son by using a loop, and by using the arguments in the previous exercise. On top of that add the arguments --emit-ref-confidence GVCF and --bamoutput <phased.bam> . Answer cd ~/workdir for sample in mother father son do gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/ $sample .recal.bam \\ --output variants/ $sample .HC.g.vcf \\ --bam-output variants/ $sample .phased.bam \\ --intervals chr20:10018000-10220000 \\ --emit-ref-confidence GVCF done 4. Combining GVCFs Now that we have all three GVCFs of the mother, father and son, we can combine them into a database. We do this because it enables us to later add GVCFs (with the option --genomicsdb-update-workspace-path ), and to efficiently combine them into a single vcf. You can generate a GenomicsDB on our three samples like this: cd ~/workdir gatk GenomicsDBImport \\ --variant variants/mother.HC.g.vcf \\ --variant variants/father.HC.g.vcf \\ --variant variants/son.HC.g.vcf \\ --intervals chr20:10018000-10220000 \\ --genomicsdb-workspace-path genomicsdb Exercise: Run this command to generate the database. You can retrieve the combined vcf from the database with gatk GenotypeGVCFs . gatk GenotypeGVCFs \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --variant gendb://genomicsdb \\ --intervals chr20:10018000-10220000 \\ --output variants/trio.vcf Exercise: Run this command to generate the combined vcf.","title":"Variant calling"},{"location":"day2/variant_calling/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe how variant information is stored in a variant call format ( .vcf ) file Describe the \u2018missing genotype problem\u2019 when calling variants of multiple samples, and the different methods on how this can be solved Follow gatk best practices workflow to perform a variant analysis by: Applying Base Quality Score Recalibration on an alignment file Calling variants with gatk HaplotypeCaller Combining multiple vcf files into a single vcf file Perform basic operations to get statistics of a vcf file","title":"Learning outcomes"},{"location":"day2/variant_calling/#material","text":"Download the presentation VCF format description GATK best practices germline short variant workflow :","title":"Material"},{"location":"day2/variant_calling/#exercises","text":"","title":"Exercises"},{"location":"day2/variant_calling/#1-indexing-indexing-indexing","text":"Many algorithms work faster, or only work with an index of their (large) input files. In that sense, gatk is no different from other tools. The index for a reference needs to be created in two steps: cd ~/workdir/data/reference samtools faidx <reference.fa> gatk CreateSequenceDictionary --REFERENCE <reference.fa> Also input vcf files need to be indexed. This will create a .idx file associated with the .vcf . You can do this like this: gatk IndexFeatureFile --input <variants.vcf> Exercise: Create the required gatk indexes for: The reference genome reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa A part of the dbsnp database: variants/GCF.38.filtered.renamed.vcf A part of the 1000 genomes indel golden standard: variants/1000g_gold_standard.indels.filtered.vcf Answer Creating the index for the reference genome: cd ~/workdir/data samtools faidx reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa gatk CreateSequenceDictionary --REFERENCE reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa Creating the indices for the vcfs: gatk IndexFeatureFile --input variants/1000g_gold_standard.indels.filtered.vcf gatk IndexFeatureFile --input variants/GCF.38.filtered.renamed.vcf Chromosome names Unlike IGV, gatk requires equal chromosome names for all its input files and indexes, e.g. in .fasta , .bam and .vcf files. In general, for the human genome there are three types of chromosome names: Just a number, e.g. 20 Prefixed by chr . e.g. chr20 Refseq name, e.g. NC_000020.11 Before you start the alignment, it\u2019s wise to check out what chromosome naming your input files are using, because changing chromosome names in a .fasta file is easier than in a .bam file. If your fasta titles are e.g. starting with a number you can add chr to it with sed : sed s/^>/>chr/g <reference.fasta> You can change chromsome names in a vcf with bcftools annotate : bcftools annotate --rename-chrs <tab-delimited-renaming> <input.vcf>","title":"1. Indexing, indexing, indexing"},{"location":"day2/variant_calling/#2-base-quality-score-recalibration-bqsr","text":"BQSR evaluates the base qualities on systematic error. It can ignore sites with known variants. BQSR helps to identify faulty base calls, and therefore reduces the chance on discovering false positive variant positions. BQSR is done in two steps: Recalibration with gatk BaseRecalibrator By using the output of gatk BaseRecalibrator , the application to the bam file with gatk ApplyBQSR Exercise: Check out the documentation of the tools. Which options are required? Answer For gatk BaseRecalibrator : --reference --input --known-sites --output For gatk ApplyBQSR : --bqsr-recal-file --input --output Exercise: Run the two commands with the required options on mother.bam , with --known-sites variants/1000g_gold_standard.indels.filtered.vcf and variants/GCF.38.filtered.renamed.vcf . Multiple inputs for same argument In some cases you need to add multiple inputs (e.g. multiple vcf files) into the same argument (e.g. --known-sites ). To provide multiple inputs for the same argument in gatk , you can use the same argument multiple times, e.g.: gatk BaseRecalibrator \\ --reference <reference.fa> \\ --input <alignment.bam> \\ --known-sites <variants1.vcf> \\ --known-sites <variants2.vcf> \\ --output <output.table> Answer cd ~/workdir mkdir bqsr gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/mother.bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/mother.recal.table gatk ApplyBQSR \\ --input alignment/mother.bam \\ --bqsr-recal-file bqsr/mother.recal.table \\ --output bqsr/mother.recal.bam Exercise: Place these commands in a loop, that performs the BQSR for mother, father and son. Answer cd ~/workdir for sample in mother father son do gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/ $sample .bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/ $sample .recal.table gatk ApplyBQSR \\ --input alignment/ $sample .bam \\ --bqsr-recal-file bqsr/ $sample .recal.table \\ --output bqsr/ $sample .recal.bam done","title":"2. Base Quality Score Recalibration (BQSR)"},{"location":"day2/variant_calling/#3-variant-calling","text":"The command gatk HaplotypeCaller is the core command of gatk . It performs the actual variant calling. Exercise: Check out the gatk HaplotypeCaller documentation , and find out which arguments are required. Answer Required arguments are: --input --ouput --reference Exercise: Make a directory ~/workdir/variants to write the output vcf. After that, run gatk HaplotypeCaller with required options on the recalibrated alignment file of the mother ( bqsr/mother.recal.bam ). We\u2019ll focus on a small region, so add --intervals chr20:10018000-10220000 . Answer cd ~/workdir mkdir variants gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/mother.recal.bam \\ --output variants/mother.HC.vcf \\ --intervals chr20:10018000-10220000 Exercise: You can get the number of records in a vcf with piping the output of grep -v '^#' to wc -l . Get the number of variants in the vcf. Answer grep -v '^#' variants/mother.HC.vcf | wc -l Shows you that there are 411 variants in there. You can get some more statistics with gatk VariantsToTable . The output can be used to easily query things in R or MS Excel. Here\u2019s an example: gatk VariantsToTable \\ --variant variants/mother.HC.vcf \\ --fields CHROM -F POS -F TYPE -GF GT \\ --output variants/mother.HC.table Exercise: Run the command and have a look at the first few records (use e.g. head or less ). After that, report the number of SNPs and INDELs. Answer You can get the number of SNPs with: grep -c \"SNP\" variants/mother.HC.table which will give 326 And the number of INDELs with: grep -c \"INDEL\" variants/mother.HC.table that outputs 84 A more fancy way to this would be: cut -f 3 variants/mother.HC.table | tail -n +2 | sort | uniq -c Giving: 84 INDEL 1 MIXED 326 SNP We will do the variant calling on all three samples. Later we want to combine the variant calls. For efficient merging of vcfs, we will need to output the variants as a GVCF. To do that, we will use the option --emit-ref-confidence GVCF . Also, we\u2019ll visualise the haplotype phasing with IGV in the next section. For that we\u2019ll need a phased bam. You can get this output with the argument --bam-output . Exercise: Run gatk HaplotypeCaller for mother, father and son by using a loop, and by using the arguments in the previous exercise. On top of that add the arguments --emit-ref-confidence GVCF and --bamoutput <phased.bam> . Answer cd ~/workdir for sample in mother father son do gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/ $sample .recal.bam \\ --output variants/ $sample .HC.g.vcf \\ --bam-output variants/ $sample .phased.bam \\ --intervals chr20:10018000-10220000 \\ --emit-ref-confidence GVCF done","title":"3. Variant calling"},{"location":"day2/variant_calling/#4-combining-gvcfs","text":"Now that we have all three GVCFs of the mother, father and son, we can combine them into a database. We do this because it enables us to later add GVCFs (with the option --genomicsdb-update-workspace-path ), and to efficiently combine them into a single vcf. You can generate a GenomicsDB on our three samples like this: cd ~/workdir gatk GenomicsDBImport \\ --variant variants/mother.HC.g.vcf \\ --variant variants/father.HC.g.vcf \\ --variant variants/son.HC.g.vcf \\ --intervals chr20:10018000-10220000 \\ --genomicsdb-workspace-path genomicsdb Exercise: Run this command to generate the database. You can retrieve the combined vcf from the database with gatk GenotypeGVCFs . gatk GenotypeGVCFs \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --variant gendb://genomicsdb \\ --intervals chr20:10018000-10220000 \\ --output variants/trio.vcf Exercise: Run this command to generate the combined vcf.","title":"4. Combining GVCFs"},{"location":"day2/visualisation/","text":"Learning outcomes After having completed this chapter you will be able to: Use IGV to: Visualise read alignments that support called variants Visualise phasing information generated by gatk Material IGV documentation Exercises Download the following files to your local computer: variants/mother.phased.bam variants/mother.phased.bam.bai bqsr/mother.recal.bam bqsr/mother.recal.bam.bai variants/mother.HC.vcf Download files from the notebook You can download files from the file browser, by right-clicking a file and selecting Download : Launch IGV and select the human genome version hg38 as a reference. Load the downloaded files as tracks in igv with File > Load From File\u2026 , and navigate to region chr20:10,026,397-10,026,638 . Exercise: Zoom out for a bit. Not all reads are in the track of mother.phased.bam . What kind of reads are in there? Answer The reads supporting called variants. Now, we\u2019ll investigate the haplotype phasing. Go back to chr20:10,026,397-10,026,638 . Tip If your screen isn\u2019t huge, you can remove the track mother.recal.bam . Do that by right-click on the track, and click on Remove Track . In the track with mother.phased.bam , right click on the reads and select Group alignments by > read group . This splits your track in two parts, one with artificial reads describing haplotypes that were taken in consideration (ArtificalHaplotypeRG), and one with original reads that support the variants. Exercise : How many haplotypes were taken into consideration? How many haplotypes can you expect at maximum within a single individual? Hint This might come as a shock, but humans are diploid. Answer Three haplotypes, as there are three artificial reads: Diploids can carry two haplotypes. So at least one of the three is wrong. Now colour the reads by phase. Do that with by right clicking on the track and choose Colour alignments by > tag , and type in \u201cHC\u201d (that\u2019s the tag where the phasing is stored). Exercise: Which artificial read doesn\u2019t get support from the original sequence reads? Are the alternative alleles of the two SNPs on the same haplotype (i.e. in phase)? Answer The track should look like this (colours can be different): The reads only support the brown and blue haplotype, and not the pink one. The alternative alleles are coloured in IGV. For the first SNP this is the C (in blue) and for the second the T (in red). They are always in different reads, so they are in repulsion (not in phase).","title":"Visualisation"},{"location":"day2/visualisation/#learning-outcomes","text":"After having completed this chapter you will be able to: Use IGV to: Visualise read alignments that support called variants Visualise phasing information generated by gatk","title":"Learning outcomes"},{"location":"day2/visualisation/#material","text":"IGV documentation","title":"Material"},{"location":"day2/visualisation/#exercises","text":"Download the following files to your local computer: variants/mother.phased.bam variants/mother.phased.bam.bai bqsr/mother.recal.bam bqsr/mother.recal.bam.bai variants/mother.HC.vcf Download files from the notebook You can download files from the file browser, by right-clicking a file and selecting Download : Launch IGV and select the human genome version hg38 as a reference. Load the downloaded files as tracks in igv with File > Load From File\u2026 , and navigate to region chr20:10,026,397-10,026,638 . Exercise: Zoom out for a bit. Not all reads are in the track of mother.phased.bam . What kind of reads are in there? Answer The reads supporting called variants. Now, we\u2019ll investigate the haplotype phasing. Go back to chr20:10,026,397-10,026,638 . Tip If your screen isn\u2019t huge, you can remove the track mother.recal.bam . Do that by right-click on the track, and click on Remove Track . In the track with mother.phased.bam , right click on the reads and select Group alignments by > read group . This splits your track in two parts, one with artificial reads describing haplotypes that were taken in consideration (ArtificalHaplotypeRG), and one with original reads that support the variants. Exercise : How many haplotypes were taken into consideration? How many haplotypes can you expect at maximum within a single individual? Hint This might come as a shock, but humans are diploid. Answer Three haplotypes, as there are three artificial reads: Diploids can carry two haplotypes. So at least one of the three is wrong. Now colour the reads by phase. Do that with by right clicking on the track and choose Colour alignments by > tag , and type in \u201cHC\u201d (that\u2019s the tag where the phasing is stored). Exercise: Which artificial read doesn\u2019t get support from the original sequence reads? Are the alternative alleles of the two SNPs on the same haplotype (i.e. in phase)? Answer The track should look like this (colours can be different): The reads only support the brown and blue haplotype, and not the pink one. The alternative alleles are coloured in IGV. For the first SNP this is the C (in blue) and for the second the T (in red). They are always in different reads, so they are in repulsion (not in phase).","title":"Exercises"}]}