{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Authors Walid Gharib Irene Keller Geert van Geest License & copyright License: CC BY-SA 4.0 Copyright: SIB Swiss Institute of Bioinformatics Material This website Zoom meeting (through mail) Google doc (through mail) Slack channel Learning outcomes After this course, you will be able to: Understand important aspects of NGS and read alignment for variant analysis Perform a read alignment ready for variant analysis Perform variant calling according to GATK best practices Perform a variant annotation Learning experiences This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only. Exercises Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different. Asking questions During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online). Find the buttons in the participants list (\u2018Participants\u2019 button): Alternatively, (depending on your zoom version or OS) use the \u2018Reactions\u2019 button: A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. If you are replying to a question, use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re really stuck and need specific tutor support, write the teachers or helpers personally. To summarise: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #q-and-a on slack","title":"Home"},{"location":"#authors","text":"Walid Gharib Irene Keller Geert van Geest","title":"Authors"},{"location":"#license-copyright","text":"License: CC BY-SA 4.0 Copyright: SIB Swiss Institute of Bioinformatics","title":"License &amp; copyright"},{"location":"#material","text":"This website Zoom meeting (through mail) Google doc (through mail) Slack channel","title":"Material"},{"location":"#learning-outcomes","text":"After this course, you will be able to: Understand important aspects of NGS and read alignment for variant analysis Perform a read alignment ready for variant analysis Perform variant calling according to GATK best practices Perform a variant annotation","title":"Learning outcomes"},{"location":"#learning-experiences","text":"This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only.","title":"Learning experiences"},{"location":"#exercises","text":"Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Exercises"},{"location":"#asking-questions","text":"During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online). Find the buttons in the participants list (\u2018Participants\u2019 button): Alternatively, (depending on your zoom version or OS) use the \u2018Reactions\u2019 button: A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. If you are replying to a question, use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re really stuck and need specific tutor support, write the teachers or helpers personally. To summarise: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #q-and-a on slack","title":"Asking questions"},{"location":"course_schedule/","text":"Day 1 block start end subject block 1 9:00 AM 10:30 AM Introduction 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Read alignment - basics 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment - advanced Day 2 block start end subject block 1 9:00 AM 10:30 AM Variant calling 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Visualisation 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Filtering & evaluation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Annotation","title":"Course schedule"},{"location":"course_schedule/#day-1","text":"block start end subject block 1 9:00 AM 10:30 AM Introduction 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Read alignment - basics 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment - advanced","title":"Day 1"},{"location":"course_schedule/#day-2","text":"block start end subject block 1 9:00 AM 10:30 AM Variant calling 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Visualisation 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Filtering & evaluation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Annotation","title":"Day 2"},{"location":"precourse/","text":"UNIX As is stated in the course prerequisites at the announcement web page , we expect participants to have a basic understanding of working with the command line on UNIX-based systems. You can test your UNIX skills with a quiz here . If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial . Software We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through a jupyter notebook . All participants will be granted access to a personal workspace to be used during the course. The only software you need to install before the course is Integrative Genomics Viewer (IGV) .","title":"Precourse preparations"},{"location":"precourse/#unix","text":"As is stated in the course prerequisites at the announcement web page , we expect participants to have a basic understanding of working with the command line on UNIX-based systems. You can test your UNIX skills with a quiz here . If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial .","title":"UNIX"},{"location":"precourse/#software","text":"We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through a jupyter notebook . All participants will be granted access to a personal workspace to be used during the course. The only software you need to install before the course is Integrative Genomics Viewer (IGV) .","title":"Software"},{"location":"day1/alignment/","text":"Learning outcomes After having completed this chapter you will be able to: Describe the general workflow of library preparation and sequencing with an Illumina sequencer Explain how the fastq format stores sequence and base quality information Calculate probability from phred quality and the other way around Explain why base quality and mapping quality are important for detecting variants Illustrate the difference between short-read and long-read sequencing Explain which type of invention led to development of long-read sequencing Explain what impact long read sequencing can have on variant analysis Describe how alignment information is stored in a sequence alignment ( .sam ) file Define a duplicate alignment and explain how alignment duplicates can affect variant analysis Perform an alignment of genomic reads with bwa mem Generate and interpret the alignment statistics from samtools flagstat Material Download the presentation Exercises 1. Prepare the reference genome Download and unpack the data files in your working directory ( ~/workdir ). cd ~/workdir wget https://ngs-variants-training.s3.eu-central-1.amazonaws.com/ngs-variants-training.tar.gz tar -xvf ngs-variants-training.tar.gz rm ngs-variants-training.tar.gz Exercise: This will create the directory data . Check out what\u2019s in there. Answer The directory data contains the following: data \u251c\u2500\u2500 fastq \u2502 \u251c\u2500\u2500 father_R1.fastq.gz \u2502 \u251c\u2500\u2500 father_R2.fastq.gz \u2502 \u251c\u2500\u2500 mother_R1.fastq.gz \u2502 \u251c\u2500\u2500 mother_R2.fastq.gz \u2502 \u251c\u2500\u2500 son_R1.fastq.gz \u2502 \u2514\u2500\u2500 son_R2.fastq.gz \u251c\u2500\u2500 reference \u2502 \u2514\u2500\u2500 Homo_sapiens.GRCh38.dna.chromosome.20.fa \u2514\u2500\u2500 variants \u251c\u2500\u2500 1000g_gold_standard.indels.filtered.vcf \u251c\u2500\u2500 GCF.38.filtered.renamed.vcf \u251c\u2500\u2500 NA12878.vcf.gz \u2514\u2500\u2500 NA12878.vcf.gz.tbi 3 directories, 11 files These are: input reads (at fastq ) a part of the human reference genome (at reference ) some vcfs with variants for calibration and evaluation (at variants ) Use data only for input The directory data that you have just downloaded, contains only input files for the exercises. So, don\u2019t write output (except for indexes) to this directory. We\u2019ll use bwa mem for the alignment. Like all alignment software, it requires an index of the reference genome. You can make an index like this: bwa index <reference.fa> Make an index of the reference sequence of chromosome 20 of the human genome. You can find the fasta file in ~/workdir/data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer cd ~/workdir/data/reference/ bwa index Homo_sapiens.GRCh38.dna.chromosome.20.fa 2. Read alignment Check out the synopsis and manual of bwa mem . We\u2019ll be using paired-end reads of three samples that can be found at ~/workdir/data/fastq . If we run bwa mem with default options, which three arguments do we need? Answer The manual says: bwa mem [-aCHMpP] [-t nThreads] [-k minSeedLen] ... db.prefix reads.fq [mates.fq] So, we\u2019ll need: a database prefix ( db.prefix ) forward reads ( reads.fq ) reverse reads ( mates.fq ) For our reference sequence a command would look like: cd ~/workdir/ bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ <forward_reads.fq> \\ <reverse_reads.fq> \\ > <alignment.sam> Perform an alignment with bwa mem of the reads from the mother ( mother_R1.fastq and mother_R2.fastq ) against chromosome 20. Write the alignment file to a directory in ~/workdir called alignment . Index prefix is the same a reference filename With default values, the name of the index of a reference for bwa mem is the same as the name of the reference itself. In this case, this would be Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer We\u2019ll first make the alignment directory: cd ~/workdir/ mkdir alignment Then, we run the alignment: bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/mother_R1.fastq.gz \\ data/fastq/mother_R2.fastq.gz \\ > alignment/mother.sam 3. Alignment statistics Exercise: Check out the statistics of the alignment by using samtools flagstat . Find the documentation here . Any duplicates in there? Answer cd ~/workdir/alignment samtools flagstat mother.sam Should give: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 0 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) No duplicates were found ( 0 + 0 duplicates ). The aligner doesn\u2019t automatically flag duplicates. This needs to be done after the alignment. 4. Sorting and compression Many downstream analyses require a coordinate sorted alignment file. Now, your alignment file is in the same order as the fastq file. You can coordinate sort an alignment file with samtools sort . You can find the documentation here . Exercise : Sort the alignment file according to coordinate. Answer samtools sort -o alignment/mother.sorted.sam alignment/mother.sam Tip: samtools sort and samtools view can write to stdout Like bwa mem , samtools sort and samtools view can write its output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Answer samtools view -bh mother.sorted.sam > mother.bam By using ls -lh , you can find out that mother.sorted.sam has a size of 55 Mb, while mother.bam is only 16 Mb.","title":"Read alignment - basics"},{"location":"day1/alignment/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe the general workflow of library preparation and sequencing with an Illumina sequencer Explain how the fastq format stores sequence and base quality information Calculate probability from phred quality and the other way around Explain why base quality and mapping quality are important for detecting variants Illustrate the difference between short-read and long-read sequencing Explain which type of invention led to development of long-read sequencing Explain what impact long read sequencing can have on variant analysis Describe how alignment information is stored in a sequence alignment ( .sam ) file Define a duplicate alignment and explain how alignment duplicates can affect variant analysis Perform an alignment of genomic reads with bwa mem Generate and interpret the alignment statistics from samtools flagstat","title":"Learning outcomes"},{"location":"day1/alignment/#material","text":"Download the presentation","title":"Material"},{"location":"day1/alignment/#exercises","text":"","title":"Exercises"},{"location":"day1/alignment/#1-prepare-the-reference-genome","text":"Download and unpack the data files in your working directory ( ~/workdir ). cd ~/workdir wget https://ngs-variants-training.s3.eu-central-1.amazonaws.com/ngs-variants-training.tar.gz tar -xvf ngs-variants-training.tar.gz rm ngs-variants-training.tar.gz Exercise: This will create the directory data . Check out what\u2019s in there. Answer The directory data contains the following: data \u251c\u2500\u2500 fastq \u2502 \u251c\u2500\u2500 father_R1.fastq.gz \u2502 \u251c\u2500\u2500 father_R2.fastq.gz \u2502 \u251c\u2500\u2500 mother_R1.fastq.gz \u2502 \u251c\u2500\u2500 mother_R2.fastq.gz \u2502 \u251c\u2500\u2500 son_R1.fastq.gz \u2502 \u2514\u2500\u2500 son_R2.fastq.gz \u251c\u2500\u2500 reference \u2502 \u2514\u2500\u2500 Homo_sapiens.GRCh38.dna.chromosome.20.fa \u2514\u2500\u2500 variants \u251c\u2500\u2500 1000g_gold_standard.indels.filtered.vcf \u251c\u2500\u2500 GCF.38.filtered.renamed.vcf \u251c\u2500\u2500 NA12878.vcf.gz \u2514\u2500\u2500 NA12878.vcf.gz.tbi 3 directories, 11 files These are: input reads (at fastq ) a part of the human reference genome (at reference ) some vcfs with variants for calibration and evaluation (at variants ) Use data only for input The directory data that you have just downloaded, contains only input files for the exercises. So, don\u2019t write output (except for indexes) to this directory. We\u2019ll use bwa mem for the alignment. Like all alignment software, it requires an index of the reference genome. You can make an index like this: bwa index <reference.fa> Make an index of the reference sequence of chromosome 20 of the human genome. You can find the fasta file in ~/workdir/data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer cd ~/workdir/data/reference/ bwa index Homo_sapiens.GRCh38.dna.chromosome.20.fa","title":"1. Prepare the reference genome"},{"location":"day1/alignment/#2-read-alignment","text":"Check out the synopsis and manual of bwa mem . We\u2019ll be using paired-end reads of three samples that can be found at ~/workdir/data/fastq . If we run bwa mem with default options, which three arguments do we need? Answer The manual says: bwa mem [-aCHMpP] [-t nThreads] [-k minSeedLen] ... db.prefix reads.fq [mates.fq] So, we\u2019ll need: a database prefix ( db.prefix ) forward reads ( reads.fq ) reverse reads ( mates.fq ) For our reference sequence a command would look like: cd ~/workdir/ bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ <forward_reads.fq> \\ <reverse_reads.fq> \\ > <alignment.sam> Perform an alignment with bwa mem of the reads from the mother ( mother_R1.fastq and mother_R2.fastq ) against chromosome 20. Write the alignment file to a directory in ~/workdir called alignment . Index prefix is the same a reference filename With default values, the name of the index of a reference for bwa mem is the same as the name of the reference itself. In this case, this would be Homo_sapiens.GRCh38.dna.chromosome.20.fa . Answer We\u2019ll first make the alignment directory: cd ~/workdir/ mkdir alignment Then, we run the alignment: bwa mem \\ data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/mother_R1.fastq.gz \\ data/fastq/mother_R2.fastq.gz \\ > alignment/mother.sam","title":"2. Read alignment"},{"location":"day1/alignment/#3-alignment-statistics","text":"Exercise: Check out the statistics of the alignment by using samtools flagstat . Find the documentation here . Any duplicates in there? Answer cd ~/workdir/alignment samtools flagstat mother.sam Should give: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 0 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) No duplicates were found ( 0 + 0 duplicates ). The aligner doesn\u2019t automatically flag duplicates. This needs to be done after the alignment.","title":"3. Alignment statistics"},{"location":"day1/alignment/#4-sorting-and-compression","text":"Many downstream analyses require a coordinate sorted alignment file. Now, your alignment file is in the same order as the fastq file. You can coordinate sort an alignment file with samtools sort . You can find the documentation here . Exercise : Sort the alignment file according to coordinate. Answer samtools sort -o alignment/mother.sorted.sam alignment/mother.sam Tip: samtools sort and samtools view can write to stdout Like bwa mem , samtools sort and samtools view can write its output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Answer samtools view -bh mother.sorted.sam > mother.bam By using ls -lh , you can find out that mother.sorted.sam has a size of 55 Mb, while mother.bam is only 16 Mb.","title":"4. Sorting and compression"},{"location":"day1/alignment_advanced/","text":"Learning outcomes After having completed this chapter you will be able to: Use samtools to mark duplicates from an alignment file Use samtools to add readgroups to an alignment file Use a for loop in bash to perform the same operation on a range of files Use samtools in a pipe to efficiently do multiple operations on an alignment file in a single command Material samtools documentation Exercises 1. Adding readgroups During several steps of variant calling gatk uses read group information. For each read, this gives information on the sequencing platform, the library, the lane and of course the sample. Have a look at the description of the different levels of read group information gatk uses here . Exercise: The documentation mentions several read group fields that are used by gatk . Have a look at the fastq header. Does that give you the information that is required? Do we have that information for our sample? Can you specify it for our sample? Hint You can have a look at the first few entries in the fastq file with: zcat mother_R1.fastq.gz | head Answer Most of the information you should now based on the experimental design, the rest you can find in the fastq header : PL : the platform. Should be quite obvious; you usually you have this information. For us, this would be ILLUMINA SM : the sample. All alignments that have reads coming from the same individual should have the same identifier in this field. For us, this would be mother . LB : library identifier. Molecular duplicates only exist within a library. If a single library was sequenced on multiple lanes, it is important to track this information. In our case, we have sequenced only one library, so you can specify it with e.g. lib1 . PU : platform unit. This field is used to identify the sequencing lane. The documentation tells us we should specify it as [FLOWCELL].[LANE].[SAMPLE BARCODE] . The header of the first entry in our fastq file looks like this: @H0164ALXX140820:2:1101:2136:40460/1 . Where the flowcell ID is H0164 and the lane 2 . This formatting is specific to Broad Genomic Services pipelines, and not very common nowadays. Here the sample barcode is added to the flowcell ID, and is therefore specified as ALXX140820. We can therefore specify it with H0164.2.ALXX140820 . ID : read group id. If you don\u2019t have specific information on the flowcell and lane (specified with PU ), you can use this field to specify a unique unit that is used for e.g. base quality score recalibration. This often a combination of a flow cell identifier and a lane. In our case this could be H0164.2 Note More modern output of an Illumina sequencer looks e.g. like this (example on Wikipedia ): @EAS139:136:FC706VJ:2:2104:15343:197393 1:Y:18:ATCACG Here, e.g. the PU field would be FC706VJ.2.ATCACG Exercise: Have a look at the documentation of AddOrReplaceReadGroups . Specify the required arguments, and run the command. Answer We can use the answers of the previous exercise, and use them in the command: gatk AddOrReplaceReadGroups \\ --INPUT alignment/mother.bam \\ --OUTPUT alignment/mother.rg.bam \\ --RGLB lib1 \\ --RGPU H0164.2.ALXX140820 \\ --RGPL ILLUMINA \\ --RGSM mother \\ --RGID H0164.2 Exercise: Compare the header and first alignments of mother.bam and mother.rg.bam . Notice any differences? Hint You can view the header with samtools view -H <alignment.bam> And the first few alignments with samtools view <alignment.bam> | head Answer Compared to the header of mother.markdup.bam , the header of mother.markdup.rg.bam contains an extra line starting with @RG : @RG ID:H0164.2 LB:lib1 PL:ILLUMINA SM:mother PU:H0164.2.ALXX140820 In the alignment records, a tag was added at the very end of each line: RG:Z:H0164.2 . Note that all fields ( LB , PU , etc.) are related to ID . So for each read only ID is specified and all other fields can be deducted from that. 2. Mark duplicates Now that we have specified read groups, we can mark the duplicates with gatk MarkDuplicates . Exercise: Have a look at the documentation , and run gatk MarkDuplicates with the three required arguments. Answer gatk MarkDuplicates \\ --INPUT alignment/mother.rg.bam \\ --OUTPUT alignment/mother.rg.md.bam \\ --METRICS_FILE alignment/marked_dup_metrics_mother.txt Exercise: Run samtools flagstat on the alignment file with marked duplicates. How many reads were marked as duplicate? Answer samtools flagstat mother.rg.md.bam Gives: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 17329 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Which tells us that 17329 reads were marked as duplicate. 3. Indexing To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools index mother.rg.md.bam 4. Piping and looping Exercise Generate a tab-delimited file in which each line represents a sample (mother, father and son), and where you specify the SM , LB , PU and ID fields. E.g., the first line (for \u2018mother\u2019) would look like: mother lib1 H0164.2.ALXX140820 H0164.2 Answer Your file should look like this: mother lib1 H0164.2.ALXX140820 H0164.2 father lib2 H0164.3.ALXX140820 H0164.3 son lib3 H0164.6.ALXX140820 H0164.6 Exercise: Below you can find a script that loops over each line in a file and creates a shell variable for each column in that line. Figure out where in the script each of the following tasks is performed: adding read groups alignment indexing compression marking duplicates sorting by coordinate Exercise: Use the tab-delimited file you created as input for the \u2018while loop\u2019 to generate bam files for each sample that are sorted, compressed, have read groups added, duplicates marked and indexed. In the example the tab-delimited file is called sample_rg_fields.txt . In addition, add a command in which you generate the alignments statistics with samtools flagstat of the bam file with marked duplicates. cat sample_rg_fields.txt | while read sample lb pu id do bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz \\ | samtools sort \\ | samtools view -bh > alignment/ $sample .bam gatk AddOrReplaceReadGroups \\ --INPUT alignment/ $sample .bam \\ --OUTPUT alignment/ $sample .rg.bam \\ --RGLB $lb \\ --RGPU $pu \\ --RGPL ILLUMINA \\ --RGSM $sample \\ --RGID $id gatk MarkDuplicates \\ --INPUT alignment/ $sample .rg.bam \\ --OUTPUT alignment/ $sample .rg.md.bam \\ --METRICS_FILE alignment/marked_dup_metrics_ $sample .txt samtools index alignment/ $sample .bam done < sample_rg_fields.txt Answer cat sample_rg_fields.txt | while read sample lb pu id do bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz \\ | samtools sort \\ | samtools view -bh > alignment/ $sample .bam gatk AddOrReplaceReadGroups \\ --INPUT alignment/ $sample .bam \\ --OUTPUT alignment/ $sample .rg.bam \\ --RGLB $lb \\ --RGPU $pu \\ --RGPL ILLUMINA \\ --RGSM $sample \\ --RGID $id gatk MarkDuplicates \\ --INPUT alignment/ $sample .rg.bam \\ --OUTPUT alignment/ $sample .rg.md.bam \\ --METRICS_FILE alignment/marked_dup_metrics_ $sample .txt samtools index alignment/ $sample .bam samtools flagstat alignment/ $sample .rg.md.bam > $sample .rg.md.stats done","title":"Read alignment - advanced"},{"location":"day1/alignment_advanced/#learning-outcomes","text":"After having completed this chapter you will be able to: Use samtools to mark duplicates from an alignment file Use samtools to add readgroups to an alignment file Use a for loop in bash to perform the same operation on a range of files Use samtools in a pipe to efficiently do multiple operations on an alignment file in a single command","title":"Learning outcomes"},{"location":"day1/alignment_advanced/#material","text":"samtools documentation","title":"Material"},{"location":"day1/alignment_advanced/#exercises","text":"","title":"Exercises"},{"location":"day1/alignment_advanced/#1-adding-readgroups","text":"During several steps of variant calling gatk uses read group information. For each read, this gives information on the sequencing platform, the library, the lane and of course the sample. Have a look at the description of the different levels of read group information gatk uses here . Exercise: The documentation mentions several read group fields that are used by gatk . Have a look at the fastq header. Does that give you the information that is required? Do we have that information for our sample? Can you specify it for our sample? Hint You can have a look at the first few entries in the fastq file with: zcat mother_R1.fastq.gz | head Answer Most of the information you should now based on the experimental design, the rest you can find in the fastq header : PL : the platform. Should be quite obvious; you usually you have this information. For us, this would be ILLUMINA SM : the sample. All alignments that have reads coming from the same individual should have the same identifier in this field. For us, this would be mother . LB : library identifier. Molecular duplicates only exist within a library. If a single library was sequenced on multiple lanes, it is important to track this information. In our case, we have sequenced only one library, so you can specify it with e.g. lib1 . PU : platform unit. This field is used to identify the sequencing lane. The documentation tells us we should specify it as [FLOWCELL].[LANE].[SAMPLE BARCODE] . The header of the first entry in our fastq file looks like this: @H0164ALXX140820:2:1101:2136:40460/1 . Where the flowcell ID is H0164 and the lane 2 . This formatting is specific to Broad Genomic Services pipelines, and not very common nowadays. Here the sample barcode is added to the flowcell ID, and is therefore specified as ALXX140820. We can therefore specify it with H0164.2.ALXX140820 . ID : read group id. If you don\u2019t have specific information on the flowcell and lane (specified with PU ), you can use this field to specify a unique unit that is used for e.g. base quality score recalibration. This often a combination of a flow cell identifier and a lane. In our case this could be H0164.2 Note More modern output of an Illumina sequencer looks e.g. like this (example on Wikipedia ): @EAS139:136:FC706VJ:2:2104:15343:197393 1:Y:18:ATCACG Here, e.g. the PU field would be FC706VJ.2.ATCACG Exercise: Have a look at the documentation of AddOrReplaceReadGroups . Specify the required arguments, and run the command. Answer We can use the answers of the previous exercise, and use them in the command: gatk AddOrReplaceReadGroups \\ --INPUT alignment/mother.bam \\ --OUTPUT alignment/mother.rg.bam \\ --RGLB lib1 \\ --RGPU H0164.2.ALXX140820 \\ --RGPL ILLUMINA \\ --RGSM mother \\ --RGID H0164.2 Exercise: Compare the header and first alignments of mother.bam and mother.rg.bam . Notice any differences? Hint You can view the header with samtools view -H <alignment.bam> And the first few alignments with samtools view <alignment.bam> | head Answer Compared to the header of mother.markdup.bam , the header of mother.markdup.rg.bam contains an extra line starting with @RG : @RG ID:H0164.2 LB:lib1 PL:ILLUMINA SM:mother PU:H0164.2.ALXX140820 In the alignment records, a tag was added at the very end of each line: RG:Z:H0164.2 . Note that all fields ( LB , PU , etc.) are related to ID . So for each read only ID is specified and all other fields can be deducted from that.","title":"1. Adding readgroups"},{"location":"day1/alignment_advanced/#2-mark-duplicates","text":"Now that we have specified read groups, we can mark the duplicates with gatk MarkDuplicates . Exercise: Have a look at the documentation , and run gatk MarkDuplicates with the three required arguments. Answer gatk MarkDuplicates \\ --INPUT alignment/mother.rg.bam \\ --OUTPUT alignment/mother.rg.md.bam \\ --METRICS_FILE alignment/marked_dup_metrics_mother.txt Exercise: Run samtools flagstat on the alignment file with marked duplicates. How many reads were marked as duplicate? Answer samtools flagstat mother.rg.md.bam Gives: 133477 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 317 + 0 supplementary 17329 + 0 duplicates 132892 + 0 mapped (99.56% : N/A) 133160 + 0 paired in sequencing 66580 + 0 read1 66580 + 0 read2 131470 + 0 properly paired (98.73% : N/A) 131990 + 0 with itself and mate mapped 585 + 0 singletons (0.44% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Which tells us that 17329 reads were marked as duplicate.","title":"2. Mark duplicates"},{"location":"day1/alignment_advanced/#3-indexing","text":"To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools index mother.rg.md.bam","title":"3. Indexing"},{"location":"day1/alignment_advanced/#4-piping-and-looping","text":"Exercise Generate a tab-delimited file in which each line represents a sample (mother, father and son), and where you specify the SM , LB , PU and ID fields. E.g., the first line (for \u2018mother\u2019) would look like: mother lib1 H0164.2.ALXX140820 H0164.2 Answer Your file should look like this: mother lib1 H0164.2.ALXX140820 H0164.2 father lib2 H0164.3.ALXX140820 H0164.3 son lib3 H0164.6.ALXX140820 H0164.6 Exercise: Below you can find a script that loops over each line in a file and creates a shell variable for each column in that line. Figure out where in the script each of the following tasks is performed: adding read groups alignment indexing compression marking duplicates sorting by coordinate Exercise: Use the tab-delimited file you created as input for the \u2018while loop\u2019 to generate bam files for each sample that are sorted, compressed, have read groups added, duplicates marked and indexed. In the example the tab-delimited file is called sample_rg_fields.txt . In addition, add a command in which you generate the alignments statistics with samtools flagstat of the bam file with marked duplicates. cat sample_rg_fields.txt | while read sample lb pu id do bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz \\ | samtools sort \\ | samtools view -bh > alignment/ $sample .bam gatk AddOrReplaceReadGroups \\ --INPUT alignment/ $sample .bam \\ --OUTPUT alignment/ $sample .rg.bam \\ --RGLB $lb \\ --RGPU $pu \\ --RGPL ILLUMINA \\ --RGSM $sample \\ --RGID $id gatk MarkDuplicates \\ --INPUT alignment/ $sample .rg.bam \\ --OUTPUT alignment/ $sample .rg.md.bam \\ --METRICS_FILE alignment/marked_dup_metrics_ $sample .txt samtools index alignment/ $sample .bam done < sample_rg_fields.txt Answer cat sample_rg_fields.txt | while read sample lb pu id do bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ data/fastq/ \" $sample \" _R1.fastq.gz \\ data/fastq/ \" $sample \" _R2.fastq.gz \\ | samtools sort \\ | samtools view -bh > alignment/ $sample .bam gatk AddOrReplaceReadGroups \\ --INPUT alignment/ $sample .bam \\ --OUTPUT alignment/ $sample .rg.bam \\ --RGLB $lb \\ --RGPU $pu \\ --RGPL ILLUMINA \\ --RGSM $sample \\ --RGID $id gatk MarkDuplicates \\ --INPUT alignment/ $sample .rg.bam \\ --OUTPUT alignment/ $sample .rg.md.bam \\ --METRICS_FILE alignment/marked_dup_metrics_ $sample .txt samtools index alignment/ $sample .bam samtools flagstat alignment/ $sample .rg.md.bam > $sample .rg.md.stats done","title":"4. Piping and looping"},{"location":"day1/introduction/","text":"Learning outcomes After having completed this chapter you will be able to: Describe the importance of studying variants Define a DNA mutation Illustrate the difference between a somatic mutation and a germline mutation Describe the two major types of small variants: SNPs and INDELs Explain why SNPs are the most used type of variant for genetic research Explain what haplotypes are and how they can capture more genetic information compared to single small variants Material Course introduction: Download the presentation Introduction to variant analysis: Download the presentation","title":"Introduction"},{"location":"day1/introduction/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe the importance of studying variants Define a DNA mutation Illustrate the difference between a somatic mutation and a germline mutation Describe the two major types of small variants: SNPs and INDELs Explain why SNPs are the most used type of variant for genetic research Explain what haplotypes are and how they can capture more genetic information compared to single small variants","title":"Learning outcomes"},{"location":"day1/introduction/#material","text":"Course introduction: Download the presentation Introduction to variant analysis: Download the presentation","title":"Material"},{"location":"day1/server_login/","text":"Learning outcomes Note You might already be able to do some or all of these learning outcomes. If so, you can go through the corresponding exercises quickly. The general aim of this chapter is to work comfortably on a remote server by using the command line. After having completed this chapter you will be able to: Use the command line to: Make a directory Change file permissions to \u2018executable\u2019 Run a bash script Pipe data from and to a file or other executable Program a loop in bash Choose your platform In this part we will show you how to access the cloud server, or setup your computer to do the exercises with conda or with Docker. If you are doing the course with a teacher , you will have to login to the remote server. Therefore choose: Cloud notebook If you are doing this course independently (i.e. without a teacher) choose either: conda Docker Cloud notebook If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002 ) in your browser. This should result in the following page: Type your password, and proceed to the notebook home page. This page contains all the files in your working directory (if there are any). Most of the exercises will be executed through the command line. Here\u2019s a video that explains how to use JupyterLab to use a terminal and work with scripts: If you rather read, here\u2019s written explanation how to work with JupyterLab. First, let\u2019s open the terminal. Find it at New > Terminal : For a.o. efficiency and reproducibility it makes sense to execute your commands from a script. You can generate and edit scripts with New > Text File : Once you have opened a script you can change the code highlighting. This is convenient for writing the code. The text editor will automatically change the highlighting based on the file extension (e.g. .py extension will result in python syntax highlighting). You can change or set the syntax highlighting by clicking the button on the bottom of the page. We will be using mainly shell scripting in this course, so here\u2019s an example for adjusting it to shell syntax highlighting: Docker Material Instructions to install docker Instructions to set up to container Exercises First login Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. The command to run the environment required for this course looks like this (in a terminal): Modify the script Modify the path after -v to the working directory on your computer before running it. docker run \\ --rm \\ -e JUPYTER_ENABLE_LAB = yes \\ -v /path/to/workingdir/:/home/jovyan \\ -p 8888 :8888 \\ geertvangeest/ngs-variants-jupyter:latest \\ start-notebook.sh If this command has run successfully, you will find a link and token in the console, e.g.: http://127.0.0.1:8888/?token = 4be8d916e89afad166923de5ce5th1s1san3xamp13 Copy this URL into your browser, and you will be able to use the jupyter notebook. The option -v mounts a local directory in your computer to the directory /home/jovyan in the docker container (\u2018jovyan\u2019 is the default user for jupyter containers). In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The part geertvangeest/ngs-variants-jupyter:latest is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. conda If you have a conda installation on your local computer, you can install the required software using conda. You can build the environment from ngs-variants.yml Generate the conda environment like this: conda env create --name ngs-variants -f ngs-variants.yml The yaml file probably only works for Linux systems If you want to use the conda environment on a different OS, use: conda create -n ngs-variants python = 3 .8 conda activate ngs-variants conda install -y -c bioconda \\ samtools \\ bwa \\ snpeff \\ gatk4 This will create the conda environment ngs-variants Activate it like so: conda activate ngs-variants After successful installation and activating the environment all the software required to do the exercises should be available. A UNIX command line interface (CLI) refresher Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory. Make a new directory Login to the server and use the command line to make a directory called workdir . If working with Docker If your are working with docker you are a root user. This means that your \u201chome\u201d directory is the root directory, i.e. /root , and not /home/username . If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts File permissions Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here . Redirection: > and | In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory (use ls and > ). Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l Variables Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE shell scripts Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l Loops If you want to run the same command on a range of arguments, it\u2019s not very convenient to type the command for each individual argument. For example, you could write dog , fox , bird to stdout in a script like this: #!/usr/bin/env bash echo dog echo fox echo bird However, if you want to change the command (add an option for example), you would have to change it for all the three command calls. Amongst others for that reason, you want to write the command only once. You can do this with a for-loop, like this: #!/usr/bin/env bash ANIMALS = \"dog fox bird\" for animal in $ANIMALS do echo $animal done Which results in: dog fox bird Write a shell script that removes all the letters \u201ce\u201d from a list of words. Hint Removing the letter \u201ce\u201d from a string can be done with tr like this: word = \"test\" echo $word | tr -d \"e\" Which would result in: tst Answer Your script should e.g. look like this (I\u2019ve added some awesome functionality): #!/usr/bin/env bash WORDLIST = \"here is a list of words resulting in a sentence\" for word in $WORDLIST do echo \"' $word ' with e's removed looks like:\" echo $word | tr -d \"e\" done resulting in: 'here' with e's removed looks like: hr 'is' with e's removed looks like: is 'a' with e's removed looks like: a 'list' with e's removed looks like: list 'of' with e's removed looks like: of 'words' with e's removed looks like: words 'resulting' with e's removed looks like: rsulting 'in' with e's removed looks like: in 'a' with e's removed looks like: a 'sentence' with e's removed looks like: sntnc Look you might be used to in R or python you can also loop over lines in files. This can be convenient if you have for example a set of parameters in each line of a file. Create a tab-delimited file animals.txt with the following contents: dog retrieves 4 fox jumps 4 bird flies 2 Hint If you\u2019re having trouble typing the actual \u2018tabs\u2019 you can also download the file here With unix shell you can loop over the lines of that file and store each column as a variable. Below, the three columns in the tab delimited file are stored in the variables $animal , $behaviour and $leg_number : cat animals.txt | while read animal behaviour leg_number do #something here done Exercise: Modify the script in such a way that it writes the strings that are stored in the variables at each line to stdout. Done cat animals.txt | while read animal behaviour leg_number do echo \"The $animal $behaviour , and has $leg_number legs\" done","title":"Server login"},{"location":"day1/server_login/#learning-outcomes","text":"Note You might already be able to do some or all of these learning outcomes. If so, you can go through the corresponding exercises quickly. The general aim of this chapter is to work comfortably on a remote server by using the command line. After having completed this chapter you will be able to: Use the command line to: Make a directory Change file permissions to \u2018executable\u2019 Run a bash script Pipe data from and to a file or other executable Program a loop in bash Choose your platform In this part we will show you how to access the cloud server, or setup your computer to do the exercises with conda or with Docker. If you are doing the course with a teacher , you will have to login to the remote server. Therefore choose: Cloud notebook If you are doing this course independently (i.e. without a teacher) choose either: conda Docker Cloud notebook If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002 ) in your browser. This should result in the following page: Type your password, and proceed to the notebook home page. This page contains all the files in your working directory (if there are any). Most of the exercises will be executed through the command line. Here\u2019s a video that explains how to use JupyterLab to use a terminal and work with scripts: If you rather read, here\u2019s written explanation how to work with JupyterLab. First, let\u2019s open the terminal. Find it at New > Terminal : For a.o. efficiency and reproducibility it makes sense to execute your commands from a script. You can generate and edit scripts with New > Text File : Once you have opened a script you can change the code highlighting. This is convenient for writing the code. The text editor will automatically change the highlighting based on the file extension (e.g. .py extension will result in python syntax highlighting). You can change or set the syntax highlighting by clicking the button on the bottom of the page. We will be using mainly shell scripting in this course, so here\u2019s an example for adjusting it to shell syntax highlighting: Docker","title":"Learning outcomes"},{"location":"day1/server_login/#material","text":"Instructions to install docker Instructions to set up to container","title":"Material"},{"location":"day1/server_login/#exercises","text":"","title":"Exercises"},{"location":"day1/server_login/#first-login","text":"Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. The command to run the environment required for this course looks like this (in a terminal): Modify the script Modify the path after -v to the working directory on your computer before running it. docker run \\ --rm \\ -e JUPYTER_ENABLE_LAB = yes \\ -v /path/to/workingdir/:/home/jovyan \\ -p 8888 :8888 \\ geertvangeest/ngs-variants-jupyter:latest \\ start-notebook.sh If this command has run successfully, you will find a link and token in the console, e.g.: http://127.0.0.1:8888/?token = 4be8d916e89afad166923de5ce5th1s1san3xamp13 Copy this URL into your browser, and you will be able to use the jupyter notebook. The option -v mounts a local directory in your computer to the directory /home/jovyan in the docker container (\u2018jovyan\u2019 is the default user for jupyter containers). In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The part geertvangeest/ngs-variants-jupyter:latest is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. conda If you have a conda installation on your local computer, you can install the required software using conda. You can build the environment from ngs-variants.yml Generate the conda environment like this: conda env create --name ngs-variants -f ngs-variants.yml The yaml file probably only works for Linux systems If you want to use the conda environment on a different OS, use: conda create -n ngs-variants python = 3 .8 conda activate ngs-variants conda install -y -c bioconda \\ samtools \\ bwa \\ snpeff \\ gatk4 This will create the conda environment ngs-variants Activate it like so: conda activate ngs-variants After successful installation and activating the environment all the software required to do the exercises should be available.","title":"First login"},{"location":"day1/server_login/#a-unix-command-line-interface-cli-refresher","text":"Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory.","title":"A UNIX command line interface (CLI) refresher"},{"location":"day1/server_login/#make-a-new-directory","text":"Login to the server and use the command line to make a directory called workdir . If working with Docker If your are working with docker you are a root user. This means that your \u201chome\u201d directory is the root directory, i.e. /root , and not /home/username . If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts","title":"Make a new directory"},{"location":"day1/server_login/#file-permissions","text":"Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here .","title":"File permissions"},{"location":"day1/server_login/#redirection-and","text":"In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory (use ls and > ). Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l","title":"Redirection: &gt; and |"},{"location":"day1/server_login/#variables","text":"Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE","title":"Variables"},{"location":"day1/server_login/#shell-scripts","text":"Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l","title":"shell scripts"},{"location":"day1/server_login/#loops","text":"If you want to run the same command on a range of arguments, it\u2019s not very convenient to type the command for each individual argument. For example, you could write dog , fox , bird to stdout in a script like this: #!/usr/bin/env bash echo dog echo fox echo bird However, if you want to change the command (add an option for example), you would have to change it for all the three command calls. Amongst others for that reason, you want to write the command only once. You can do this with a for-loop, like this: #!/usr/bin/env bash ANIMALS = \"dog fox bird\" for animal in $ANIMALS do echo $animal done Which results in: dog fox bird Write a shell script that removes all the letters \u201ce\u201d from a list of words. Hint Removing the letter \u201ce\u201d from a string can be done with tr like this: word = \"test\" echo $word | tr -d \"e\" Which would result in: tst Answer Your script should e.g. look like this (I\u2019ve added some awesome functionality): #!/usr/bin/env bash WORDLIST = \"here is a list of words resulting in a sentence\" for word in $WORDLIST do echo \"' $word ' with e's removed looks like:\" echo $word | tr -d \"e\" done resulting in: 'here' with e's removed looks like: hr 'is' with e's removed looks like: is 'a' with e's removed looks like: a 'list' with e's removed looks like: list 'of' with e's removed looks like: of 'words' with e's removed looks like: words 'resulting' with e's removed looks like: rsulting 'in' with e's removed looks like: in 'a' with e's removed looks like: a 'sentence' with e's removed looks like: sntnc Look you might be used to in R or python you can also loop over lines in files. This can be convenient if you have for example a set of parameters in each line of a file. Create a tab-delimited file animals.txt with the following contents: dog retrieves 4 fox jumps 4 bird flies 2 Hint If you\u2019re having trouble typing the actual \u2018tabs\u2019 you can also download the file here With unix shell you can loop over the lines of that file and store each column as a variable. Below, the three columns in the tab delimited file are stored in the variables $animal , $behaviour and $leg_number : cat animals.txt | while read animal behaviour leg_number do #something here done Exercise: Modify the script in such a way that it writes the strings that are stored in the variables at each line to stdout. Done cat animals.txt | while read animal behaviour leg_number do echo \"The $animal $behaviour , and has $leg_number legs\" done","title":"Loops"},{"location":"day2/annotation/","text":"Learning outcomes After having completed this chapter you will be able to: Describe the aims of variant annotation Explain how variants are ranked in order of importance Explain how splice variation affects variant annotation Perform a variant annotation with snpEff Interpret the report generated by snpEff Explain how variant annotation can be added to a vcf file Material Presentation will be sent to you by e-mail. Exercises To use the human genome as a reference, we have downloaded the database with: No need to download, it\u2019s already downloaded for you # don't run this. It's already downloaded for you snpEff download -v GRCh38.99 You can run snpEff like so: mkdir annotation snpEff -Xmx4g \\ -v \\ -o gatk \\ GRCh38.99 \\ variants/trio.filtered.vcf > annotation/trio.filtered.snpeff.vcf Output -o gatk is deprecated for gatk4 Here, we use output -o gatk for readability reasons (only one effect per variant is reported). With gatk3 you could use gatk VariantAnnotator with input from snpEff . In gatk4 that is not supported anymore. Exercise: Run the command, and check out the html file ( snpEff_summary.html ). Try to answer these questions: A. How many effects were calculated? B. How many variants are in the vcf? C. Why is this different? D. How many effects result in a missense mutation? Answer A. There were 10,357 effects calculated. B. There are only 556 variants in the vcf. C. This means that there are multiple effects per variant. snpEff calculates effects for each splice variant, and therefore the number of effects are a multitude of the number of variants. D. Two effects result in a missense mutation. You can (quick and dirty) query the annotation vcf ( trio.filtered.snpeff.vcf ) for the missense mutation with grep . Exercise: Find the variant causing the missense mutation (the line contains the string MISSENSE ). And answer the following questions: Hint grep MISSENSE annotation/trio.filtered.snpeff.vcf Only one effect per SNP in the vcf In the vcf we have created you can only find one effect per SNP. If you would run snpEff without -o gatk , you would get all effects per variant. A. How are the SNP annotations stored in the vcf? B. What are the genotypes of the individuals? C. Which amino acid change does it cause? Answer Find the line with the missense mutation like this: grep MISSENSE annotation/trio.filtered.snpeff.vcf This results in (long line, scroll to the right to see more): chr20 10049540 . T A 220.29 PASS AC=1;AF=0.167;AN=6;BaseQRankSum=-6.040e-01;DP=85;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=0.00;QD=8.16;ReadPosRankSum=0.226;SOR=0.951;EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|cTg/cAg|L324Q|ANKEF1|protein_coding|CODING|ENST00000378392|7) GT:AD:DP:GQ:PL 0/0:34,0:34:99:0,102,1163 0/1:17,10:27:99:229,0,492 0/0:24,0:24:72:0,72,811 A. SNP annotations are stored in the INFO field, starting with EFF= B. The genotypes are homozygous reference for the father and son, and heterozygous for the mother. (find the order of the samples with grep ^#CHROM ) C. The triplet changes from cTg to cAg, resulting in a change from L (Leucine) to Q (Glutamine).","title":"Annotation"},{"location":"day2/annotation/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe the aims of variant annotation Explain how variants are ranked in order of importance Explain how splice variation affects variant annotation Perform a variant annotation with snpEff Interpret the report generated by snpEff Explain how variant annotation can be added to a vcf file","title":"Learning outcomes"},{"location":"day2/annotation/#material","text":"Presentation will be sent to you by e-mail.","title":"Material"},{"location":"day2/annotation/#exercises","text":"To use the human genome as a reference, we have downloaded the database with: No need to download, it\u2019s already downloaded for you # don't run this. It's already downloaded for you snpEff download -v GRCh38.99 You can run snpEff like so: mkdir annotation snpEff -Xmx4g \\ -v \\ -o gatk \\ GRCh38.99 \\ variants/trio.filtered.vcf > annotation/trio.filtered.snpeff.vcf Output -o gatk is deprecated for gatk4 Here, we use output -o gatk for readability reasons (only one effect per variant is reported). With gatk3 you could use gatk VariantAnnotator with input from snpEff . In gatk4 that is not supported anymore. Exercise: Run the command, and check out the html file ( snpEff_summary.html ). Try to answer these questions: A. How many effects were calculated? B. How many variants are in the vcf? C. Why is this different? D. How many effects result in a missense mutation? Answer A. There were 10,357 effects calculated. B. There are only 556 variants in the vcf. C. This means that there are multiple effects per variant. snpEff calculates effects for each splice variant, and therefore the number of effects are a multitude of the number of variants. D. Two effects result in a missense mutation. You can (quick and dirty) query the annotation vcf ( trio.filtered.snpeff.vcf ) for the missense mutation with grep . Exercise: Find the variant causing the missense mutation (the line contains the string MISSENSE ). And answer the following questions: Hint grep MISSENSE annotation/trio.filtered.snpeff.vcf Only one effect per SNP in the vcf In the vcf we have created you can only find one effect per SNP. If you would run snpEff without -o gatk , you would get all effects per variant. A. How are the SNP annotations stored in the vcf? B. What are the genotypes of the individuals? C. Which amino acid change does it cause? Answer Find the line with the missense mutation like this: grep MISSENSE annotation/trio.filtered.snpeff.vcf This results in (long line, scroll to the right to see more): chr20 10049540 . T A 220.29 PASS AC=1;AF=0.167;AN=6;BaseQRankSum=-6.040e-01;DP=85;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=0.00;QD=8.16;ReadPosRankSum=0.226;SOR=0.951;EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|cTg/cAg|L324Q|ANKEF1|protein_coding|CODING|ENST00000378392|7) GT:AD:DP:GQ:PL 0/0:34,0:34:99:0,102,1163 0/1:17,10:27:99:229,0,492 0/0:24,0:24:72:0,72,811 A. SNP annotations are stored in the INFO field, starting with EFF= B. The genotypes are homozygous reference for the father and son, and heterozygous for the mother. (find the order of the samples with grep ^#CHROM ) C. The triplet changes from cTg to cAg, resulting in a change from L (Leucine) to Q (Glutamine).","title":"Exercises"},{"location":"day2/filtering_evaluation/","text":"Learning outcomes After having completed this chapter you will be able to: Explain why using Variant Quality Score Recalibration (VQSR) for filtering variants can outperform hard filtering Perform hard filtering on both SNPs and INDELs separately by using gatk SelectVariants in combination with gatk VariantFiltration Perform concordance between called variants and a truth set and evaluate performance of a variant calling workflow Exercises 1. Hard filtering The developers of gatk strongly advise to do Variant Quality Score Recalibration (VQSR) for filtering SNPs and INDELs. However, this is not always possible. For example, in the case of limited data availability and/or in the case you are working with non-model organisms and/or in the case you are a bit lazy and okay with a number of false positives. Our dataset is too small to apply VQSR. We will therefore do hard filtering instead. Splitting SNPs and INDELs First, filtering thresholds are usually different for SNPs and INDELs. You can extract all the SNP records in our trio vcf like this: cd ~/workdir gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type SNP \\ --output variants/trio.SNP.vcf Exercise: Check out the documentation of gatk SelectVariants , and: Figure out what you\u2019ll need to fill in at --select-type if you want to select only INDELS. Generate a vcf with only the SNPs and a second vcf with only the INDELs from trio.vcf . Answer You will need to fill in INDEL at --select-type to filter for INDELs. To get the SNPs you can run the command above. To get the INDELs you\u2019ll need to change --select-type to INDEL : gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type INDEL \\ --output variants/trio.INDEL.vcf Filtering SNPs The command gatk VariantFiltration enables you to filter for both the INFO field (per variant) and FORMAT field (per genotype). For now we\u2019re only interested in filtering variants. Below you can find the command to hard-filter the SNP variants on some sensible thresholds (that are explained here ). gatk VariantFiltration \\ --variant variants/trio.SNP.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"SOR > 3.0\" --filter-name \"SOR3\" \\ --filter-expression \"FS > 60.0\" --filter-name \"FS60\" \\ --filter-expression \"MQ < 40.0\" --filter-name \"MQ40\" \\ --filter-expression \"MQRankSum < -12.5\" --filter-name \"MQRankSum-12.5\" \\ --filter-expression \"ReadPosRankSum < -8.0\" --filter-name \"ReadPosRankSum-8\" \\ --output variants/trio.SNP.filtered.vcf Exercise: Run the filtering command above. Did it affect the number of records in the vcf? Hint You can check out the number of records in a vcf with: grep -v \"^#\" <variants.vcf> | wc -l Answer There are no differences in the number of records: grep -v \"^#\" variants/trio.SNP.vcf | wc -l and grep -v \"^#\" variants/trio.SNP.filtered.vcf | wc -l both give 446. However, there are SNPs filtered out, by changing the FILTER column. You can check the number of records with PASS by: grep -v \"^#\" variants/trio.SNP.filtered.vcf | cut -f 7 | sort | uniq -c Giving: 441 PASS 2 QD2;SOR3 3 SOR3 Filtering INDELs A command with sensible parameters to do a first iteration of hard filtering the INDELs would be: gatk VariantFiltration \\ --variant variants/trio.INDEL.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"FS > 200.0\" --filter-name \"FS200\" \\ --filter-expression \"ReadPosRankSum < -20.0\" --filter-name \"ReadPosRankSum-20\" \\ --output variants/trio.INDEL.filtered.vcf Exercise: Run the command and figure out how many variants are filtered out. Hint You can use this command from the answer to the previous exercise: grep -v \"^#\" <variants.vcf> | cut -f 7 | sort | uniq -c to see how many INDELs were filtered out. Answer grep -v \"^#\" variants/trio.INDEL.filtered.vcf | cut -f 7 | sort | uniq -c gives: 110 PASS So no variants are filtered out. Merging filtered SNPs and INDELs Now that we have filtered the INDELs and SNPs separately, we can merge them again with this command: gatk MergeVcfs \\ --INPUT variants/trio.SNP.filtered.vcf \\ --INPUT variants/trio.INDEL.filtered.vcf \\ --OUTPUT variants/trio.filtered.vcf Exercise: Run the command to merge the vcfs. 2. Evaluation by concordance For this region we have a highly curated truth set for the mother available. It originates from the Illumina Platinum truth set . You can find it at data/variants/NA12878.vcf.gz To check how well we did, we\u2019d first need to extract a vcf with only the information of the mother. Exercise: To extract variants that have at least one alternative allele in the mother from variants/trio.filtered.vcf , use gatk SelectVariants with the arguments: --sample-name mother --exclude-non-variants --remove-unused-alternates In addition to the required arguments. Answer gatk SelectVariants \\ --variant variants/trio.filtered.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --output variants/mother.trio.filtered.vcf Exercise: A. How many variants are in mother.trio.filtered.vcf ? How many of those are filtered out? B. Compare our vcf with the curated truth set with the command below. How many SNPs didn\u2019t we detect? gatk Concordance \\ --evaluation variants/mother.trio.filtered.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio.filtered Answer To get the number of records per FILTER, we run: grep -v \"^#\" variants/mother.trio.filtered.vcf | cut -f 7 | sort | uniq -c gives: 407 PASS 2 SOR3 So two records were filtered out, based on the Symmetric Odds Ratio (issues with strand bias). Check out the output of gatk Concordance with cat : cat variants/concordance.mother.trio.filtered gives: type TP FP FN RECALL PRECISION SNP 319 5 9 0.973 0.985 INDEL 63 20 6 0.913 0.759 Showing that there were 9 false negatives, i.e. SNPs we didn\u2019t detect. Recall & precision More info on the definition of recall and precision on this wikipedia page Exercise: Check out the concordance of the mother with the truth set before filtering. Did filtering improve the recall or precision? Note We did the filtering on trio.vcf , therefore, you first have to extract the records that only apply to the mother by using gatk SelectVariants . Also note that trio.vcf contains records other than SNPs and INDELs. Use --select-type to select only SNPs and INDELs. Answer First select only SNPs and INDELs from the mother from the unfiltered vcf: gatk SelectVariants \\ --variant variants/trio.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --select-type INDEL \\ --select-type SNP \\ --output variants/mother.trio.vcf Get the concordance with the truth set: gatk Concordance \\ --evaluation variants/mother.trio.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio Which gives: type TP FP FN RECALL PRECISION SNP 319 7 9 0.973 0.979 INDEL 63 20 6 0.913 0.759 The precision for SNPs is slightly lower. Due to filtering, we removed two false positives.","title":"Filtering & evaluation"},{"location":"day2/filtering_evaluation/#learning-outcomes","text":"After having completed this chapter you will be able to: Explain why using Variant Quality Score Recalibration (VQSR) for filtering variants can outperform hard filtering Perform hard filtering on both SNPs and INDELs separately by using gatk SelectVariants in combination with gatk VariantFiltration Perform concordance between called variants and a truth set and evaluate performance of a variant calling workflow","title":"Learning outcomes"},{"location":"day2/filtering_evaluation/#exercises","text":"","title":"Exercises"},{"location":"day2/filtering_evaluation/#1-hard-filtering","text":"The developers of gatk strongly advise to do Variant Quality Score Recalibration (VQSR) for filtering SNPs and INDELs. However, this is not always possible. For example, in the case of limited data availability and/or in the case you are working with non-model organisms and/or in the case you are a bit lazy and okay with a number of false positives. Our dataset is too small to apply VQSR. We will therefore do hard filtering instead.","title":"1. Hard filtering"},{"location":"day2/filtering_evaluation/#splitting-snps-and-indels","text":"First, filtering thresholds are usually different for SNPs and INDELs. You can extract all the SNP records in our trio vcf like this: cd ~/workdir gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type SNP \\ --output variants/trio.SNP.vcf Exercise: Check out the documentation of gatk SelectVariants , and: Figure out what you\u2019ll need to fill in at --select-type if you want to select only INDELS. Generate a vcf with only the SNPs and a second vcf with only the INDELs from trio.vcf . Answer You will need to fill in INDEL at --select-type to filter for INDELs. To get the SNPs you can run the command above. To get the INDELs you\u2019ll need to change --select-type to INDEL : gatk SelectVariants \\ --variant variants/trio.vcf \\ --select-type INDEL \\ --output variants/trio.INDEL.vcf","title":"Splitting SNPs and INDELs"},{"location":"day2/filtering_evaluation/#filtering-snps","text":"The command gatk VariantFiltration enables you to filter for both the INFO field (per variant) and FORMAT field (per genotype). For now we\u2019re only interested in filtering variants. Below you can find the command to hard-filter the SNP variants on some sensible thresholds (that are explained here ). gatk VariantFiltration \\ --variant variants/trio.SNP.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"SOR > 3.0\" --filter-name \"SOR3\" \\ --filter-expression \"FS > 60.0\" --filter-name \"FS60\" \\ --filter-expression \"MQ < 40.0\" --filter-name \"MQ40\" \\ --filter-expression \"MQRankSum < -12.5\" --filter-name \"MQRankSum-12.5\" \\ --filter-expression \"ReadPosRankSum < -8.0\" --filter-name \"ReadPosRankSum-8\" \\ --output variants/trio.SNP.filtered.vcf Exercise: Run the filtering command above. Did it affect the number of records in the vcf? Hint You can check out the number of records in a vcf with: grep -v \"^#\" <variants.vcf> | wc -l Answer There are no differences in the number of records: grep -v \"^#\" variants/trio.SNP.vcf | wc -l and grep -v \"^#\" variants/trio.SNP.filtered.vcf | wc -l both give 446. However, there are SNPs filtered out, by changing the FILTER column. You can check the number of records with PASS by: grep -v \"^#\" variants/trio.SNP.filtered.vcf | cut -f 7 | sort | uniq -c Giving: 441 PASS 2 QD2;SOR3 3 SOR3","title":"Filtering SNPs"},{"location":"day2/filtering_evaluation/#filtering-indels","text":"A command with sensible parameters to do a first iteration of hard filtering the INDELs would be: gatk VariantFiltration \\ --variant variants/trio.INDEL.vcf \\ --filter-expression \"QD < 2.0\" --filter-name \"QD2\" \\ --filter-expression \"QUAL < 30.0\" --filter-name \"QUAL30\" \\ --filter-expression \"FS > 200.0\" --filter-name \"FS200\" \\ --filter-expression \"ReadPosRankSum < -20.0\" --filter-name \"ReadPosRankSum-20\" \\ --output variants/trio.INDEL.filtered.vcf Exercise: Run the command and figure out how many variants are filtered out. Hint You can use this command from the answer to the previous exercise: grep -v \"^#\" <variants.vcf> | cut -f 7 | sort | uniq -c to see how many INDELs were filtered out. Answer grep -v \"^#\" variants/trio.INDEL.filtered.vcf | cut -f 7 | sort | uniq -c gives: 110 PASS So no variants are filtered out.","title":"Filtering INDELs"},{"location":"day2/filtering_evaluation/#merging-filtered-snps-and-indels","text":"Now that we have filtered the INDELs and SNPs separately, we can merge them again with this command: gatk MergeVcfs \\ --INPUT variants/trio.SNP.filtered.vcf \\ --INPUT variants/trio.INDEL.filtered.vcf \\ --OUTPUT variants/trio.filtered.vcf Exercise: Run the command to merge the vcfs.","title":"Merging filtered SNPs and INDELs"},{"location":"day2/filtering_evaluation/#2-evaluation-by-concordance","text":"For this region we have a highly curated truth set for the mother available. It originates from the Illumina Platinum truth set . You can find it at data/variants/NA12878.vcf.gz To check how well we did, we\u2019d first need to extract a vcf with only the information of the mother. Exercise: To extract variants that have at least one alternative allele in the mother from variants/trio.filtered.vcf , use gatk SelectVariants with the arguments: --sample-name mother --exclude-non-variants --remove-unused-alternates In addition to the required arguments. Answer gatk SelectVariants \\ --variant variants/trio.filtered.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --output variants/mother.trio.filtered.vcf Exercise: A. How many variants are in mother.trio.filtered.vcf ? How many of those are filtered out? B. Compare our vcf with the curated truth set with the command below. How many SNPs didn\u2019t we detect? gatk Concordance \\ --evaluation variants/mother.trio.filtered.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio.filtered Answer To get the number of records per FILTER, we run: grep -v \"^#\" variants/mother.trio.filtered.vcf | cut -f 7 | sort | uniq -c gives: 407 PASS 2 SOR3 So two records were filtered out, based on the Symmetric Odds Ratio (issues with strand bias). Check out the output of gatk Concordance with cat : cat variants/concordance.mother.trio.filtered gives: type TP FP FN RECALL PRECISION SNP 319 5 9 0.973 0.985 INDEL 63 20 6 0.913 0.759 Showing that there were 9 false negatives, i.e. SNPs we didn\u2019t detect. Recall & precision More info on the definition of recall and precision on this wikipedia page Exercise: Check out the concordance of the mother with the truth set before filtering. Did filtering improve the recall or precision? Note We did the filtering on trio.vcf , therefore, you first have to extract the records that only apply to the mother by using gatk SelectVariants . Also note that trio.vcf contains records other than SNPs and INDELs. Use --select-type to select only SNPs and INDELs. Answer First select only SNPs and INDELs from the mother from the unfiltered vcf: gatk SelectVariants \\ --variant variants/trio.vcf \\ --sample-name mother \\ --exclude-non-variants \\ --remove-unused-alternates \\ --select-type INDEL \\ --select-type SNP \\ --output variants/mother.trio.vcf Get the concordance with the truth set: gatk Concordance \\ --evaluation variants/mother.trio.vcf \\ --truth data/variants/NA12878.vcf.gz \\ --intervals chr20:10018000-10220000 \\ --summary variants/concordance.mother.trio Which gives: type TP FP FN RECALL PRECISION SNP 319 7 9 0.973 0.979 INDEL 63 20 6 0.913 0.759 The precision for SNPs is slightly lower. Due to filtering, we removed two false positives.","title":"2. Evaluation by concordance"},{"location":"day2/variant_calling/","text":"Learning outcomes After having completed this chapter you will be able to: Describe how variant information is stored in a variant call format ( .vcf ) file Describe the \u2018missing genotype problem\u2019 when calling variants of multiple samples, and the different methods on how this can be solved Follow gatk best practices workflow to perform a variant analysis by: Applying Base Quality Score Recalibration on an alignment file Calling variants with gatk HaplotypeCaller Combining multiple vcf files into a single vcf file Perform basic operations to get statistics of a vcf file Material Download the presentation VCF format description The paper on genomic variant call format (gVCF) GATK best practices germline short variant workflow : Exercises 1. Indexing, indexing, indexing Many algorithms work faster, or only work with an index of their (large) input files. In that sense, gatk is no different from other tools. The index for a reference needs to be created in two steps: cd ~/workdir/data/reference samtools faidx <reference.fa> gatk CreateSequenceDictionary --REFERENCE <reference.fa> Also input vcf files need to be indexed. This will create a .idx file associated with the .vcf . You can do this like this: gatk IndexFeatureFile --input <variants.vcf> Exercise: Create the required gatk indexes for: The reference genome reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa A part of the dbsnp database: variants/GCF.38.filtered.renamed.vcf A part of the 1000 genomes indel golden standard: variants/1000g_gold_standard.indels.filtered.vcf Answer Creating the index for the reference genome: cd ~/workdir/data samtools faidx reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa gatk CreateSequenceDictionary --REFERENCE reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa Creating the indices for the vcfs: gatk IndexFeatureFile --input variants/1000g_gold_standard.indels.filtered.vcf gatk IndexFeatureFile --input variants/GCF.38.filtered.renamed.vcf Chromosome names Unlike IGV, gatk requires equal chromosome names for all its input files and indexes, e.g. in .fasta , .bam and .vcf files. In general, for the human genome there are three types of chromosome names: Just a number, e.g. 20 Prefixed by chr . e.g. chr20 Refseq name, e.g. NC_000020.11 Before you start the alignment, it\u2019s wise to check out what chromosome naming your input files are using, because changing chromosome names in a .fasta file is easier than in a .bam file. If your fasta titles are e.g. starting with a number you can add chr to it with sed : sed s/^>/>chr/g <reference.fasta> You can change chromsome names in a vcf with bcftools annotate : bcftools annotate --rename-chrs <tab-delimited-renaming> <input.vcf> 2. Base Quality Score Recalibration (BQSR) BQSR evaluates the base qualities on systematic error. It can ignore sites with known variants. BQSR helps to identify faulty base calls, and therefore reduces the chance on discovering false positive variant positions. BQSR is done in two steps: Recalibration with gatk BaseRecalibrator By using the output of gatk BaseRecalibrator , the application to the bam file with gatk ApplyBQSR Exercise: Check out the documentation of the tools. Which options are required? Answer For gatk BaseRecalibrator : --reference --input --known-sites --output For gatk ApplyBQSR : --bqsr-recal-file --input --output Exercise: Run the two commands with the required options on mother.rg.md.bam , with --known-sites variants/1000g_gold_standard.indels.filtered.vcf and variants/GCF.38.filtered.renamed.vcf . Multiple inputs for same argument In some cases you need to add multiple inputs (e.g. multiple vcf files) into the same argument (e.g. --known-sites ). To provide multiple inputs for the same argument in gatk , you can use the same argument multiple times, e.g.: gatk BaseRecalibrator \\ --reference <reference.fa> \\ --input <alignment.bam> \\ --known-sites <variants1.vcf> \\ --known-sites <variants2.vcf> \\ --output <output.table> Answer cd ~/workdir mkdir bqsr gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/mother.rg.md.bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/mother.recal.table gatk ApplyBQSR \\ --input alignment/mother.rg.md.bam \\ --bqsr-recal-file bqsr/mother.recal.table \\ --output bqsr/mother.recal.bam Exercise: Place these commands in a \u2018for loop\u2019, that performs the BQSR for mother, father and son. Answer cd ~/workdir for sample in mother father son do gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/ $sample .rg.md.bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/ $sample .recal.table gatk ApplyBQSR \\ --input alignment/ $sample .rg.md.bam \\ --bqsr-recal-file bqsr/ $sample .recal.table \\ --output bqsr/ $sample .recal.bam done 3. Variant calling Calculating PL and GQ by hand Here\u2019s a function in R to calculate genotype likelihoods as described in Li H. Bioinformatics. 2011;27:2987\u201393 (assuming equal base error probabilities for all reads): genotype_likelihood <- function ( m , g , e , ref , alt ){ ((( m - g ) * e + g * ( 1 - e )) ^ alt * (( m - g ) * ( 1 - e ) + g * e ) ^ ref ) / ( m ^ ( ref + alt )) } Where: m : ploidy g : number of alternative alleles e : base error probability ref : number of reference alleles counted alt : number of alternative alleles counted Exercise: In a local R session, calculate the genotype likelihoods for a case where we count 22 reference alleles and 4 alternative alleles (so a coverage of 26), and base error probability of 0.01. Calculate the PL values ( -10*log10(likelihood) ) for each genotype. Answer # For g = 0 (i.e. 0 reference alleles) -10 * log10 ( genotype_likelihood ( m = 2 , g = 0 , e = 0.01 , ref = 22 , alt = 4 )) # [1] 80.96026 -10 * log10 ( genotype_likelihood ( m = 2 , g = 1 , e = 0.01 , ref = 22 , alt = 4 )) # [1] 78.2678 -10 * log10 ( genotype_likelihood ( m = 2 , g = 2 , e = 0.01 , ref = 22 , alt = 4 )) # [1] 440.1746 Exercise: What is the most likely genotype? What is the genotype quality (GQ)? Do you think we should be confident about this genotype call? Answer The most likely genotype has the lowest PL, so where g=1 (heterozygous). GL is calculated by subtracting the lowest PL from the second lowest PL, so 80.96 - 78.27 = 2.69. This is a low genotype quality (note that we\u2019re in the phred scale), i.e. an error probability of 0.54. This makes sense, if the genotype is heterozygous we would roughly expect to count as many reference as alternative alleles, and our example quite strongly deviates from this expectation. Calling variants with GATK The command gatk HaplotypeCaller is the core command of gatk . It performs the actual variant calling. Exercise: Check out the gatk HaplotypeCaller documentation , and find out which arguments are required. Answer Required arguments are: --input --ouput --reference Exercise: Make a directory ~/workdir/variants to write the output vcf. After that, run gatk HaplotypeCaller with required options on the recalibrated alignment file of the mother ( bqsr/mother.recal.bam ). We\u2019ll focus on a small region, so add --intervals chr20:10018000-10220000 . Answer cd ~/workdir mkdir variants gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/mother.recal.bam \\ --output variants/mother.HC.vcf \\ --intervals chr20:10018000-10220000 Exercise: You can get the number of records in a vcf with piping the output of grep -v '^#' to wc -l . Get the number of variants in the vcf. Answer grep -v '^#' variants/mother.HC.vcf | wc -l Shows you that there are 411 variants in there. You can get some more statistics with gatk VariantsToTable . The output can be used to easily query things in R or MS Excel. Here\u2019s an example: gatk VariantsToTable \\ --variant variants/mother.HC.vcf \\ --fields CHROM -F POS -F TYPE -GF GT \\ --output variants/mother.HC.table Exercise: Run the command and have a look at the first few records (use e.g. head or less ). After that, report the number of SNPs and INDELs. Answer You can get the number of SNPs with: grep -c \"SNP\" variants/mother.HC.table which will give 326 And the number of INDELs with: grep -c \"INDEL\" variants/mother.HC.table that outputs 84 A more fancy way to this would be: cut -f 3 variants/mother.HC.table | tail -n +2 | sort | uniq -c Giving: 84 INDEL 1 MIXED 326 SNP We will do the variant calling on all three samples. Later we want to combine the variant calls. For efficient merging of vcfs, we will need to output the variants as a GVCF. To do that, we will use the option --emit-ref-confidence GVCF . Also, we\u2019ll visualise the haplotype phasing with IGV in the next section. For that we\u2019ll need a phased bam. You can get this output with the argument --bam-output . Exercise: Run gatk HaplotypeCaller for mother, father and son by using a loop, and by using the arguments in the previous exercise. On top of that add the arguments --emit-ref-confidence GVCF and --bamoutput <phased.bam> . Answer cd ~/workdir for sample in mother father son do gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/ $sample .recal.bam \\ --output variants/ $sample .HC.g.vcf \\ --bam-output variants/ $sample .phased.bam \\ --intervals chr20:10018000-10220000 \\ --emit-ref-confidence GVCF done 4. Combining GVCFs Now that we have all three GVCFs of the mother, father and son, we can combine them into a database. We do this because it enables us to later add GVCFs (with the option --genomicsdb-update-workspace-path ), and to efficiently combine them into a single vcf. You can generate a GenomicsDB on our three samples like this: cd ~/workdir gatk GenomicsDBImport \\ --variant variants/mother.HC.g.vcf \\ --variant variants/father.HC.g.vcf \\ --variant variants/son.HC.g.vcf \\ --intervals chr20:10018000-10220000 \\ --genomicsdb-workspace-path genomicsdb Exercise: Run this command to generate the database. You can retrieve the combined vcf from the database with gatk GenotypeGVCFs . gatk GenotypeGVCFs \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --variant gendb://genomicsdb \\ --intervals chr20:10018000-10220000 \\ --output variants/trio.vcf Exercise: Run this command to generate the combined vcf.","title":"Variant calling"},{"location":"day2/variant_calling/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe how variant information is stored in a variant call format ( .vcf ) file Describe the \u2018missing genotype problem\u2019 when calling variants of multiple samples, and the different methods on how this can be solved Follow gatk best practices workflow to perform a variant analysis by: Applying Base Quality Score Recalibration on an alignment file Calling variants with gatk HaplotypeCaller Combining multiple vcf files into a single vcf file Perform basic operations to get statistics of a vcf file","title":"Learning outcomes"},{"location":"day2/variant_calling/#material","text":"Download the presentation VCF format description The paper on genomic variant call format (gVCF) GATK best practices germline short variant workflow :","title":"Material"},{"location":"day2/variant_calling/#exercises","text":"","title":"Exercises"},{"location":"day2/variant_calling/#1-indexing-indexing-indexing","text":"Many algorithms work faster, or only work with an index of their (large) input files. In that sense, gatk is no different from other tools. The index for a reference needs to be created in two steps: cd ~/workdir/data/reference samtools faidx <reference.fa> gatk CreateSequenceDictionary --REFERENCE <reference.fa> Also input vcf files need to be indexed. This will create a .idx file associated with the .vcf . You can do this like this: gatk IndexFeatureFile --input <variants.vcf> Exercise: Create the required gatk indexes for: The reference genome reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa A part of the dbsnp database: variants/GCF.38.filtered.renamed.vcf A part of the 1000 genomes indel golden standard: variants/1000g_gold_standard.indels.filtered.vcf Answer Creating the index for the reference genome: cd ~/workdir/data samtools faidx reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa gatk CreateSequenceDictionary --REFERENCE reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa Creating the indices for the vcfs: gatk IndexFeatureFile --input variants/1000g_gold_standard.indels.filtered.vcf gatk IndexFeatureFile --input variants/GCF.38.filtered.renamed.vcf Chromosome names Unlike IGV, gatk requires equal chromosome names for all its input files and indexes, e.g. in .fasta , .bam and .vcf files. In general, for the human genome there are three types of chromosome names: Just a number, e.g. 20 Prefixed by chr . e.g. chr20 Refseq name, e.g. NC_000020.11 Before you start the alignment, it\u2019s wise to check out what chromosome naming your input files are using, because changing chromosome names in a .fasta file is easier than in a .bam file. If your fasta titles are e.g. starting with a number you can add chr to it with sed : sed s/^>/>chr/g <reference.fasta> You can change chromsome names in a vcf with bcftools annotate : bcftools annotate --rename-chrs <tab-delimited-renaming> <input.vcf>","title":"1. Indexing, indexing, indexing"},{"location":"day2/variant_calling/#2-base-quality-score-recalibration-bqsr","text":"BQSR evaluates the base qualities on systematic error. It can ignore sites with known variants. BQSR helps to identify faulty base calls, and therefore reduces the chance on discovering false positive variant positions. BQSR is done in two steps: Recalibration with gatk BaseRecalibrator By using the output of gatk BaseRecalibrator , the application to the bam file with gatk ApplyBQSR Exercise: Check out the documentation of the tools. Which options are required? Answer For gatk BaseRecalibrator : --reference --input --known-sites --output For gatk ApplyBQSR : --bqsr-recal-file --input --output Exercise: Run the two commands with the required options on mother.rg.md.bam , with --known-sites variants/1000g_gold_standard.indels.filtered.vcf and variants/GCF.38.filtered.renamed.vcf . Multiple inputs for same argument In some cases you need to add multiple inputs (e.g. multiple vcf files) into the same argument (e.g. --known-sites ). To provide multiple inputs for the same argument in gatk , you can use the same argument multiple times, e.g.: gatk BaseRecalibrator \\ --reference <reference.fa> \\ --input <alignment.bam> \\ --known-sites <variants1.vcf> \\ --known-sites <variants2.vcf> \\ --output <output.table> Answer cd ~/workdir mkdir bqsr gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/mother.rg.md.bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/mother.recal.table gatk ApplyBQSR \\ --input alignment/mother.rg.md.bam \\ --bqsr-recal-file bqsr/mother.recal.table \\ --output bqsr/mother.recal.bam Exercise: Place these commands in a \u2018for loop\u2019, that performs the BQSR for mother, father and son. Answer cd ~/workdir for sample in mother father son do gatk BaseRecalibrator \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input alignment/ $sample .rg.md.bam \\ --known-sites data/variants/GCF.38.filtered.renamed.vcf \\ --known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\ --output bqsr/ $sample .recal.table gatk ApplyBQSR \\ --input alignment/ $sample .rg.md.bam \\ --bqsr-recal-file bqsr/ $sample .recal.table \\ --output bqsr/ $sample .recal.bam done","title":"2. Base Quality Score Recalibration (BQSR)"},{"location":"day2/variant_calling/#3-variant-calling","text":"","title":"3. Variant calling"},{"location":"day2/variant_calling/#calculating-pl-and-gq-by-hand","text":"Here\u2019s a function in R to calculate genotype likelihoods as described in Li H. Bioinformatics. 2011;27:2987\u201393 (assuming equal base error probabilities for all reads): genotype_likelihood <- function ( m , g , e , ref , alt ){ ((( m - g ) * e + g * ( 1 - e )) ^ alt * (( m - g ) * ( 1 - e ) + g * e ) ^ ref ) / ( m ^ ( ref + alt )) } Where: m : ploidy g : number of alternative alleles e : base error probability ref : number of reference alleles counted alt : number of alternative alleles counted Exercise: In a local R session, calculate the genotype likelihoods for a case where we count 22 reference alleles and 4 alternative alleles (so a coverage of 26), and base error probability of 0.01. Calculate the PL values ( -10*log10(likelihood) ) for each genotype. Answer # For g = 0 (i.e. 0 reference alleles) -10 * log10 ( genotype_likelihood ( m = 2 , g = 0 , e = 0.01 , ref = 22 , alt = 4 )) # [1] 80.96026 -10 * log10 ( genotype_likelihood ( m = 2 , g = 1 , e = 0.01 , ref = 22 , alt = 4 )) # [1] 78.2678 -10 * log10 ( genotype_likelihood ( m = 2 , g = 2 , e = 0.01 , ref = 22 , alt = 4 )) # [1] 440.1746 Exercise: What is the most likely genotype? What is the genotype quality (GQ)? Do you think we should be confident about this genotype call? Answer The most likely genotype has the lowest PL, so where g=1 (heterozygous). GL is calculated by subtracting the lowest PL from the second lowest PL, so 80.96 - 78.27 = 2.69. This is a low genotype quality (note that we\u2019re in the phred scale), i.e. an error probability of 0.54. This makes sense, if the genotype is heterozygous we would roughly expect to count as many reference as alternative alleles, and our example quite strongly deviates from this expectation.","title":"Calculating PL and GQ by hand"},{"location":"day2/variant_calling/#calling-variants-with-gatk","text":"The command gatk HaplotypeCaller is the core command of gatk . It performs the actual variant calling. Exercise: Check out the gatk HaplotypeCaller documentation , and find out which arguments are required. Answer Required arguments are: --input --ouput --reference Exercise: Make a directory ~/workdir/variants to write the output vcf. After that, run gatk HaplotypeCaller with required options on the recalibrated alignment file of the mother ( bqsr/mother.recal.bam ). We\u2019ll focus on a small region, so add --intervals chr20:10018000-10220000 . Answer cd ~/workdir mkdir variants gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/mother.recal.bam \\ --output variants/mother.HC.vcf \\ --intervals chr20:10018000-10220000 Exercise: You can get the number of records in a vcf with piping the output of grep -v '^#' to wc -l . Get the number of variants in the vcf. Answer grep -v '^#' variants/mother.HC.vcf | wc -l Shows you that there are 411 variants in there. You can get some more statistics with gatk VariantsToTable . The output can be used to easily query things in R or MS Excel. Here\u2019s an example: gatk VariantsToTable \\ --variant variants/mother.HC.vcf \\ --fields CHROM -F POS -F TYPE -GF GT \\ --output variants/mother.HC.table Exercise: Run the command and have a look at the first few records (use e.g. head or less ). After that, report the number of SNPs and INDELs. Answer You can get the number of SNPs with: grep -c \"SNP\" variants/mother.HC.table which will give 326 And the number of INDELs with: grep -c \"INDEL\" variants/mother.HC.table that outputs 84 A more fancy way to this would be: cut -f 3 variants/mother.HC.table | tail -n +2 | sort | uniq -c Giving: 84 INDEL 1 MIXED 326 SNP We will do the variant calling on all three samples. Later we want to combine the variant calls. For efficient merging of vcfs, we will need to output the variants as a GVCF. To do that, we will use the option --emit-ref-confidence GVCF . Also, we\u2019ll visualise the haplotype phasing with IGV in the next section. For that we\u2019ll need a phased bam. You can get this output with the argument --bam-output . Exercise: Run gatk HaplotypeCaller for mother, father and son by using a loop, and by using the arguments in the previous exercise. On top of that add the arguments --emit-ref-confidence GVCF and --bamoutput <phased.bam> . Answer cd ~/workdir for sample in mother father son do gatk HaplotypeCaller \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --input bqsr/ $sample .recal.bam \\ --output variants/ $sample .HC.g.vcf \\ --bam-output variants/ $sample .phased.bam \\ --intervals chr20:10018000-10220000 \\ --emit-ref-confidence GVCF done","title":"Calling variants with GATK"},{"location":"day2/variant_calling/#4-combining-gvcfs","text":"Now that we have all three GVCFs of the mother, father and son, we can combine them into a database. We do this because it enables us to later add GVCFs (with the option --genomicsdb-update-workspace-path ), and to efficiently combine them into a single vcf. You can generate a GenomicsDB on our three samples like this: cd ~/workdir gatk GenomicsDBImport \\ --variant variants/mother.HC.g.vcf \\ --variant variants/father.HC.g.vcf \\ --variant variants/son.HC.g.vcf \\ --intervals chr20:10018000-10220000 \\ --genomicsdb-workspace-path genomicsdb Exercise: Run this command to generate the database. You can retrieve the combined vcf from the database with gatk GenotypeGVCFs . gatk GenotypeGVCFs \\ --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\ --variant gendb://genomicsdb \\ --intervals chr20:10018000-10220000 \\ --output variants/trio.vcf Exercise: Run this command to generate the combined vcf.","title":"4. Combining GVCFs"},{"location":"day2/visualisation/","text":"Learning outcomes After having completed this chapter you will be able to: Use IGV to: Visualise read alignments that support called variants Visualise phasing information generated by gatk Material IGV documentation Exercises Download the following files to your local computer: variants/mother.phased.bam variants/mother.phased.bai bqsr/mother.recal.bam bqsr/mother.recal.bai variants/mother.HC.vcf Download files from the notebook You can download files from the file browser, by right-clicking a file and selecting Download : Launch IGV and select the human genome version hg38 as a reference. Load the downloaded files as tracks in igv with File > Load From File\u2026 , and navigate to region chr20:10,026,397-10,026,638 . Exercise: Zoom out for a bit. Not all reads are in the track of mother.phased.bam . What kind of reads are in there? Answer The reads supporting called variants. Now, we\u2019ll investigate the haplotype phasing. Go back to chr20:10,026,397-10,026,638 . Tip If your screen isn\u2019t huge, you can remove the track mother.recal.bam . Do that by right-click on the track, and click on Remove Track . In the track with mother.phased.bam , right click on the reads and select Group alignments by > read group . This splits your track in two parts, one with artificial reads describing haplotypes that were taken in consideration (ArtificalHaplotypeRG), and one with original reads that support the variants. Exercise : How many haplotypes were taken into consideration? How many haplotypes can you expect at maximum within a single individual? Hint This might come as a shock, but humans are diploid. Answer Three haplotypes, as there are three artificial reads: Diploids can carry two haplotypes. So at least one of the three is wrong. Now colour the reads by phase. Do that with by right clicking on the track and choose Colour alignments by > tag , and type in \u201cHC\u201d (that\u2019s the tag where the phasing is stored). Exercise: Which artificial read doesn\u2019t get support from the original sequence reads? Are the alternative alleles of the two SNPs on the same haplotype (i.e. in phase)? Answer The track should look like this (colours can be different): The reads only support the brown and blue haplotype, and not the pink one. The alternative alleles are coloured in IGV. For the first SNP this is the C (in blue) and for the second the T (in red). They are always in different reads, so they are in repulsion (not in phase).","title":"Visualisation"},{"location":"day2/visualisation/#learning-outcomes","text":"After having completed this chapter you will be able to: Use IGV to: Visualise read alignments that support called variants Visualise phasing information generated by gatk","title":"Learning outcomes"},{"location":"day2/visualisation/#material","text":"IGV documentation","title":"Material"},{"location":"day2/visualisation/#exercises","text":"Download the following files to your local computer: variants/mother.phased.bam variants/mother.phased.bai bqsr/mother.recal.bam bqsr/mother.recal.bai variants/mother.HC.vcf Download files from the notebook You can download files from the file browser, by right-clicking a file and selecting Download : Launch IGV and select the human genome version hg38 as a reference. Load the downloaded files as tracks in igv with File > Load From File\u2026 , and navigate to region chr20:10,026,397-10,026,638 . Exercise: Zoom out for a bit. Not all reads are in the track of mother.phased.bam . What kind of reads are in there? Answer The reads supporting called variants. Now, we\u2019ll investigate the haplotype phasing. Go back to chr20:10,026,397-10,026,638 . Tip If your screen isn\u2019t huge, you can remove the track mother.recal.bam . Do that by right-click on the track, and click on Remove Track . In the track with mother.phased.bam , right click on the reads and select Group alignments by > read group . This splits your track in two parts, one with artificial reads describing haplotypes that were taken in consideration (ArtificalHaplotypeRG), and one with original reads that support the variants. Exercise : How many haplotypes were taken into consideration? How many haplotypes can you expect at maximum within a single individual? Hint This might come as a shock, but humans are diploid. Answer Three haplotypes, as there are three artificial reads: Diploids can carry two haplotypes. So at least one of the three is wrong. Now colour the reads by phase. Do that with by right clicking on the track and choose Colour alignments by > tag , and type in \u201cHC\u201d (that\u2019s the tag where the phasing is stored). Exercise: Which artificial read doesn\u2019t get support from the original sequence reads? Are the alternative alleles of the two SNPs on the same haplotype (i.e. in phase)? Answer The track should look like this (colours can be different): The reads only support the brown and blue haplotype, and not the pink one. The alternative alleles are coloured in IGV. For the first SNP this is the C (in blue) and for the second the T (in red). They are always in different reads, so they are in repulsion (not in phase).","title":"Exercises"}]}